{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.7381163271331562,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002952465308532625,
      "grad_norm": 1.6679085493087769,
      "learning_rate": 1.409722468260998e-05,
      "logits/chosen": 1.3163950443267822,
      "logits/rejected": 1.295025110244751,
      "logps/chosen": -188.26011657714844,
      "logps/rejected": -187.53231811523438,
      "loss": 0.6938,
      "rewards/accuracies": 0.5166667103767395,
      "rewards/chosen": 0.01493812631815672,
      "rewards/margins": -0.0012866719625890255,
      "rewards/rejected": 0.016224797815084457,
      "step": 10
    },
    {
      "epoch": 0.00590493061706525,
      "grad_norm": 1.9812248945236206,
      "learning_rate": 1.4094449365219959e-05,
      "logits/chosen": 1.0816289186477661,
      "logits/rejected": 1.0566896200180054,
      "logps/chosen": -188.89474487304688,
      "logps/rejected": -193.21630859375,
      "loss": 0.6938,
      "rewards/accuracies": 0.5000000596046448,
      "rewards/chosen": -0.0006403095903806388,
      "rewards/margins": -0.0011046089930459857,
      "rewards/rejected": 0.0004642995190806687,
      "step": 20
    },
    {
      "epoch": 0.008857395925597875,
      "grad_norm": 1.9625227451324463,
      "learning_rate": 1.4091674047829938e-05,
      "logits/chosen": 1.3286247253417969,
      "logits/rejected": 1.3404796123504639,
      "logps/chosen": -192.5899200439453,
      "logps/rejected": -191.12594604492188,
      "loss": 0.692,
      "rewards/accuracies": 0.5166666507720947,
      "rewards/chosen": -0.005629756022244692,
      "rewards/margins": 0.0024397787638008595,
      "rewards/rejected": -0.008069533854722977,
      "step": 30
    },
    {
      "epoch": 0.0118098612341305,
      "grad_norm": 1.7556151151657104,
      "learning_rate": 1.4088898730439919e-05,
      "logits/chosen": 1.3959019184112549,
      "logits/rejected": 1.389626145362854,
      "logps/chosen": -190.3701171875,
      "logps/rejected": -192.5779266357422,
      "loss": 0.6854,
      "rewards/accuracies": 0.6333333253860474,
      "rewards/chosen": -0.011286011897027493,
      "rewards/margins": 0.01599980890750885,
      "rewards/rejected": -0.027285819873213768,
      "step": 40
    },
    {
      "epoch": 0.014762326542663124,
      "grad_norm": 2.2692432403564453,
      "learning_rate": 1.4086123413049898e-05,
      "logits/chosen": 1.2686465978622437,
      "logits/rejected": 1.2498760223388672,
      "logps/chosen": -197.56130981445312,
      "logps/rejected": -196.86962890625,
      "loss": 0.6785,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.03369282931089401,
      "rewards/margins": 0.030824029818177223,
      "rewards/rejected": -0.06451685726642609,
      "step": 50
    },
    {
      "epoch": 0.01771479185119575,
      "grad_norm": 2.0968775749206543,
      "learning_rate": 1.4083348095659877e-05,
      "logits/chosen": 1.1023571491241455,
      "logits/rejected": 1.1064975261688232,
      "logps/chosen": -196.503173828125,
      "logps/rejected": -197.2303466796875,
      "loss": 0.6772,
      "rewards/accuracies": 0.5833333134651184,
      "rewards/chosen": -0.08436842262744904,
      "rewards/margins": 0.03441276401281357,
      "rewards/rejected": -0.1187811866402626,
      "step": 60
    },
    {
      "epoch": 0.020667257159728374,
      "grad_norm": 1.8844558000564575,
      "learning_rate": 1.4080572778269856e-05,
      "logits/chosen": 1.223649024963379,
      "logits/rejected": 1.2093896865844727,
      "logps/chosen": -194.44735717773438,
      "logps/rejected": -191.98007202148438,
      "loss": 0.6716,
      "rewards/accuracies": 0.6833333373069763,
      "rewards/chosen": -0.14823535084724426,
      "rewards/margins": 0.047428231686353683,
      "rewards/rejected": -0.19566360116004944,
      "step": 70
    },
    {
      "epoch": 0.023619722468261,
      "grad_norm": 2.167191505432129,
      "learning_rate": 1.4077797460879835e-05,
      "logits/chosen": 1.200514316558838,
      "logits/rejected": 1.194620966911316,
      "logps/chosen": -192.8304443359375,
      "logps/rejected": -195.03567504882812,
      "loss": 0.687,
      "rewards/accuracies": 0.5333333015441895,
      "rewards/chosen": -0.19469544291496277,
      "rewards/margins": 0.020383045077323914,
      "rewards/rejected": -0.2150784432888031,
      "step": 80
    },
    {
      "epoch": 0.026572187776793623,
      "grad_norm": 1.8391653299331665,
      "learning_rate": 1.4075022143489814e-05,
      "logits/chosen": 1.1776010990142822,
      "logits/rejected": 1.164192795753479,
      "logps/chosen": -193.01126098632812,
      "logps/rejected": -197.3560028076172,
      "loss": 0.676,
      "rewards/accuracies": 0.6333333253860474,
      "rewards/chosen": -0.2179233729839325,
      "rewards/margins": 0.04631948471069336,
      "rewards/rejected": -0.26424282789230347,
      "step": 90
    },
    {
      "epoch": 0.029524653085326247,
      "grad_norm": 2.3060414791107178,
      "learning_rate": 1.4072246826099793e-05,
      "logits/chosen": 1.4481456279754639,
      "logits/rejected": 1.423404335975647,
      "logps/chosen": -190.39169311523438,
      "logps/rejected": -188.42910766601562,
      "loss": 0.6718,
      "rewards/accuracies": 0.5333333611488342,
      "rewards/chosen": -0.249594047665596,
      "rewards/margins": 0.058133114129304886,
      "rewards/rejected": -0.3077271580696106,
      "step": 100
    },
    {
      "epoch": 0.032477118393858875,
      "grad_norm": 2.4504520893096924,
      "learning_rate": 1.4069471508709774e-05,
      "logits/chosen": 1.3212354183197021,
      "logits/rejected": 1.3001505136489868,
      "logps/chosen": -191.887451171875,
      "logps/rejected": -196.02572631835938,
      "loss": 0.651,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.1926524043083191,
      "rewards/margins": 0.11011922359466553,
      "rewards/rejected": -0.3027716279029846,
      "step": 110
    },
    {
      "epoch": 0.0354295837023915,
      "grad_norm": 2.6443369388580322,
      "learning_rate": 1.4066696191319753e-05,
      "logits/chosen": 1.144884467124939,
      "logits/rejected": 1.1536208391189575,
      "logps/chosen": -191.10101318359375,
      "logps/rejected": -195.90509033203125,
      "loss": 0.6707,
      "rewards/accuracies": 0.4833332896232605,
      "rewards/chosen": -0.27623942494392395,
      "rewards/margins": 0.0764901265501976,
      "rewards/rejected": -0.35272955894470215,
      "step": 120
    },
    {
      "epoch": 0.038382049010924124,
      "grad_norm": 3.0184335708618164,
      "learning_rate": 1.406392087392973e-05,
      "logits/chosen": 1.1022096872329712,
      "logits/rejected": 1.0936453342437744,
      "logps/chosen": -193.27810668945312,
      "logps/rejected": -198.29055786132812,
      "loss": 0.6658,
      "rewards/accuracies": 0.5166666507720947,
      "rewards/chosen": -0.2800106108188629,
      "rewards/margins": 0.08543922752141953,
      "rewards/rejected": -0.36544984579086304,
      "step": 130
    },
    {
      "epoch": 0.04133451431945675,
      "grad_norm": 4.631040573120117,
      "learning_rate": 1.4061145556539711e-05,
      "logits/chosen": 1.1325372457504272,
      "logits/rejected": 1.1201159954071045,
      "logps/chosen": -192.26309204101562,
      "logps/rejected": -195.80029296875,
      "loss": 0.6797,
      "rewards/accuracies": 0.5666667222976685,
      "rewards/chosen": -0.19191798567771912,
      "rewards/margins": 0.07050926983356476,
      "rewards/rejected": -0.26242727041244507,
      "step": 140
    },
    {
      "epoch": 0.04428697962798937,
      "grad_norm": 4.540611743927002,
      "learning_rate": 1.405837023914969e-05,
      "logits/chosen": 1.4499328136444092,
      "logits/rejected": 1.4280996322631836,
      "logps/chosen": -195.67062377929688,
      "logps/rejected": -191.3633575439453,
      "loss": 0.6644,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.12889732420444489,
      "rewards/margins": 0.09265853464603424,
      "rewards/rejected": -0.22155587375164032,
      "step": 150
    },
    {
      "epoch": 0.047239444936522,
      "grad_norm": 4.287151336669922,
      "learning_rate": 1.4055594921759671e-05,
      "logits/chosen": 0.8965250253677368,
      "logits/rejected": 0.8926364779472351,
      "logps/chosen": -197.40505981445312,
      "logps/rejected": -188.66720581054688,
      "loss": 0.6792,
      "rewards/accuracies": 0.5666666626930237,
      "rewards/chosen": -0.18037454783916473,
      "rewards/margins": 0.061235349625349045,
      "rewards/rejected": -0.24160988628864288,
      "step": 160
    },
    {
      "epoch": 0.05019191024505462,
      "grad_norm": 3.9502644538879395,
      "learning_rate": 1.4052819604369648e-05,
      "logits/chosen": 1.1591306924819946,
      "logits/rejected": 1.163309097290039,
      "logps/chosen": -189.30929565429688,
      "logps/rejected": -192.555419921875,
      "loss": 0.7255,
      "rewards/accuracies": 0.5333333611488342,
      "rewards/chosen": -0.12713633477687836,
      "rewards/margins": -0.030258914455771446,
      "rewards/rejected": -0.09687741845846176,
      "step": 170
    },
    {
      "epoch": 0.053144375553587246,
      "grad_norm": 3.4528775215148926,
      "learning_rate": 1.405004428697963e-05,
      "logits/chosen": 1.4292628765106201,
      "logits/rejected": 1.4242165088653564,
      "logps/chosen": -191.7925567626953,
      "logps/rejected": -194.33726501464844,
      "loss": 0.6004,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": 0.06182248517870903,
      "rewards/margins": 0.23165583610534668,
      "rewards/rejected": -0.16983334720134735,
      "step": 180
    },
    {
      "epoch": 0.05609684086211987,
      "grad_norm": 3.3132870197296143,
      "learning_rate": 1.4047268969589608e-05,
      "logits/chosen": 1.4588228464126587,
      "logits/rejected": 1.4415382146835327,
      "logps/chosen": -189.73126220703125,
      "logps/rejected": -193.24221801757812,
      "loss": 0.669,
      "rewards/accuracies": 0.5833333730697632,
      "rewards/chosen": -0.033274997025728226,
      "rewards/margins": 0.09554506838321686,
      "rewards/rejected": -0.12882007658481598,
      "step": 190
    },
    {
      "epoch": 0.059049306170652495,
      "grad_norm": 4.620922565460205,
      "learning_rate": 1.4044493652199586e-05,
      "logits/chosen": 1.396113634109497,
      "logits/rejected": 1.4153512716293335,
      "logps/chosen": -196.70509338378906,
      "logps/rejected": -198.3530731201172,
      "loss": 0.6608,
      "rewards/accuracies": 0.6333333253860474,
      "rewards/chosen": -0.04336482658982277,
      "rewards/margins": 0.12052655220031738,
      "rewards/rejected": -0.16389136016368866,
      "step": 200
    },
    {
      "epoch": 0.06200177147918512,
      "grad_norm": 3.7829530239105225,
      "learning_rate": 1.4041718334809567e-05,
      "logits/chosen": 1.1892964839935303,
      "logits/rejected": 1.1847786903381348,
      "logps/chosen": -200.33338928222656,
      "logps/rejected": -193.14791870117188,
      "loss": 0.658,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.0833594799041748,
      "rewards/margins": 0.11519128084182739,
      "rewards/rejected": -0.1985507607460022,
      "step": 210
    },
    {
      "epoch": 0.06495423678771775,
      "grad_norm": 4.058221340179443,
      "learning_rate": 1.4038943017419546e-05,
      "logits/chosen": 1.252482295036316,
      "logits/rejected": 1.2444968223571777,
      "logps/chosen": -194.92417907714844,
      "logps/rejected": -195.31048583984375,
      "loss": 0.658,
      "rewards/accuracies": 0.6166666746139526,
      "rewards/chosen": -0.08455131947994232,
      "rewards/margins": 0.1268441379070282,
      "rewards/rejected": -0.21139545738697052,
      "step": 220
    },
    {
      "epoch": 0.06790670209625037,
      "grad_norm": 3.745450258255005,
      "learning_rate": 1.4036167700029526e-05,
      "logits/chosen": 1.385107159614563,
      "logits/rejected": 1.3698781728744507,
      "logps/chosen": -194.59793090820312,
      "logps/rejected": -196.3892822265625,
      "loss": 0.6736,
      "rewards/accuracies": 0.5666667222976685,
      "rewards/chosen": 0.08112544566392899,
      "rewards/margins": 0.08153979480266571,
      "rewards/rejected": -0.00041435210732743144,
      "step": 230
    },
    {
      "epoch": 0.070859167404783,
      "grad_norm": 2.9725348949432373,
      "learning_rate": 1.4033392382639504e-05,
      "logits/chosen": 1.1615731716156006,
      "logits/rejected": 1.1560640335083008,
      "logps/chosen": -185.8077392578125,
      "logps/rejected": -186.9185333251953,
      "loss": 0.6222,
      "rewards/accuracies": 0.6833333373069763,
      "rewards/chosen": 0.1949777603149414,
      "rewards/margins": 0.18908299505710602,
      "rewards/rejected": 0.00589474942535162,
      "step": 240
    },
    {
      "epoch": 0.07381163271331562,
      "grad_norm": 4.325450897216797,
      "learning_rate": 1.4030617065249485e-05,
      "logits/chosen": 1.5378572940826416,
      "logits/rejected": 1.5322496891021729,
      "logps/chosen": -188.58370971679688,
      "logps/rejected": -192.54074096679688,
      "loss": 0.6617,
      "rewards/accuracies": 0.5500000715255737,
      "rewards/chosen": 0.24724681675434113,
      "rewards/margins": 0.1351567804813385,
      "rewards/rejected": 0.11209002882242203,
      "step": 250
    },
    {
      "epoch": 0.07676409802184825,
      "grad_norm": 3.1030044555664062,
      "learning_rate": 1.4027841747859464e-05,
      "logits/chosen": 1.2079741954803467,
      "logits/rejected": 1.1819932460784912,
      "logps/chosen": -185.81826782226562,
      "logps/rejected": -193.75759887695312,
      "loss": 0.5707,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": 0.2342633306980133,
      "rewards/margins": 0.31327393651008606,
      "rewards/rejected": -0.07901062816381454,
      "step": 260
    },
    {
      "epoch": 0.07971656333038087,
      "grad_norm": 4.69927978515625,
      "learning_rate": 1.4025066430469443e-05,
      "logits/chosen": 1.6036651134490967,
      "logits/rejected": 1.599760890007019,
      "logps/chosen": -192.2106475830078,
      "logps/rejected": -191.76205444335938,
      "loss": 0.6552,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.25549736618995667,
      "rewards/margins": 0.15238171815872192,
      "rewards/rejected": 0.10311566293239594,
      "step": 270
    },
    {
      "epoch": 0.0826690286389135,
      "grad_norm": 3.630969524383545,
      "learning_rate": 1.4022291113079422e-05,
      "logits/chosen": 1.1886093616485596,
      "logits/rejected": 1.154433012008667,
      "logps/chosen": -183.30165100097656,
      "logps/rejected": -190.86807250976562,
      "loss": 0.5877,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": 0.38790780305862427,
      "rewards/margins": 0.3166651129722595,
      "rewards/rejected": 0.07124273478984833,
      "step": 280
    },
    {
      "epoch": 0.08562149394744611,
      "grad_norm": 4.337339878082275,
      "learning_rate": 1.4019515795689401e-05,
      "logits/chosen": 1.238832712173462,
      "logits/rejected": 1.2280035018920898,
      "logps/chosen": -187.2677459716797,
      "logps/rejected": -191.61102294921875,
      "loss": 0.6071,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": -0.0029330463148653507,
      "rewards/margins": 0.26880979537963867,
      "rewards/rejected": -0.27174288034439087,
      "step": 290
    },
    {
      "epoch": 0.08857395925597875,
      "grad_norm": 3.1550943851470947,
      "learning_rate": 1.4016740478299382e-05,
      "logits/chosen": 0.9376860857009888,
      "logits/rejected": 0.908215343952179,
      "logps/chosen": -189.13121032714844,
      "logps/rejected": -197.40408325195312,
      "loss": 0.5776,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.20738092064857483,
      "rewards/margins": 0.3554242253303528,
      "rewards/rejected": -0.14804331958293915,
      "step": 300
    },
    {
      "epoch": 0.09152642456451136,
      "grad_norm": 5.293827533721924,
      "learning_rate": 1.4013965160909359e-05,
      "logits/chosen": 1.2593042850494385,
      "logits/rejected": 1.2576757669448853,
      "logps/chosen": -193.03384399414062,
      "logps/rejected": -197.1147003173828,
      "loss": 0.5531,
      "rewards/accuracies": 0.7000000476837158,
      "rewards/chosen": 0.012028905563056469,
      "rewards/margins": 0.3902202248573303,
      "rewards/rejected": -0.3781912922859192,
      "step": 310
    },
    {
      "epoch": 0.094478889873044,
      "grad_norm": 5.352402687072754,
      "learning_rate": 1.4011189843519338e-05,
      "logits/chosen": 1.3172454833984375,
      "logits/rejected": 1.321548581123352,
      "logps/chosen": -192.3401336669922,
      "logps/rejected": -196.40338134765625,
      "loss": 0.5783,
      "rewards/accuracies": 0.6999999284744263,
      "rewards/chosen": 0.056578803807497025,
      "rewards/margins": 0.36487430334091187,
      "rewards/rejected": -0.30829551815986633,
      "step": 320
    },
    {
      "epoch": 0.09743135518157661,
      "grad_norm": 10.026690483093262,
      "learning_rate": 1.4008414526129319e-05,
      "logits/chosen": 1.1030714511871338,
      "logits/rejected": 1.1130080223083496,
      "logps/chosen": -192.13851928710938,
      "logps/rejected": -193.59088134765625,
      "loss": 0.6414,
      "rewards/accuracies": 0.6333333253860474,
      "rewards/chosen": 0.055295102298259735,
      "rewards/margins": 0.19160673022270203,
      "rewards/rejected": -0.1363116204738617,
      "step": 330
    },
    {
      "epoch": 0.10038382049010924,
      "grad_norm": 6.331115245819092,
      "learning_rate": 1.4005639208739298e-05,
      "logits/chosen": 1.6091644763946533,
      "logits/rejected": 1.6061195135116577,
      "logps/chosen": -188.35067749023438,
      "logps/rejected": -187.3347625732422,
      "loss": 0.5477,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": 0.4333586096763611,
      "rewards/margins": 0.4175632894039154,
      "rewards/rejected": 0.015795309096574783,
      "step": 340
    },
    {
      "epoch": 0.10333628579864186,
      "grad_norm": 6.189100742340088,
      "learning_rate": 1.4002863891349277e-05,
      "logits/chosen": 1.451856017112732,
      "logits/rejected": 1.4584990739822388,
      "logps/chosen": -195.68283081054688,
      "logps/rejected": -195.28054809570312,
      "loss": 0.6363,
      "rewards/accuracies": 0.6333333253860474,
      "rewards/chosen": -0.3257672190666199,
      "rewards/margins": 0.24154171347618103,
      "rewards/rejected": -0.5673089623451233,
      "step": 350
    },
    {
      "epoch": 0.10628875110717449,
      "grad_norm": 4.33870792388916,
      "learning_rate": 1.4000088573959256e-05,
      "logits/chosen": 1.721693754196167,
      "logits/rejected": 1.7042274475097656,
      "logps/chosen": -195.85984802246094,
      "logps/rejected": -202.40042114257812,
      "loss": 0.5351,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -0.377876341342926,
      "rewards/margins": 0.44985252618789673,
      "rewards/rejected": -0.8277287483215332,
      "step": 360
    },
    {
      "epoch": 0.10924121641570711,
      "grad_norm": 5.9729838371276855,
      "learning_rate": 1.3997313256569237e-05,
      "logits/chosen": 1.7267179489135742,
      "logits/rejected": 1.7092078924179077,
      "logps/chosen": -198.197265625,
      "logps/rejected": -202.08651733398438,
      "loss": 0.6305,
      "rewards/accuracies": 0.6666666269302368,
      "rewards/chosen": -0.4697350859642029,
      "rewards/margins": 0.24590475857257843,
      "rewards/rejected": -0.7156398296356201,
      "step": 370
    },
    {
      "epoch": 0.11219368172423974,
      "grad_norm": 6.878342151641846,
      "learning_rate": 1.3994537939179214e-05,
      "logits/chosen": 1.0931222438812256,
      "logits/rejected": 1.1013003587722778,
      "logps/chosen": -191.40005493164062,
      "logps/rejected": -197.43832397460938,
      "loss": 0.5716,
      "rewards/accuracies": 0.6833333373069763,
      "rewards/chosen": -0.2582472264766693,
      "rewards/margins": 0.45802420377731323,
      "rewards/rejected": -0.7162715196609497,
      "step": 380
    },
    {
      "epoch": 0.11514614703277236,
      "grad_norm": 5.161092281341553,
      "learning_rate": 1.3991762621789194e-05,
      "logits/chosen": 1.1736077070236206,
      "logits/rejected": 1.1796709299087524,
      "logps/chosen": -195.00279235839844,
      "logps/rejected": -198.90708923339844,
      "loss": 0.5535,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -0.21737010776996613,
      "rewards/margins": 0.5003905892372131,
      "rewards/rejected": -0.7177606821060181,
      "step": 390
    },
    {
      "epoch": 0.11809861234130499,
      "grad_norm": 5.3378143310546875,
      "learning_rate": 1.3988987304399174e-05,
      "logits/chosen": 1.6110525131225586,
      "logits/rejected": 1.6213066577911377,
      "logps/chosen": -198.57835388183594,
      "logps/rejected": -197.31871032714844,
      "loss": 0.6375,
      "rewards/accuracies": 0.6833333969116211,
      "rewards/chosen": -0.519882082939148,
      "rewards/margins": 0.3187263607978821,
      "rewards/rejected": -0.8386083841323853,
      "step": 400
    },
    {
      "epoch": 0.12105107764983762,
      "grad_norm": 4.281058311462402,
      "learning_rate": 1.3986211987009153e-05,
      "logits/chosen": 1.7067716121673584,
      "logits/rejected": 1.6785106658935547,
      "logps/chosen": -193.8726348876953,
      "logps/rejected": -195.8690948486328,
      "loss": 0.5377,
      "rewards/accuracies": 0.7666667699813843,
      "rewards/chosen": -0.5168667435646057,
      "rewards/margins": 0.46979039907455444,
      "rewards/rejected": -0.9866571426391602,
      "step": 410
    },
    {
      "epoch": 0.12400354295837024,
      "grad_norm": 6.924513339996338,
      "learning_rate": 1.3983436669619133e-05,
      "logits/chosen": 1.6769517660140991,
      "logits/rejected": 1.6663461923599243,
      "logps/chosen": -197.52024841308594,
      "logps/rejected": -200.78775024414062,
      "loss": 0.5269,
      "rewards/accuracies": 0.7000000476837158,
      "rewards/chosen": -0.3740094304084778,
      "rewards/margins": 0.527606189250946,
      "rewards/rejected": -0.9016156196594238,
      "step": 420
    },
    {
      "epoch": 0.12695600826690287,
      "grad_norm": 5.216395854949951,
      "learning_rate": 1.3980661352229112e-05,
      "logits/chosen": 1.582249402999878,
      "logits/rejected": 1.5770212411880493,
      "logps/chosen": -199.21463012695312,
      "logps/rejected": -200.1426544189453,
      "loss": 0.6883,
      "rewards/accuracies": 0.5833333730697632,
      "rewards/chosen": -0.569111704826355,
      "rewards/margins": 0.1844874918460846,
      "rewards/rejected": -0.7535991668701172,
      "step": 430
    },
    {
      "epoch": 0.1299084735754355,
      "grad_norm": 7.478115558624268,
      "learning_rate": 1.3977886034839092e-05,
      "logits/chosen": 1.4185559749603271,
      "logits/rejected": 1.422137975692749,
      "logps/chosen": -195.01441955566406,
      "logps/rejected": -203.3802032470703,
      "loss": 0.6275,
      "rewards/accuracies": 0.6166666746139526,
      "rewards/chosen": -0.22044813632965088,
      "rewards/margins": 0.3313215374946594,
      "rewards/rejected": -0.5517696738243103,
      "step": 440
    },
    {
      "epoch": 0.1328609388839681,
      "grad_norm": 6.546402454376221,
      "learning_rate": 1.397511071744907e-05,
      "logits/chosen": 1.4084579944610596,
      "logits/rejected": 1.3918402194976807,
      "logps/chosen": -193.29083251953125,
      "logps/rejected": -195.42774963378906,
      "loss": 0.482,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": 0.14833512902259827,
      "rewards/margins": 0.6549378633499146,
      "rewards/rejected": -0.5066027641296387,
      "step": 450
    },
    {
      "epoch": 0.13581340419250074,
      "grad_norm": 7.340824604034424,
      "learning_rate": 1.3972335400059049e-05,
      "logits/chosen": 1.3701339960098267,
      "logits/rejected": 1.3961457014083862,
      "logps/chosen": -200.71026611328125,
      "logps/rejected": -198.08091735839844,
      "loss": 0.6158,
      "rewards/accuracies": 0.5833333730697632,
      "rewards/chosen": -0.45223164558410645,
      "rewards/margins": 0.29829519987106323,
      "rewards/rejected": -0.7505267858505249,
      "step": 460
    },
    {
      "epoch": 0.13876586950103337,
      "grad_norm": 4.373767852783203,
      "learning_rate": 1.396956008266903e-05,
      "logits/chosen": 1.027295470237732,
      "logits/rejected": 1.031782627105713,
      "logps/chosen": -193.41415405273438,
      "logps/rejected": -196.322509765625,
      "loss": 0.5432,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -0.2368394434452057,
      "rewards/margins": 0.5144467949867249,
      "rewards/rejected": -0.7512862086296082,
      "step": 470
    },
    {
      "epoch": 0.141718334809566,
      "grad_norm": 5.2234206199646,
      "learning_rate": 1.3966784765279009e-05,
      "logits/chosen": 1.5841565132141113,
      "logits/rejected": 1.5681902170181274,
      "logps/chosen": -187.58705139160156,
      "logps/rejected": -196.79531860351562,
      "loss": 0.6206,
      "rewards/accuracies": 0.6666666865348816,
      "rewards/chosen": 0.0732032060623169,
      "rewards/margins": 0.3161352574825287,
      "rewards/rejected": -0.2429320514202118,
      "step": 480
    },
    {
      "epoch": 0.1446708001180986,
      "grad_norm": 4.839746952056885,
      "learning_rate": 1.3964009447888988e-05,
      "logits/chosen": 2.0335705280303955,
      "logits/rejected": 2.0044736862182617,
      "logps/chosen": -189.8508758544922,
      "logps/rejected": -192.4295654296875,
      "loss": 0.5505,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": 0.2527107298374176,
      "rewards/margins": 0.4909486174583435,
      "rewards/rejected": -0.23823793232440948,
      "step": 490
    },
    {
      "epoch": 0.14762326542663123,
      "grad_norm": 8.474494934082031,
      "learning_rate": 1.3961234130498967e-05,
      "logits/chosen": 1.5221954584121704,
      "logits/rejected": 1.5036510229110718,
      "logps/chosen": -191.12142944335938,
      "logps/rejected": -197.06878662109375,
      "loss": 0.5878,
      "rewards/accuracies": 0.6833333373069763,
      "rewards/chosen": 0.12255720794200897,
      "rewards/margins": 0.3607734143733978,
      "rewards/rejected": -0.23821623623371124,
      "step": 500
    },
    {
      "epoch": 0.15057573073516387,
      "grad_norm": 5.455799102783203,
      "learning_rate": 1.3958458813108946e-05,
      "logits/chosen": 1.6846637725830078,
      "logits/rejected": 1.6706092357635498,
      "logps/chosen": -187.89956665039062,
      "logps/rejected": -193.3470458984375,
      "loss": 0.5724,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.09783384203910828,
      "rewards/margins": 0.5389536619186401,
      "rewards/rejected": -0.44111984968185425,
      "step": 510
    },
    {
      "epoch": 0.1535281960436965,
      "grad_norm": 9.712525367736816,
      "learning_rate": 1.3955683495718927e-05,
      "logits/chosen": 1.5154314041137695,
      "logits/rejected": 1.5004998445510864,
      "logps/chosen": -193.40211486816406,
      "logps/rejected": -200.68800354003906,
      "loss": 0.5895,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.20585997402668,
      "rewards/margins": 0.43901723623275757,
      "rewards/rejected": -0.6448771357536316,
      "step": 520
    },
    {
      "epoch": 0.1564806613522291,
      "grad_norm": 7.3644561767578125,
      "learning_rate": 1.3952908178328904e-05,
      "logits/chosen": 1.651282548904419,
      "logits/rejected": 1.605571985244751,
      "logps/chosen": -197.5159454345703,
      "logps/rejected": -199.32553100585938,
      "loss": 0.5566,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -0.3843417465686798,
      "rewards/margins": 0.5140015482902527,
      "rewards/rejected": -0.8983432650566101,
      "step": 530
    },
    {
      "epoch": 0.15943312666076173,
      "grad_norm": 6.950796604156494,
      "learning_rate": 1.3950132860938885e-05,
      "logits/chosen": 1.4003444910049438,
      "logits/rejected": 1.3973586559295654,
      "logps/chosen": -197.37171936035156,
      "logps/rejected": -200.85830688476562,
      "loss": 0.5878,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -0.4141266345977783,
      "rewards/margins": 0.4524826109409332,
      "rewards/rejected": -0.8666092157363892,
      "step": 540
    },
    {
      "epoch": 0.16238559196929436,
      "grad_norm": 13.512359619140625,
      "learning_rate": 1.3947357543548864e-05,
      "logits/chosen": 1.71316397190094,
      "logits/rejected": 1.6991745233535767,
      "logps/chosen": -192.09390258789062,
      "logps/rejected": -200.2991180419922,
      "loss": 0.4426,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.31709447503089905,
      "rewards/margins": 0.9771798849105835,
      "rewards/rejected": -1.2942743301391602,
      "step": 550
    },
    {
      "epoch": 0.165338057277827,
      "grad_norm": 7.5016608238220215,
      "learning_rate": 1.3944582226158843e-05,
      "logits/chosen": 1.4190157651901245,
      "logits/rejected": 1.397769570350647,
      "logps/chosen": -196.3062744140625,
      "logps/rejected": -203.023193359375,
      "loss": 0.5747,
      "rewards/accuracies": 0.6666666865348816,
      "rewards/chosen": -0.31903892755508423,
      "rewards/margins": 0.4381542205810547,
      "rewards/rejected": -0.7571932077407837,
      "step": 560
    },
    {
      "epoch": 0.1682905225863596,
      "grad_norm": 8.862321853637695,
      "learning_rate": 1.3941806908768822e-05,
      "logits/chosen": 1.6507947444915771,
      "logits/rejected": 1.634508490562439,
      "logps/chosen": -195.4605712890625,
      "logps/rejected": -203.16168212890625,
      "loss": 0.5491,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.7009005546569824,
      "rewards/margins": 0.5517116189002991,
      "rewards/rejected": -1.2526122331619263,
      "step": 570
    },
    {
      "epoch": 0.17124298789489223,
      "grad_norm": 8.572301864624023,
      "learning_rate": 1.3939031591378801e-05,
      "logits/chosen": 1.5527796745300293,
      "logits/rejected": 1.5554765462875366,
      "logps/chosen": -203.1864471435547,
      "logps/rejected": -209.63589477539062,
      "loss": 0.6382,
      "rewards/accuracies": 0.6333333253860474,
      "rewards/chosen": -0.9296405911445618,
      "rewards/margins": 0.427315890789032,
      "rewards/rejected": -1.3569567203521729,
      "step": 580
    },
    {
      "epoch": 0.17419545320342486,
      "grad_norm": 10.827735900878906,
      "learning_rate": 1.3936256273988782e-05,
      "logits/chosen": 1.607672095298767,
      "logits/rejected": 1.5917370319366455,
      "logps/chosen": -198.20590209960938,
      "logps/rejected": -203.5550994873047,
      "loss": 0.5355,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -0.5957968235015869,
      "rewards/margins": 0.6727001070976257,
      "rewards/rejected": -1.2684969902038574,
      "step": 590
    },
    {
      "epoch": 0.1771479185119575,
      "grad_norm": 5.1767683029174805,
      "learning_rate": 1.393348095659876e-05,
      "logits/chosen": 1.7136447429656982,
      "logits/rejected": 1.7289421558380127,
      "logps/chosen": -203.92312622070312,
      "logps/rejected": -206.67843627929688,
      "loss": 0.5337,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9750642776489258,
      "rewards/margins": 0.631384015083313,
      "rewards/rejected": -1.6064484119415283,
      "step": 600
    },
    {
      "epoch": 0.18010038382049012,
      "grad_norm": 9.803211212158203,
      "learning_rate": 1.393070563920874e-05,
      "logits/chosen": 1.3029720783233643,
      "logits/rejected": 1.2817301750183105,
      "logps/chosen": -196.36660766601562,
      "logps/rejected": -203.23463439941406,
      "loss": 0.5413,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.6328852772712708,
      "rewards/margins": 0.5570027828216553,
      "rewards/rejected": -1.1898878812789917,
      "step": 610
    },
    {
      "epoch": 0.18305284912902273,
      "grad_norm": 8.100458145141602,
      "learning_rate": 1.392793032181872e-05,
      "logits/chosen": 1.6452715396881104,
      "logits/rejected": 1.6206741333007812,
      "logps/chosen": -195.28591918945312,
      "logps/rejected": -202.88424682617188,
      "loss": 0.5552,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": -0.37176576256752014,
      "rewards/margins": 0.6265665292739868,
      "rewards/rejected": -0.9983322024345398,
      "step": 620
    },
    {
      "epoch": 0.18600531443755536,
      "grad_norm": 17.513731002807617,
      "learning_rate": 1.3925155004428697e-05,
      "logits/chosen": 1.6810232400894165,
      "logits/rejected": 1.660459280014038,
      "logps/chosen": -196.9962158203125,
      "logps/rejected": -203.01724243164062,
      "loss": 0.5974,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5827935934066772,
      "rewards/margins": 0.5433915853500366,
      "rewards/rejected": -1.1261851787567139,
      "step": 630
    },
    {
      "epoch": 0.188957779746088,
      "grad_norm": 11.85683536529541,
      "learning_rate": 1.3922379687038678e-05,
      "logits/chosen": 1.4123656749725342,
      "logits/rejected": 1.3985894918441772,
      "logps/chosen": -200.14138793945312,
      "logps/rejected": -199.87423706054688,
      "loss": 0.5524,
      "rewards/accuracies": 0.7000000476837158,
      "rewards/chosen": -0.7585046291351318,
      "rewards/margins": 0.5784589648246765,
      "rewards/rejected": -1.3369635343551636,
      "step": 640
    },
    {
      "epoch": 0.19191024505462062,
      "grad_norm": 13.129853248596191,
      "learning_rate": 1.3919604369648657e-05,
      "logits/chosen": 1.2822368144989014,
      "logits/rejected": 1.2874641418457031,
      "logps/chosen": -193.5782470703125,
      "logps/rejected": -196.95626831054688,
      "loss": 0.5857,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": -0.5862565636634827,
      "rewards/margins": 0.5714415311813354,
      "rewards/rejected": -1.1576982736587524,
      "step": 650
    },
    {
      "epoch": 0.19486271036315322,
      "grad_norm": 6.484643459320068,
      "learning_rate": 1.3916829052258638e-05,
      "logits/chosen": 1.3544518947601318,
      "logits/rejected": 1.3391717672348022,
      "logps/chosen": -197.18270874023438,
      "logps/rejected": -202.9368438720703,
      "loss": 0.5777,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.3226294219493866,
      "rewards/margins": 0.6095346808433533,
      "rewards/rejected": -0.9321640729904175,
      "step": 660
    },
    {
      "epoch": 0.19781517567168586,
      "grad_norm": 15.009284019470215,
      "learning_rate": 1.3914053734868615e-05,
      "logits/chosen": 1.9556468725204468,
      "logits/rejected": 1.9356054067611694,
      "logps/chosen": -194.5548858642578,
      "logps/rejected": -204.35205078125,
      "loss": 0.5849,
      "rewards/accuracies": 0.6500000357627869,
      "rewards/chosen": -0.10491206496953964,
      "rewards/margins": 0.48025745153427124,
      "rewards/rejected": -0.5851696133613586,
      "step": 670
    },
    {
      "epoch": 0.2007676409802185,
      "grad_norm": 11.531158447265625,
      "learning_rate": 1.3911278417478596e-05,
      "logits/chosen": 1.7948713302612305,
      "logits/rejected": 1.7592147588729858,
      "logps/chosen": -202.28526306152344,
      "logps/rejected": -206.9293670654297,
      "loss": 0.5857,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.7145658135414124,
      "rewards/margins": 0.5463818311691284,
      "rewards/rejected": -1.260947585105896,
      "step": 680
    },
    {
      "epoch": 0.20372010628875112,
      "grad_norm": 8.758695602416992,
      "learning_rate": 1.3908503100088575e-05,
      "logits/chosen": 1.654526710510254,
      "logits/rejected": 1.6220977306365967,
      "logps/chosen": -205.5690460205078,
      "logps/rejected": -217.84597778320312,
      "loss": 0.5653,
      "rewards/accuracies": 0.7166666388511658,
      "rewards/chosen": -1.6412239074707031,
      "rewards/margins": 0.5346428751945496,
      "rewards/rejected": -2.1758668422698975,
      "step": 690
    },
    {
      "epoch": 0.20667257159728372,
      "grad_norm": 6.9325947761535645,
      "learning_rate": 1.3905727782698554e-05,
      "logits/chosen": 1.7840909957885742,
      "logits/rejected": 1.7705589532852173,
      "logps/chosen": -203.45840454101562,
      "logps/rejected": -211.3821563720703,
      "loss": 0.5453,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -1.3180232048034668,
      "rewards/margins": 0.5886237025260925,
      "rewards/rejected": -1.906646966934204,
      "step": 700
    },
    {
      "epoch": 0.20962503690581635,
      "grad_norm": 5.255789756774902,
      "learning_rate": 1.3902952465308533e-05,
      "logits/chosen": 1.5460247993469238,
      "logits/rejected": 1.5268275737762451,
      "logps/chosen": -196.31495666503906,
      "logps/rejected": -205.9846954345703,
      "loss": 0.4597,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.4804108142852783,
      "rewards/margins": 0.9415706396102905,
      "rewards/rejected": -1.4219814538955688,
      "step": 710
    },
    {
      "epoch": 0.21257750221434898,
      "grad_norm": 5.02420711517334,
      "learning_rate": 1.3900177147918512e-05,
      "logits/chosen": 1.8122316598892212,
      "logits/rejected": 1.7924606800079346,
      "logps/chosen": -200.14515686035156,
      "logps/rejected": -206.4359588623047,
      "loss": 0.6315,
      "rewards/accuracies": 0.6833333373069763,
      "rewards/chosen": -0.9444215893745422,
      "rewards/margins": 0.559006929397583,
      "rewards/rejected": -1.503428339958191,
      "step": 720
    },
    {
      "epoch": 0.21552996752288162,
      "grad_norm": 7.677519798278809,
      "learning_rate": 1.3897401830528493e-05,
      "logits/chosen": 1.045641303062439,
      "logits/rejected": 1.0404492616653442,
      "logps/chosen": -207.1392364501953,
      "logps/rejected": -212.0641632080078,
      "loss": 0.6271,
      "rewards/accuracies": 0.6333333253860474,
      "rewards/chosen": -1.9417740106582642,
      "rewards/margins": 0.3787049651145935,
      "rewards/rejected": -2.320478916168213,
      "step": 730
    },
    {
      "epoch": 0.21848243283141422,
      "grad_norm": 4.300086498260498,
      "learning_rate": 1.389462651313847e-05,
      "logits/chosen": 1.6318432092666626,
      "logits/rejected": 1.5932117700576782,
      "logps/chosen": -217.016357421875,
      "logps/rejected": -219.87918090820312,
      "loss": 0.4817,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.1930506229400635,
      "rewards/margins": 0.7295680642127991,
      "rewards/rejected": -2.9226186275482178,
      "step": 740
    },
    {
      "epoch": 0.22143489813994685,
      "grad_norm": 8.665371894836426,
      "learning_rate": 1.3891851195748451e-05,
      "logits/chosen": 1.3674259185791016,
      "logits/rejected": 1.3547977209091187,
      "logps/chosen": -216.1984100341797,
      "logps/rejected": -223.07373046875,
      "loss": 0.5746,
      "rewards/accuracies": 0.6833333373069763,
      "rewards/chosen": -2.12206768989563,
      "rewards/margins": 0.5470091104507446,
      "rewards/rejected": -2.669076681137085,
      "step": 750
    },
    {
      "epoch": 0.22438736344847948,
      "grad_norm": 8.332193374633789,
      "learning_rate": 1.388907587835843e-05,
      "logits/chosen": 1.9906949996948242,
      "logits/rejected": 1.9765859842300415,
      "logps/chosen": -213.06509399414062,
      "logps/rejected": -218.3328857421875,
      "loss": 0.5744,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": -1.9199966192245483,
      "rewards/margins": 0.6769169569015503,
      "rewards/rejected": -2.5969138145446777,
      "step": 760
    },
    {
      "epoch": 0.2273398287570121,
      "grad_norm": 6.103339672088623,
      "learning_rate": 1.388630056096841e-05,
      "logits/chosen": 1.928613305091858,
      "logits/rejected": 1.9054968357086182,
      "logps/chosen": -200.99964904785156,
      "logps/rejected": -209.3754119873047,
      "loss": 0.5345,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.1689717769622803,
      "rewards/margins": 0.7331969141960144,
      "rewards/rejected": -1.90216863155365,
      "step": 770
    },
    {
      "epoch": 0.23029229406554472,
      "grad_norm": 6.418448448181152,
      "learning_rate": 1.3883525243578388e-05,
      "logits/chosen": 1.4570674896240234,
      "logits/rejected": 1.4235891103744507,
      "logps/chosen": -200.81253051757812,
      "logps/rejected": -211.59170532226562,
      "loss": 0.5046,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -1.007707953453064,
      "rewards/margins": 0.8069156408309937,
      "rewards/rejected": -1.8146235942840576,
      "step": 780
    },
    {
      "epoch": 0.23324475937407735,
      "grad_norm": 8.33934497833252,
      "learning_rate": 1.3880749926188367e-05,
      "logits/chosen": 1.5619279146194458,
      "logits/rejected": 1.5374114513397217,
      "logps/chosen": -203.60739135742188,
      "logps/rejected": -211.75296020507812,
      "loss": 0.4851,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -1.087677001953125,
      "rewards/margins": 0.9038565754890442,
      "rewards/rejected": -1.991533637046814,
      "step": 790
    },
    {
      "epoch": 0.23619722468260998,
      "grad_norm": 5.138166427612305,
      "learning_rate": 1.3877974608798348e-05,
      "logits/chosen": 1.9492590427398682,
      "logits/rejected": 1.931825876235962,
      "logps/chosen": -201.5854034423828,
      "logps/rejected": -209.51974487304688,
      "loss": 0.5435,
      "rewards/accuracies": 0.7166666388511658,
      "rewards/chosen": -1.1496951580047607,
      "rewards/margins": 0.755763590335846,
      "rewards/rejected": -1.9054588079452515,
      "step": 800
    },
    {
      "epoch": 0.2391496899911426,
      "grad_norm": 10.359140396118164,
      "learning_rate": 1.3875199291408326e-05,
      "logits/chosen": 1.820840835571289,
      "logits/rejected": 1.8106231689453125,
      "logps/chosen": -203.36721801757812,
      "logps/rejected": -212.40322875976562,
      "loss": 0.5742,
      "rewards/accuracies": 0.6666666269302368,
      "rewards/chosen": -1.1280142068862915,
      "rewards/margins": 0.7798991203308105,
      "rewards/rejected": -1.9079134464263916,
      "step": 810
    },
    {
      "epoch": 0.24210215529967524,
      "grad_norm": 9.49273681640625,
      "learning_rate": 1.3872423974018305e-05,
      "logits/chosen": 1.947005271911621,
      "logits/rejected": 1.9435631036758423,
      "logps/chosen": -207.2179412841797,
      "logps/rejected": -214.86788940429688,
      "loss": 0.4776,
      "rewards/accuracies": 0.7333332896232605,
      "rewards/chosen": -1.1342576742172241,
      "rewards/margins": 0.8822417259216309,
      "rewards/rejected": -2.0164995193481445,
      "step": 820
    },
    {
      "epoch": 0.24505462060820785,
      "grad_norm": 7.151697158813477,
      "learning_rate": 1.3869648656628285e-05,
      "logits/chosen": 1.7463388442993164,
      "logits/rejected": 1.6956487894058228,
      "logps/chosen": -209.41506958007812,
      "logps/rejected": -221.5378875732422,
      "loss": 0.4828,
      "rewards/accuracies": 0.7666667699813843,
      "rewards/chosen": -1.4422399997711182,
      "rewards/margins": 0.7942317128181458,
      "rewards/rejected": -2.236471652984619,
      "step": 830
    },
    {
      "epoch": 0.24800708591674048,
      "grad_norm": 8.914382934570312,
      "learning_rate": 1.3866873339238265e-05,
      "logits/chosen": 1.6714146137237549,
      "logits/rejected": 1.646619439125061,
      "logps/chosen": -205.0666046142578,
      "logps/rejected": -207.4016571044922,
      "loss": 0.5002,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -1.0493441820144653,
      "rewards/margins": 0.8461869359016418,
      "rewards/rejected": -1.8955309391021729,
      "step": 840
    },
    {
      "epoch": 0.2509595512252731,
      "grad_norm": 7.256534576416016,
      "learning_rate": 1.3864098021848244e-05,
      "logits/chosen": 2.1807210445404053,
      "logits/rejected": 2.1766488552093506,
      "logps/chosen": -198.8083953857422,
      "logps/rejected": -208.1200714111328,
      "loss": 0.5044,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -1.16326105594635,
      "rewards/margins": 0.8944520950317383,
      "rewards/rejected": -2.057713031768799,
      "step": 850
    },
    {
      "epoch": 0.25391201653380574,
      "grad_norm": 9.827410697937012,
      "learning_rate": 1.3861322704458223e-05,
      "logits/chosen": 1.2667344808578491,
      "logits/rejected": 1.2566596269607544,
      "logps/chosen": -208.36416625976562,
      "logps/rejected": -217.05545043945312,
      "loss": 0.5421,
      "rewards/accuracies": 0.6666666269302368,
      "rewards/chosen": -1.1700646877288818,
      "rewards/margins": 0.8592768907546997,
      "rewards/rejected": -2.029341697692871,
      "step": 860
    },
    {
      "epoch": 0.25686448184233834,
      "grad_norm": 9.706259727478027,
      "learning_rate": 1.3858547387068204e-05,
      "logits/chosen": 1.587172031402588,
      "logits/rejected": 1.560068130493164,
      "logps/chosen": -199.06927490234375,
      "logps/rejected": -210.4639892578125,
      "loss": 0.4636,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.101255178451538,
      "rewards/margins": 0.9410642385482788,
      "rewards/rejected": -2.0423197746276855,
      "step": 870
    },
    {
      "epoch": 0.259816947150871,
      "grad_norm": 7.526109218597412,
      "learning_rate": 1.3855772069678183e-05,
      "logits/chosen": 1.9598249197006226,
      "logits/rejected": 1.923606514930725,
      "logps/chosen": -212.5594024658203,
      "logps/rejected": -219.98583984375,
      "loss": 0.5473,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.8117889165878296,
      "rewards/margins": 0.8612030148506165,
      "rewards/rejected": -2.6729917526245117,
      "step": 880
    },
    {
      "epoch": 0.2627694124594036,
      "grad_norm": 9.555264472961426,
      "learning_rate": 1.385299675228816e-05,
      "logits/chosen": 1.4182078838348389,
      "logits/rejected": 1.3990509510040283,
      "logps/chosen": -209.5186767578125,
      "logps/rejected": -221.25466918945312,
      "loss": 0.5549,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -2.3261451721191406,
      "rewards/margins": 0.7999902367591858,
      "rewards/rejected": -3.1261353492736816,
      "step": 890
    },
    {
      "epoch": 0.2657218777679362,
      "grad_norm": 7.747138500213623,
      "learning_rate": 1.385022143489814e-05,
      "logits/chosen": 2.2562527656555176,
      "logits/rejected": 2.2515735626220703,
      "logps/chosen": -213.87930297851562,
      "logps/rejected": -224.92611694335938,
      "loss": 0.5679,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": -2.6030449867248535,
      "rewards/margins": 0.6296696066856384,
      "rewards/rejected": -3.232714891433716,
      "step": 900
    },
    {
      "epoch": 0.26867434307646887,
      "grad_norm": 10.982300758361816,
      "learning_rate": 1.384744611750812e-05,
      "logits/chosen": 1.9108693599700928,
      "logits/rejected": 1.9344346523284912,
      "logps/chosen": -214.9486846923828,
      "logps/rejected": -222.2103271484375,
      "loss": 0.4867,
      "rewards/accuracies": 0.73333340883255,
      "rewards/chosen": -1.9787464141845703,
      "rewards/margins": 1.0253312587738037,
      "rewards/rejected": -3.004077911376953,
      "step": 910
    },
    {
      "epoch": 0.2716268083850015,
      "grad_norm": 10.776519775390625,
      "learning_rate": 1.3844670800118099e-05,
      "logits/chosen": 2.1133971214294434,
      "logits/rejected": 2.0974297523498535,
      "logps/chosen": -213.1396026611328,
      "logps/rejected": -223.69729614257812,
      "loss": 0.5238,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -2.2478902339935303,
      "rewards/margins": 0.9503337740898132,
      "rewards/rejected": -3.1982243061065674,
      "step": 920
    },
    {
      "epoch": 0.2745792736935341,
      "grad_norm": 10.14970588684082,
      "learning_rate": 1.3841895482728078e-05,
      "logits/chosen": 1.256277322769165,
      "logits/rejected": 1.2374504804611206,
      "logps/chosen": -216.58889770507812,
      "logps/rejected": -223.6951141357422,
      "loss": 0.5859,
      "rewards/accuracies": 0.6833332777023315,
      "rewards/chosen": -2.5083537101745605,
      "rewards/margins": 0.841750979423523,
      "rewards/rejected": -3.3501052856445312,
      "step": 930
    },
    {
      "epoch": 0.27753173900206674,
      "grad_norm": 5.421786308288574,
      "learning_rate": 1.3839120165338059e-05,
      "logits/chosen": 2.100062131881714,
      "logits/rejected": 2.0663318634033203,
      "logps/chosen": -214.3224639892578,
      "logps/rejected": -225.01339721679688,
      "loss": 0.5295,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.4520602226257324,
      "rewards/margins": 1.0149857997894287,
      "rewards/rejected": -3.4670462608337402,
      "step": 940
    },
    {
      "epoch": 0.28048420431059934,
      "grad_norm": 15.477884292602539,
      "learning_rate": 1.3836344847948038e-05,
      "logits/chosen": 2.082733392715454,
      "logits/rejected": 2.0627031326293945,
      "logps/chosen": -219.08181762695312,
      "logps/rejected": -225.2157440185547,
      "loss": 0.5279,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -2.5814857482910156,
      "rewards/margins": 0.8895920515060425,
      "rewards/rejected": -3.4710781574249268,
      "step": 950
    },
    {
      "epoch": 0.283436669619132,
      "grad_norm": 5.351193428039551,
      "learning_rate": 1.3833569530558015e-05,
      "logits/chosen": 1.722224473953247,
      "logits/rejected": 1.6951875686645508,
      "logps/chosen": -213.6050262451172,
      "logps/rejected": -221.3406524658203,
      "loss": 0.4873,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -1.5938340425491333,
      "rewards/margins": 0.9869332313537598,
      "rewards/rejected": -2.5807671546936035,
      "step": 960
    },
    {
      "epoch": 0.2863891349276646,
      "grad_norm": 10.514854431152344,
      "learning_rate": 1.3830794213167996e-05,
      "logits/chosen": 1.3077778816223145,
      "logits/rejected": 1.307377815246582,
      "logps/chosen": -207.8743438720703,
      "logps/rejected": -213.96475219726562,
      "loss": 0.6194,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": -1.8218564987182617,
      "rewards/margins": 0.6280580759048462,
      "rewards/rejected": -2.4499144554138184,
      "step": 970
    },
    {
      "epoch": 0.2893416002361972,
      "grad_norm": 14.9252290725708,
      "learning_rate": 1.3828018895777975e-05,
      "logits/chosen": 1.6916170120239258,
      "logits/rejected": 1.6623926162719727,
      "logps/chosen": -204.11453247070312,
      "logps/rejected": -218.81735229492188,
      "loss": 0.5994,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -1.5576375722885132,
      "rewards/margins": 0.7740439176559448,
      "rewards/rejected": -2.331681489944458,
      "step": 980
    },
    {
      "epoch": 0.29229406554472986,
      "grad_norm": 6.4273457527160645,
      "learning_rate": 1.3825243578387954e-05,
      "logits/chosen": 1.7818095684051514,
      "logits/rejected": 1.7813279628753662,
      "logps/chosen": -204.68600463867188,
      "logps/rejected": -217.4008331298828,
      "loss": 0.5894,
      "rewards/accuracies": 0.6666666269302368,
      "rewards/chosen": -1.725433349609375,
      "rewards/margins": 0.7360233068466187,
      "rewards/rejected": -2.461456537246704,
      "step": 990
    },
    {
      "epoch": 0.29524653085326247,
      "grad_norm": 10.012327194213867,
      "learning_rate": 1.3822468260997933e-05,
      "logits/chosen": 2.072169542312622,
      "logits/rejected": 2.065290927886963,
      "logps/chosen": -213.41702270507812,
      "logps/rejected": -222.50375366210938,
      "loss": 0.5415,
      "rewards/accuracies": 0.7166666388511658,
      "rewards/chosen": -2.2047152519226074,
      "rewards/margins": 0.6676673889160156,
      "rewards/rejected": -2.872382640838623,
      "step": 1000
    },
    {
      "epoch": 0.29819899616179507,
      "grad_norm": 11.485982894897461,
      "learning_rate": 1.3819692943607913e-05,
      "logits/chosen": 1.6578937768936157,
      "logits/rejected": 1.652907133102417,
      "logps/chosen": -218.9358367919922,
      "logps/rejected": -227.8074493408203,
      "loss": 0.5169,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.855656623840332,
      "rewards/margins": 1.0421665906906128,
      "rewards/rejected": -3.8978238105773926,
      "step": 1010
    },
    {
      "epoch": 0.30115146147032773,
      "grad_norm": 7.439169406890869,
      "learning_rate": 1.3816917626217893e-05,
      "logits/chosen": 1.8739023208618164,
      "logits/rejected": 1.8308055400848389,
      "logps/chosen": -217.2263641357422,
      "logps/rejected": -228.4720001220703,
      "loss": 0.5313,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.5108461380004883,
      "rewards/margins": 0.8468034863471985,
      "rewards/rejected": -3.357649564743042,
      "step": 1020
    },
    {
      "epoch": 0.30410392677886033,
      "grad_norm": 9.529221534729004,
      "learning_rate": 1.381414230882787e-05,
      "logits/chosen": 1.9741023778915405,
      "logits/rejected": 1.9687042236328125,
      "logps/chosen": -212.3037109375,
      "logps/rejected": -229.2590789794922,
      "loss": 0.324,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.9908777475357056,
      "rewards/margins": 1.6339921951293945,
      "rewards/rejected": -3.6248695850372314,
      "step": 1030
    },
    {
      "epoch": 0.307056392087393,
      "grad_norm": 14.02534008026123,
      "learning_rate": 1.3811366991437851e-05,
      "logits/chosen": 1.7309894561767578,
      "logits/rejected": 1.722938895225525,
      "logps/chosen": -214.36196899414062,
      "logps/rejected": -222.6759796142578,
      "loss": 0.5693,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.339090347290039,
      "rewards/margins": 1.0474903583526611,
      "rewards/rejected": -3.3865807056427,
      "step": 1040
    },
    {
      "epoch": 0.3100088573959256,
      "grad_norm": 16.860857009887695,
      "learning_rate": 1.380859167404783e-05,
      "logits/chosen": 1.4350665807724,
      "logits/rejected": 1.4386931657791138,
      "logps/chosen": -221.4638671875,
      "logps/rejected": -232.4891815185547,
      "loss": 0.4943,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -2.4540696144104004,
      "rewards/margins": 1.0868152379989624,
      "rewards/rejected": -3.5408847332000732,
      "step": 1050
    },
    {
      "epoch": 0.3129613227044582,
      "grad_norm": 6.349522113800049,
      "learning_rate": 1.380581635665781e-05,
      "logits/chosen": 1.9555385112762451,
      "logits/rejected": 1.939695954322815,
      "logps/chosen": -215.0701141357422,
      "logps/rejected": -228.73526000976562,
      "loss": 0.4948,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -2.744551658630371,
      "rewards/margins": 1.2981369495391846,
      "rewards/rejected": -4.042688369750977,
      "step": 1060
    },
    {
      "epoch": 0.31591378801299086,
      "grad_norm": 17.8336124420166,
      "learning_rate": 1.3803041039267789e-05,
      "logits/chosen": 1.732016921043396,
      "logits/rejected": 1.7191989421844482,
      "logps/chosen": -219.24044799804688,
      "logps/rejected": -232.5294952392578,
      "loss": 0.4507,
      "rewards/accuracies": 0.8000000715255737,
      "rewards/chosen": -2.580195903778076,
      "rewards/margins": 1.3831874132156372,
      "rewards/rejected": -3.963383197784424,
      "step": 1070
    },
    {
      "epoch": 0.31886625332152346,
      "grad_norm": 3.9702541828155518,
      "learning_rate": 1.3800265721877768e-05,
      "logits/chosen": 1.9763418436050415,
      "logits/rejected": 1.95572030544281,
      "logps/chosen": -220.8898468017578,
      "logps/rejected": -233.2143096923828,
      "loss": 0.7277,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -3.104234218597412,
      "rewards/margins": 0.845171332359314,
      "rewards/rejected": -3.9494051933288574,
      "step": 1080
    },
    {
      "epoch": 0.3218187186300561,
      "grad_norm": 12.855263710021973,
      "learning_rate": 1.3797490404487749e-05,
      "logits/chosen": 1.8954505920410156,
      "logits/rejected": 1.8821500539779663,
      "logps/chosen": -220.39614868164062,
      "logps/rejected": -228.66812133789062,
      "loss": 0.4637,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.870349407196045,
      "rewards/margins": 1.136059045791626,
      "rewards/rejected": -4.006407737731934,
      "step": 1090
    },
    {
      "epoch": 0.3247711839385887,
      "grad_norm": 21.506155014038086,
      "learning_rate": 1.3794715087097726e-05,
      "logits/chosen": 1.7802226543426514,
      "logits/rejected": 1.7805248498916626,
      "logps/chosen": -211.2801971435547,
      "logps/rejected": -226.8338623046875,
      "loss": 0.4927,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.4609179496765137,
      "rewards/margins": 1.1869043111801147,
      "rewards/rejected": -3.647822141647339,
      "step": 1100
    },
    {
      "epoch": 0.32772364924712133,
      "grad_norm": 5.560802936553955,
      "learning_rate": 1.3791939769707707e-05,
      "logits/chosen": 1.980316162109375,
      "logits/rejected": 1.980513334274292,
      "logps/chosen": -219.9320068359375,
      "logps/rejected": -231.6981201171875,
      "loss": 0.4685,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.5042405128479004,
      "rewards/margins": 1.2848763465881348,
      "rewards/rejected": -3.7891170978546143,
      "step": 1110
    },
    {
      "epoch": 0.330676114555654,
      "grad_norm": 12.213945388793945,
      "learning_rate": 1.3789164452317686e-05,
      "logits/chosen": 2.115111827850342,
      "logits/rejected": 2.1002206802368164,
      "logps/chosen": -221.154541015625,
      "logps/rejected": -229.95828247070312,
      "loss": 0.578,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.5855820178985596,
      "rewards/margins": 0.7789326906204224,
      "rewards/rejected": -3.3645145893096924,
      "step": 1120
    },
    {
      "epoch": 0.3336285798641866,
      "grad_norm": 8.087267875671387,
      "learning_rate": 1.3786389134927667e-05,
      "logits/chosen": 2.16579008102417,
      "logits/rejected": 2.1590890884399414,
      "logps/chosen": -214.2847900390625,
      "logps/rejected": -222.20614624023438,
      "loss": 0.5636,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": -2.05302095413208,
      "rewards/margins": 0.8976022601127625,
      "rewards/rejected": -2.950623035430908,
      "step": 1130
    },
    {
      "epoch": 0.3365810451727192,
      "grad_norm": 8.870088577270508,
      "learning_rate": 1.3783613817537644e-05,
      "logits/chosen": 2.4099674224853516,
      "logits/rejected": 2.406712293624878,
      "logps/chosen": -218.5517120361328,
      "logps/rejected": -226.0723114013672,
      "loss": 0.5312,
      "rewards/accuracies": 0.7166666388511658,
      "rewards/chosen": -2.0577595233917236,
      "rewards/margins": 0.9043012857437134,
      "rewards/rejected": -2.9620609283447266,
      "step": 1140
    },
    {
      "epoch": 0.33953351048125185,
      "grad_norm": 11.521981239318848,
      "learning_rate": 1.3780838500147623e-05,
      "logits/chosen": 1.8213729858398438,
      "logits/rejected": 1.7872745990753174,
      "logps/chosen": -218.8849334716797,
      "logps/rejected": -231.4100799560547,
      "loss": 0.4788,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.8948044776916504,
      "rewards/margins": 1.2837425470352173,
      "rewards/rejected": -4.178546905517578,
      "step": 1150
    },
    {
      "epoch": 0.34248597578978446,
      "grad_norm": 5.543089389801025,
      "learning_rate": 1.3778063182757604e-05,
      "logits/chosen": 1.6957380771636963,
      "logits/rejected": 1.687414526939392,
      "logps/chosen": -228.29525756835938,
      "logps/rejected": -240.8555908203125,
      "loss": 0.5282,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -3.2915797233581543,
      "rewards/margins": 0.9044113159179688,
      "rewards/rejected": -4.195991516113281,
      "step": 1160
    },
    {
      "epoch": 0.3454384410983171,
      "grad_norm": 13.544578552246094,
      "learning_rate": 1.3775287865367581e-05,
      "logits/chosen": 1.850188970565796,
      "logits/rejected": 1.835333228111267,
      "logps/chosen": -230.42709350585938,
      "logps/rejected": -236.2783966064453,
      "loss": 0.5726,
      "rewards/accuracies": 0.6833333969116211,
      "rewards/chosen": -3.8688015937805176,
      "rewards/margins": 0.6987537145614624,
      "rewards/rejected": -4.567554950714111,
      "step": 1170
    },
    {
      "epoch": 0.3483909064068497,
      "grad_norm": 13.035003662109375,
      "learning_rate": 1.3772512547977562e-05,
      "logits/chosen": 1.7601511478424072,
      "logits/rejected": 1.754481315612793,
      "logps/chosen": -217.6327362060547,
      "logps/rejected": -235.26278686523438,
      "loss": 0.4613,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.7457189559936523,
      "rewards/margins": 1.2735373973846436,
      "rewards/rejected": -4.019256114959717,
      "step": 1180
    },
    {
      "epoch": 0.3513433717153823,
      "grad_norm": 5.458191394805908,
      "learning_rate": 1.3769737230587541e-05,
      "logits/chosen": 2.1032357215881348,
      "logits/rejected": 2.1085989475250244,
      "logps/chosen": -218.1141357421875,
      "logps/rejected": -226.9083709716797,
      "loss": 0.5658,
      "rewards/accuracies": 0.6666666269302368,
      "rewards/chosen": -2.3842384815216064,
      "rewards/margins": 0.8993189930915833,
      "rewards/rejected": -3.283557415008545,
      "step": 1190
    },
    {
      "epoch": 0.354295837023915,
      "grad_norm": 12.18082046508789,
      "learning_rate": 1.376696191319752e-05,
      "logits/chosen": 2.082583427429199,
      "logits/rejected": 2.0681283473968506,
      "logps/chosen": -216.634033203125,
      "logps/rejected": -229.59848022460938,
      "loss": 0.4585,
      "rewards/accuracies": 0.8000000715255737,
      "rewards/chosen": -2.401216983795166,
      "rewards/margins": 1.360975980758667,
      "rewards/rejected": -3.762192487716675,
      "step": 1200
    },
    {
      "epoch": 0.3572483023324476,
      "grad_norm": 10.940686225891113,
      "learning_rate": 1.37641865958075e-05,
      "logits/chosen": 2.0348174571990967,
      "logits/rejected": 1.9974712133407593,
      "logps/chosen": -208.80331420898438,
      "logps/rejected": -224.99911499023438,
      "loss": 0.485,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -2.2392098903656006,
      "rewards/margins": 1.4007337093353271,
      "rewards/rejected": -3.6399435997009277,
      "step": 1210
    },
    {
      "epoch": 0.36020076764098025,
      "grad_norm": 11.344941139221191,
      "learning_rate": 1.3761411278417479e-05,
      "logits/chosen": 1.4156608581542969,
      "logits/rejected": 1.3916361331939697,
      "logps/chosen": -221.9427032470703,
      "logps/rejected": -233.4093017578125,
      "loss": 0.5148,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -2.602412700653076,
      "rewards/margins": 1.2618510723114014,
      "rewards/rejected": -3.8642640113830566,
      "step": 1220
    },
    {
      "epoch": 0.36315323294951285,
      "grad_norm": 7.801835060119629,
      "learning_rate": 1.375863596102746e-05,
      "logits/chosen": 1.80277419090271,
      "logits/rejected": 1.7832691669464111,
      "logps/chosen": -211.4281463623047,
      "logps/rejected": -219.17129516601562,
      "loss": 0.6266,
      "rewards/accuracies": 0.6833332777023315,
      "rewards/chosen": -1.983661413192749,
      "rewards/margins": 0.8334311246871948,
      "rewards/rejected": -2.8170924186706543,
      "step": 1230
    },
    {
      "epoch": 0.36610569825804545,
      "grad_norm": 10.663352966308594,
      "learning_rate": 1.3755860643637437e-05,
      "logits/chosen": 2.0886025428771973,
      "logits/rejected": 2.0843446254730225,
      "logps/chosen": -202.31692504882812,
      "logps/rejected": -212.079833984375,
      "loss": 0.5593,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -1.3286370038986206,
      "rewards/margins": 0.7676858901977539,
      "rewards/rejected": -2.096322774887085,
      "step": 1240
    },
    {
      "epoch": 0.3690581635665781,
      "grad_norm": 10.333218574523926,
      "learning_rate": 1.3753085326247417e-05,
      "logits/chosen": 2.266921043395996,
      "logits/rejected": 2.2500052452087402,
      "logps/chosen": -205.0960693359375,
      "logps/rejected": -213.87637329101562,
      "loss": 0.5461,
      "rewards/accuracies": 0.7166666388511658,
      "rewards/chosen": -1.557697057723999,
      "rewards/margins": 0.7934540510177612,
      "rewards/rejected": -2.35115122795105,
      "step": 1250
    },
    {
      "epoch": 0.3720106288751107,
      "grad_norm": 6.346786022186279,
      "learning_rate": 1.3750310008857397e-05,
      "logits/chosen": 1.9328693151474,
      "logits/rejected": 1.8828283548355103,
      "logps/chosen": -212.33773803710938,
      "logps/rejected": -235.36471557617188,
      "loss": 0.412,
      "rewards/accuracies": 0.8166667819023132,
      "rewards/chosen": -2.4529500007629395,
      "rewards/margins": 1.2962747812271118,
      "rewards/rejected": -3.749224901199341,
      "step": 1260
    },
    {
      "epoch": 0.3749630941836433,
      "grad_norm": 6.169670104980469,
      "learning_rate": 1.3747534691467376e-05,
      "logits/chosen": 1.1433370113372803,
      "logits/rejected": 1.1611034870147705,
      "logps/chosen": -221.8472900390625,
      "logps/rejected": -227.82937622070312,
      "loss": 0.574,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -2.9512619972229004,
      "rewards/margins": 0.8556710481643677,
      "rewards/rejected": -3.8069329261779785,
      "step": 1270
    },
    {
      "epoch": 0.377915559492176,
      "grad_norm": 12.513062477111816,
      "learning_rate": 1.3744759374077355e-05,
      "logits/chosen": 1.6488815546035767,
      "logits/rejected": 1.6456187963485718,
      "logps/chosen": -221.9256134033203,
      "logps/rejected": -227.60696411132812,
      "loss": 0.5024,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.9174017906188965,
      "rewards/margins": 1.0509783029556274,
      "rewards/rejected": -3.9683804512023926,
      "step": 1280
    },
    {
      "epoch": 0.3808680248007086,
      "grad_norm": 17.250574111938477,
      "learning_rate": 1.3741984056687334e-05,
      "logits/chosen": 1.6531445980072021,
      "logits/rejected": 1.6497787237167358,
      "logps/chosen": -225.02810668945312,
      "logps/rejected": -230.06448364257812,
      "loss": 0.7343,
      "rewards/accuracies": 0.5333333611488342,
      "rewards/chosen": -3.2623162269592285,
      "rewards/margins": 0.49406471848487854,
      "rewards/rejected": -3.7563815116882324,
      "step": 1290
    },
    {
      "epoch": 0.38382049010924124,
      "grad_norm": 13.133663177490234,
      "learning_rate": 1.3739208739297315e-05,
      "logits/chosen": 2.0162134170532227,
      "logits/rejected": 1.9927009344100952,
      "logps/chosen": -224.71884155273438,
      "logps/rejected": -229.5316619873047,
      "loss": 0.4748,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -3.0771050453186035,
      "rewards/margins": 1.062684416770935,
      "rewards/rejected": -4.139789581298828,
      "step": 1300
    },
    {
      "epoch": 0.38677295541777384,
      "grad_norm": 10.483170509338379,
      "learning_rate": 1.3736433421907294e-05,
      "logits/chosen": 1.5577936172485352,
      "logits/rejected": 1.5437971353530884,
      "logps/chosen": -220.3124542236328,
      "logps/rejected": -230.45034790039062,
      "loss": 0.5577,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.8609237670898438,
      "rewards/margins": 0.9044517278671265,
      "rewards/rejected": -3.7653756141662598,
      "step": 1310
    },
    {
      "epoch": 0.38972542072630645,
      "grad_norm": 6.518091201782227,
      "learning_rate": 1.3733658104517273e-05,
      "logits/chosen": 1.8137454986572266,
      "logits/rejected": 1.8029327392578125,
      "logps/chosen": -217.33517456054688,
      "logps/rejected": -228.5708465576172,
      "loss": 0.5361,
      "rewards/accuracies": 0.6666666269302368,
      "rewards/chosen": -2.175438642501831,
      "rewards/margins": 1.0663999319076538,
      "rewards/rejected": -3.2418389320373535,
      "step": 1320
    },
    {
      "epoch": 0.3926778860348391,
      "grad_norm": 8.882863998413086,
      "learning_rate": 1.3730882787127252e-05,
      "logits/chosen": 1.6356346607208252,
      "logits/rejected": 1.637589693069458,
      "logps/chosen": -202.528076171875,
      "logps/rejected": -211.1672821044922,
      "loss": 0.4934,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4117660522460938,
      "rewards/margins": 0.8523308634757996,
      "rewards/rejected": -2.264096975326538,
      "step": 1330
    },
    {
      "epoch": 0.3956303513433717,
      "grad_norm": 12.818718910217285,
      "learning_rate": 1.3728107469737231e-05,
      "logits/chosen": 1.8591057062149048,
      "logits/rejected": 1.8289158344268799,
      "logps/chosen": -208.8351287841797,
      "logps/rejected": -221.6759033203125,
      "loss": 0.5102,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -1.6498727798461914,
      "rewards/margins": 1.1612746715545654,
      "rewards/rejected": -2.8111472129821777,
      "step": 1340
    },
    {
      "epoch": 0.3985828166519043,
      "grad_norm": 7.211512565612793,
      "learning_rate": 1.372533215234721e-05,
      "logits/chosen": 1.5977344512939453,
      "logits/rejected": 1.5836025476455688,
      "logps/chosen": -211.8744659423828,
      "logps/rejected": -221.554931640625,
      "loss": 0.6129,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -1.9586708545684814,
      "rewards/margins": 1.0027716159820557,
      "rewards/rejected": -2.961442470550537,
      "step": 1350
    },
    {
      "epoch": 0.401535281960437,
      "grad_norm": 5.497565269470215,
      "learning_rate": 1.372255683495719e-05,
      "logits/chosen": 2.093667984008789,
      "logits/rejected": 2.0454821586608887,
      "logps/chosen": -214.49874877929688,
      "logps/rejected": -228.67825317382812,
      "loss": 0.4172,
      "rewards/accuracies": 0.8666667938232422,
      "rewards/chosen": -2.2145543098449707,
      "rewards/margins": 1.3450396060943604,
      "rewards/rejected": -3.559593677520752,
      "step": 1360
    },
    {
      "epoch": 0.4044877472689696,
      "grad_norm": 12.209760665893555,
      "learning_rate": 1.371978151756717e-05,
      "logits/chosen": 1.842495322227478,
      "logits/rejected": 1.803160309791565,
      "logps/chosen": -212.26327514648438,
      "logps/rejected": -226.1024627685547,
      "loss": 0.4916,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -2.247070789337158,
      "rewards/margins": 1.2144203186035156,
      "rewards/rejected": -3.461491346359253,
      "step": 1370
    },
    {
      "epoch": 0.40744021257750224,
      "grad_norm": 8.238576889038086,
      "learning_rate": 1.3717006200177149e-05,
      "logits/chosen": 1.5510226488113403,
      "logits/rejected": 1.509584665298462,
      "logps/chosen": -206.6161346435547,
      "logps/rejected": -220.59521484375,
      "loss": 0.5904,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -1.8386774063110352,
      "rewards/margins": 1.0830117464065552,
      "rewards/rejected": -2.921689033508301,
      "step": 1380
    },
    {
      "epoch": 0.41039267788603484,
      "grad_norm": 10.410922050476074,
      "learning_rate": 1.3714230882787126e-05,
      "logits/chosen": 1.8549950122833252,
      "logits/rejected": 1.8649299144744873,
      "logps/chosen": -214.55966186523438,
      "logps/rejected": -223.87490844726562,
      "loss": 0.5597,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -1.8828332424163818,
      "rewards/margins": 0.9564754366874695,
      "rewards/rejected": -2.839308500289917,
      "step": 1390
    },
    {
      "epoch": 0.41334514319456744,
      "grad_norm": 12.684691429138184,
      "learning_rate": 1.3711455565397107e-05,
      "logits/chosen": 1.9625962972640991,
      "logits/rejected": 1.9356422424316406,
      "logps/chosen": -211.6839141845703,
      "logps/rejected": -219.6362762451172,
      "loss": 0.6239,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -1.9281479120254517,
      "rewards/margins": 0.616747260093689,
      "rewards/rejected": -2.5448951721191406,
      "step": 1400
    },
    {
      "epoch": 0.4162976085031001,
      "grad_norm": 7.307606220245361,
      "learning_rate": 1.3708680248007086e-05,
      "logits/chosen": 1.9638292789459229,
      "logits/rejected": 1.914389967918396,
      "logps/chosen": -207.5119171142578,
      "logps/rejected": -225.87222290039062,
      "loss": 0.4557,
      "rewards/accuracies": 0.7666667699813843,
      "rewards/chosen": -1.8299411535263062,
      "rewards/margins": 1.1650432348251343,
      "rewards/rejected": -2.9949843883514404,
      "step": 1410
    },
    {
      "epoch": 0.4192500738116327,
      "grad_norm": 12.257874488830566,
      "learning_rate": 1.3705904930617065e-05,
      "logits/chosen": 1.391054391860962,
      "logits/rejected": 1.3818986415863037,
      "logps/chosen": -214.1422576904297,
      "logps/rejected": -222.73483276367188,
      "loss": 0.4544,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.209418773651123,
      "rewards/margins": 1.234089970588684,
      "rewards/rejected": -3.4435086250305176,
      "step": 1420
    },
    {
      "epoch": 0.42220253912016537,
      "grad_norm": 8.540604591369629,
      "learning_rate": 1.3703129613227045e-05,
      "logits/chosen": 1.6971172094345093,
      "logits/rejected": 1.6461479663848877,
      "logps/chosen": -211.138427734375,
      "logps/rejected": -226.9855499267578,
      "loss": 0.4452,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -2.346330165863037,
      "rewards/margins": 1.2418601512908936,
      "rewards/rejected": -3.5881905555725098,
      "step": 1430
    },
    {
      "epoch": 0.42515500442869797,
      "grad_norm": 9.268149375915527,
      "learning_rate": 1.3700354295837025e-05,
      "logits/chosen": 1.9548860788345337,
      "logits/rejected": 1.9177993535995483,
      "logps/chosen": -215.9374237060547,
      "logps/rejected": -232.84793090820312,
      "loss": 0.402,
      "rewards/accuracies": 0.76666659116745,
      "rewards/chosen": -2.377653121948242,
      "rewards/margins": 1.3045767545700073,
      "rewards/rejected": -3.682229518890381,
      "step": 1440
    },
    {
      "epoch": 0.4281074697372306,
      "grad_norm": 21.954275131225586,
      "learning_rate": 1.3697578978447004e-05,
      "logits/chosen": 1.3979498147964478,
      "logits/rejected": 1.3677526712417603,
      "logps/chosen": -210.64718627929688,
      "logps/rejected": -228.50210571289062,
      "loss": 0.5304,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.5609898567199707,
      "rewards/margins": 1.1258093118667603,
      "rewards/rejected": -3.6867988109588623,
      "step": 1450
    },
    {
      "epoch": 0.43105993504576323,
      "grad_norm": 6.470329761505127,
      "learning_rate": 1.3694803661056982e-05,
      "logits/chosen": 1.86702561378479,
      "logits/rejected": 1.8463395833969116,
      "logps/chosen": -210.182861328125,
      "logps/rejected": -222.9962615966797,
      "loss": 0.4301,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.1927437782287598,
      "rewards/margins": 1.3028995990753174,
      "rewards/rejected": -3.495642900466919,
      "step": 1460
    },
    {
      "epoch": 0.43401240035429584,
      "grad_norm": 10.098443984985352,
      "learning_rate": 1.3692028343666963e-05,
      "logits/chosen": 1.8360755443572998,
      "logits/rejected": 1.8288065195083618,
      "logps/chosen": -212.3291778564453,
      "logps/rejected": -230.2407989501953,
      "loss": 0.4633,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -2.4677927494049072,
      "rewards/margins": 1.3908017873764038,
      "rewards/rejected": -3.8585944175720215,
      "step": 1470
    },
    {
      "epoch": 0.43696486566282844,
      "grad_norm": 12.44874095916748,
      "learning_rate": 1.3689253026276942e-05,
      "logits/chosen": 2.090280532836914,
      "logits/rejected": 2.044217586517334,
      "logps/chosen": -215.22946166992188,
      "logps/rejected": -227.16513061523438,
      "loss": 0.5509,
      "rewards/accuracies": 0.6833333969116211,
      "rewards/chosen": -2.303443670272827,
      "rewards/margins": 1.3296005725860596,
      "rewards/rejected": -3.6330440044403076,
      "step": 1480
    },
    {
      "epoch": 0.4399173309713611,
      "grad_norm": 11.090987205505371,
      "learning_rate": 1.368647770888692e-05,
      "logits/chosen": 1.7956199645996094,
      "logits/rejected": 1.7700704336166382,
      "logps/chosen": -210.5890350341797,
      "logps/rejected": -226.54629516601562,
      "loss": 0.4757,
      "rewards/accuracies": 0.8000000715255737,
      "rewards/chosen": -2.070655345916748,
      "rewards/margins": 1.3257092237472534,
      "rewards/rejected": -3.396364688873291,
      "step": 1490
    },
    {
      "epoch": 0.4428697962798937,
      "grad_norm": 5.824823379516602,
      "learning_rate": 1.36837023914969e-05,
      "logits/chosen": 1.9223756790161133,
      "logits/rejected": 1.9066959619522095,
      "logps/chosen": -211.0733184814453,
      "logps/rejected": -219.2902069091797,
      "loss": 0.4481,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.8967406749725342,
      "rewards/margins": 1.0397989749908447,
      "rewards/rejected": -2.9365394115448,
      "step": 1500
    },
    {
      "epoch": 0.44582226158842636,
      "grad_norm": 7.674006462097168,
      "learning_rate": 1.368092707410688e-05,
      "logits/chosen": 2.1385536193847656,
      "logits/rejected": 2.1098129749298096,
      "logps/chosen": -215.989990234375,
      "logps/rejected": -233.7119598388672,
      "loss": 0.4264,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.4696831703186035,
      "rewards/margins": 1.5908679962158203,
      "rewards/rejected": -4.060551643371582,
      "step": 1510
    },
    {
      "epoch": 0.44877472689695896,
      "grad_norm": 6.420853614807129,
      "learning_rate": 1.367815175671686e-05,
      "logits/chosen": 2.0408225059509277,
      "logits/rejected": 2.022550344467163,
      "logps/chosen": -226.0774383544922,
      "logps/rejected": -238.9863739013672,
      "loss": 0.3821,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -3.3092453479766846,
      "rewards/margins": 1.5551948547363281,
      "rewards/rejected": -4.864439964294434,
      "step": 1520
    },
    {
      "epoch": 0.45172719220549157,
      "grad_norm": 15.518784523010254,
      "learning_rate": 1.3675376439326837e-05,
      "logits/chosen": 1.6517670154571533,
      "logits/rejected": 1.6276919841766357,
      "logps/chosen": -220.96597290039062,
      "logps/rejected": -233.22994995117188,
      "loss": 0.6264,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -3.0785157680511475,
      "rewards/margins": 0.9479033350944519,
      "rewards/rejected": -4.026418685913086,
      "step": 1530
    },
    {
      "epoch": 0.4546796575140242,
      "grad_norm": 5.152675151824951,
      "learning_rate": 1.3672601121936818e-05,
      "logits/chosen": 1.9268500804901123,
      "logits/rejected": 1.9107993841171265,
      "logps/chosen": -213.47293090820312,
      "logps/rejected": -223.3741912841797,
      "loss": 0.4393,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -2.232581615447998,
      "rewards/margins": 1.3964608907699585,
      "rewards/rejected": -3.629042387008667,
      "step": 1540
    },
    {
      "epoch": 0.45763212282255683,
      "grad_norm": 11.195971488952637,
      "learning_rate": 1.3669825804546797e-05,
      "logits/chosen": 2.092090129852295,
      "logits/rejected": 2.0562055110931396,
      "logps/chosen": -207.5973663330078,
      "logps/rejected": -219.9665985107422,
      "loss": 0.5258,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -1.6384203433990479,
      "rewards/margins": 1.2694920301437378,
      "rewards/rejected": -2.907912254333496,
      "step": 1550
    },
    {
      "epoch": 0.46058458813108943,
      "grad_norm": 5.433038711547852,
      "learning_rate": 1.3667050487156778e-05,
      "logits/chosen": 2.0838725566864014,
      "logits/rejected": 2.0633792877197266,
      "logps/chosen": -214.7119598388672,
      "logps/rejected": -231.4275360107422,
      "loss": 0.339,
      "rewards/accuracies": 0.8333333134651184,
      "rewards/chosen": -2.225616216659546,
      "rewards/margins": 1.7597196102142334,
      "rewards/rejected": -3.9853358268737793,
      "step": 1560
    },
    {
      "epoch": 0.4635370534396221,
      "grad_norm": 3.5557994842529297,
      "learning_rate": 1.3664275169766755e-05,
      "logits/chosen": 1.6766105890274048,
      "logits/rejected": 1.6569492816925049,
      "logps/chosen": -216.2813720703125,
      "logps/rejected": -228.3469696044922,
      "loss": 0.3606,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -2.377837896347046,
      "rewards/margins": 1.597261667251587,
      "rewards/rejected": -3.975100040435791,
      "step": 1570
    },
    {
      "epoch": 0.4664895187481547,
      "grad_norm": 8.185144424438477,
      "learning_rate": 1.3661499852376734e-05,
      "logits/chosen": 1.7583338022232056,
      "logits/rejected": 1.7287986278533936,
      "logps/chosen": -217.25326538085938,
      "logps/rejected": -235.4297332763672,
      "loss": 0.3391,
      "rewards/accuracies": 0.8666666150093079,
      "rewards/chosen": -2.7011170387268066,
      "rewards/margins": 1.6880295276641846,
      "rewards/rejected": -4.389146327972412,
      "step": 1580
    },
    {
      "epoch": 0.46944198405668736,
      "grad_norm": 12.313129425048828,
      "learning_rate": 1.3658724534986715e-05,
      "logits/chosen": 2.467402219772339,
      "logits/rejected": 2.436138153076172,
      "logps/chosen": -219.18435668945312,
      "logps/rejected": -240.09249877929688,
      "loss": 0.4521,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -2.8630428314208984,
      "rewards/margins": 1.5054595470428467,
      "rewards/rejected": -4.368502616882324,
      "step": 1590
    },
    {
      "epoch": 0.47239444936521996,
      "grad_norm": 20.70305824279785,
      "learning_rate": 1.3655949217596692e-05,
      "logits/chosen": 1.1246540546417236,
      "logits/rejected": 1.103082537651062,
      "logps/chosen": -218.1312255859375,
      "logps/rejected": -231.3955535888672,
      "loss": 0.5178,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -3.012030839920044,
      "rewards/margins": 1.1094756126403809,
      "rewards/rejected": -4.121506690979004,
      "step": 1600
    },
    {
      "epoch": 0.47534691467375256,
      "grad_norm": 20.012422561645508,
      "learning_rate": 1.3653173900206673e-05,
      "logits/chosen": 1.9295810461044312,
      "logits/rejected": 1.9109834432601929,
      "logps/chosen": -221.8497772216797,
      "logps/rejected": -234.19540405273438,
      "loss": 0.669,
      "rewards/accuracies": 0.6166666746139526,
      "rewards/chosen": -3.0872931480407715,
      "rewards/margins": 1.0524697303771973,
      "rewards/rejected": -4.139763355255127,
      "step": 1610
    },
    {
      "epoch": 0.4782993799822852,
      "grad_norm": 10.924357414245605,
      "learning_rate": 1.3650398582816652e-05,
      "logits/chosen": 2.226010799407959,
      "logits/rejected": 2.2022106647491455,
      "logps/chosen": -226.2699737548828,
      "logps/rejected": -235.23703002929688,
      "loss": 0.5711,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -3.1082897186279297,
      "rewards/margins": 0.7846865653991699,
      "rewards/rejected": -3.8929762840270996,
      "step": 1620
    },
    {
      "epoch": 0.4812518452908178,
      "grad_norm": 5.985132694244385,
      "learning_rate": 1.3647623265426633e-05,
      "logits/chosen": 1.758713722229004,
      "logits/rejected": 1.7222049236297607,
      "logps/chosen": -222.83529663085938,
      "logps/rejected": -226.83230590820312,
      "loss": 0.5465,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -2.6711649894714355,
      "rewards/margins": 1.063751220703125,
      "rewards/rejected": -3.7349166870117188,
      "step": 1630
    },
    {
      "epoch": 0.4842043105993505,
      "grad_norm": 13.286523818969727,
      "learning_rate": 1.364484794803661e-05,
      "logits/chosen": 1.8418067693710327,
      "logits/rejected": 1.8069814443588257,
      "logps/chosen": -215.5402374267578,
      "logps/rejected": -229.61776733398438,
      "loss": 0.5514,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -1.976281762123108,
      "rewards/margins": 1.3927664756774902,
      "rewards/rejected": -3.3690483570098877,
      "step": 1640
    },
    {
      "epoch": 0.4871567759078831,
      "grad_norm": 11.771552085876465,
      "learning_rate": 1.364207263064659e-05,
      "logits/chosen": 2.2157530784606934,
      "logits/rejected": 2.1916890144348145,
      "logps/chosen": -215.77099609375,
      "logps/rejected": -234.46713256835938,
      "loss": 0.5072,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.270838499069214,
      "rewards/margins": 1.2623354196548462,
      "rewards/rejected": -3.5331740379333496,
      "step": 1650
    },
    {
      "epoch": 0.4901092412164157,
      "grad_norm": 6.383574485778809,
      "learning_rate": 1.363929731325657e-05,
      "logits/chosen": 1.7555738687515259,
      "logits/rejected": 1.7417335510253906,
      "logps/chosen": -214.7494659423828,
      "logps/rejected": -223.4855499267578,
      "loss": 0.5991,
      "rewards/accuracies": 0.7333332896232605,
      "rewards/chosen": -2.2431271076202393,
      "rewards/margins": 0.7948106527328491,
      "rewards/rejected": -3.037937641143799,
      "step": 1660
    },
    {
      "epoch": 0.49306170652494835,
      "grad_norm": 9.047196388244629,
      "learning_rate": 1.363652199586655e-05,
      "logits/chosen": 1.7017238140106201,
      "logits/rejected": 1.671651840209961,
      "logps/chosen": -207.5101318359375,
      "logps/rejected": -219.2568359375,
      "loss": 0.3798,
      "rewards/accuracies": 0.8000000715255737,
      "rewards/chosen": -1.4072130918502808,
      "rewards/margins": 1.801683783531189,
      "rewards/rejected": -3.2088966369628906,
      "step": 1670
    },
    {
      "epoch": 0.49601417183348095,
      "grad_norm": 9.652542114257812,
      "learning_rate": 1.3633746678476529e-05,
      "logits/chosen": 2.100886344909668,
      "logits/rejected": 2.07208251953125,
      "logps/chosen": -208.528076171875,
      "logps/rejected": -223.0659637451172,
      "loss": 0.4214,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.795819640159607,
      "rewards/margins": 1.6873962879180908,
      "rewards/rejected": -3.48321533203125,
      "step": 1680
    },
    {
      "epoch": 0.49896663714201356,
      "grad_norm": 5.488962173461914,
      "learning_rate": 1.3630971361086508e-05,
      "logits/chosen": 1.456458568572998,
      "logits/rejected": 1.4290472269058228,
      "logps/chosen": -211.7396240234375,
      "logps/rejected": -232.5260009765625,
      "loss": 0.3524,
      "rewards/accuracies": 0.8833333849906921,
      "rewards/chosen": -2.33013916015625,
      "rewards/margins": 1.6171772480010986,
      "rewards/rejected": -3.9473166465759277,
      "step": 1690
    },
    {
      "epoch": 0.5019191024505462,
      "grad_norm": 9.461639404296875,
      "learning_rate": 1.3628196043696488e-05,
      "logits/chosen": 1.2098820209503174,
      "logits/rejected": 1.1752185821533203,
      "logps/chosen": -215.4205322265625,
      "logps/rejected": -233.56668090820312,
      "loss": 0.4349,
      "rewards/accuracies": 0.8166666030883789,
      "rewards/chosen": -2.6936964988708496,
      "rewards/margins": 1.462408185005188,
      "rewards/rejected": -4.15610408782959,
      "step": 1700
    },
    {
      "epoch": 0.5048715677590788,
      "grad_norm": 14.905614852905273,
      "learning_rate": 1.3625420726306466e-05,
      "logits/chosen": 1.6375011205673218,
      "logits/rejected": 1.602940559387207,
      "logps/chosen": -223.638916015625,
      "logps/rejected": -242.69064331054688,
      "loss": 0.4219,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.2713170051574707,
      "rewards/margins": 1.5532879829406738,
      "rewards/rejected": -4.8246049880981445,
      "step": 1710
    },
    {
      "epoch": 0.5078240330676115,
      "grad_norm": 17.574359893798828,
      "learning_rate": 1.3622645408916445e-05,
      "logits/chosen": 1.41639244556427,
      "logits/rejected": 1.4115097522735596,
      "logps/chosen": -218.8412628173828,
      "logps/rejected": -233.05191040039062,
      "loss": 0.4117,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.414156913757324,
      "rewards/margins": 1.5347868204116821,
      "rewards/rejected": -3.948943614959717,
      "step": 1720
    },
    {
      "epoch": 0.510776498376144,
      "grad_norm": 7.096879482269287,
      "learning_rate": 1.3619870091526426e-05,
      "logits/chosen": 1.9362733364105225,
      "logits/rejected": 1.8924524784088135,
      "logps/chosen": -213.8209686279297,
      "logps/rejected": -232.6898193359375,
      "loss": 0.4478,
      "rewards/accuracies": 0.8166667819023132,
      "rewards/chosen": -2.5080599784851074,
      "rewards/margins": 1.512339472770691,
      "rewards/rejected": -4.0203986167907715,
      "step": 1730
    },
    {
      "epoch": 0.5137289636846767,
      "grad_norm": 10.205978393554688,
      "learning_rate": 1.3617094774136405e-05,
      "logits/chosen": 1.705865502357483,
      "logits/rejected": 1.6761407852172852,
      "logps/chosen": -214.02694702148438,
      "logps/rejected": -233.987060546875,
      "loss": 0.432,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.457549810409546,
      "rewards/margins": 1.748765230178833,
      "rewards/rejected": -4.206315040588379,
      "step": 1740
    },
    {
      "epoch": 0.5166814289932093,
      "grad_norm": 9.89065170288086,
      "learning_rate": 1.3614319456746384e-05,
      "logits/chosen": 1.7233545780181885,
      "logits/rejected": 1.6838144063949585,
      "logps/chosen": -213.57470703125,
      "logps/rejected": -230.47579956054688,
      "loss": 0.5118,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -2.562201976776123,
      "rewards/margins": 1.5503149032592773,
      "rewards/rejected": -4.1125168800354,
      "step": 1750
    },
    {
      "epoch": 0.519633894301742,
      "grad_norm": 5.909658432006836,
      "learning_rate": 1.3611544139356363e-05,
      "logits/chosen": 1.881115198135376,
      "logits/rejected": 1.8846698999404907,
      "logps/chosen": -217.54592895507812,
      "logps/rejected": -233.6405487060547,
      "loss": 0.3637,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.7034945487976074,
      "rewards/margins": 1.8425480127334595,
      "rewards/rejected": -4.546042442321777,
      "step": 1760
    },
    {
      "epoch": 0.5225863596102746,
      "grad_norm": 7.261380672454834,
      "learning_rate": 1.3608768821966342e-05,
      "logits/chosen": 2.1151416301727295,
      "logits/rejected": 2.0793769359588623,
      "logps/chosen": -221.4873809814453,
      "logps/rejected": -238.36001586914062,
      "loss": 0.404,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -3.1679484844207764,
      "rewards/margins": 1.775097131729126,
      "rewards/rejected": -4.943045616149902,
      "step": 1770
    },
    {
      "epoch": 0.5255388249188072,
      "grad_norm": 9.798108100891113,
      "learning_rate": 1.3605993504576321e-05,
      "logits/chosen": 2.1483030319213867,
      "logits/rejected": 2.1052119731903076,
      "logps/chosen": -221.1150360107422,
      "logps/rejected": -238.43179321289062,
      "loss": 0.4617,
      "rewards/accuracies": 0.7833333015441895,
      "rewards/chosen": -2.9746711254119873,
      "rewards/margins": 1.7289714813232422,
      "rewards/rejected": -4.703642845153809,
      "step": 1780
    },
    {
      "epoch": 0.5284912902273399,
      "grad_norm": 15.364336013793945,
      "learning_rate": 1.36032181871863e-05,
      "logits/chosen": 1.8836174011230469,
      "logits/rejected": 1.8350496292114258,
      "logps/chosen": -217.30429077148438,
      "logps/rejected": -232.18112182617188,
      "loss": 0.526,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -3.0188276767730713,
      "rewards/margins": 1.4717059135437012,
      "rewards/rejected": -4.490532875061035,
      "step": 1790
    },
    {
      "epoch": 0.5314437555358724,
      "grad_norm": 17.891401290893555,
      "learning_rate": 1.3600442869796281e-05,
      "logits/chosen": 2.1916515827178955,
      "logits/rejected": 2.1705522537231445,
      "logps/chosen": -223.8739013671875,
      "logps/rejected": -234.02182006835938,
      "loss": 0.609,
      "rewards/accuracies": 0.73333340883255,
      "rewards/chosen": -3.0375161170959473,
      "rewards/margins": 1.091819405555725,
      "rewards/rejected": -4.129336357116699,
      "step": 1800
    },
    {
      "epoch": 0.5343962208444051,
      "grad_norm": 13.366281509399414,
      "learning_rate": 1.359766755240626e-05,
      "logits/chosen": 1.8447974920272827,
      "logits/rejected": 1.819527268409729,
      "logps/chosen": -221.0160675048828,
      "logps/rejected": -235.2687530517578,
      "loss": 0.4544,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -2.8818764686584473,
      "rewards/margins": 1.5959842205047607,
      "rewards/rejected": -4.477861404418945,
      "step": 1810
    },
    {
      "epoch": 0.5373486861529377,
      "grad_norm": 7.008061408996582,
      "learning_rate": 1.359489223501624e-05,
      "logits/chosen": 1.8874187469482422,
      "logits/rejected": 1.877894639968872,
      "logps/chosen": -214.2112579345703,
      "logps/rejected": -230.3230438232422,
      "loss": 0.4161,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.683110475540161,
      "rewards/margins": 1.721260666847229,
      "rewards/rejected": -4.4043707847595215,
      "step": 1820
    },
    {
      "epoch": 0.5403011514614703,
      "grad_norm": 7.282690048217773,
      "learning_rate": 1.3592116917626218e-05,
      "logits/chosen": 1.6366586685180664,
      "logits/rejected": 1.615143060684204,
      "logps/chosen": -230.55203247070312,
      "logps/rejected": -241.218017578125,
      "loss": 0.4357,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -3.637394666671753,
      "rewards/margins": 1.6582340002059937,
      "rewards/rejected": -5.295628547668457,
      "step": 1830
    },
    {
      "epoch": 0.543253616770003,
      "grad_norm": 7.909693241119385,
      "learning_rate": 1.3589341600236197e-05,
      "logits/chosen": 1.8665746450424194,
      "logits/rejected": 1.8289117813110352,
      "logps/chosen": -219.9162139892578,
      "logps/rejected": -236.56179809570312,
      "loss": 0.5136,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -2.729038715362549,
      "rewards/margins": 1.4635531902313232,
      "rewards/rejected": -4.192591667175293,
      "step": 1840
    },
    {
      "epoch": 0.5462060820785356,
      "grad_norm": 5.152673244476318,
      "learning_rate": 1.3586566282846177e-05,
      "logits/chosen": 1.8958371877670288,
      "logits/rejected": 1.8452669382095337,
      "logps/chosen": -215.92074584960938,
      "logps/rejected": -232.5720672607422,
      "loss": 0.4022,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -2.890207290649414,
      "rewards/margins": 1.4724963903427124,
      "rewards/rejected": -4.362703800201416,
      "step": 1850
    },
    {
      "epoch": 0.5491585473870682,
      "grad_norm": 16.869836807250977,
      "learning_rate": 1.3583790965456156e-05,
      "logits/chosen": 1.7068731784820557,
      "logits/rejected": 1.6766220331192017,
      "logps/chosen": -209.456787109375,
      "logps/rejected": -221.5702667236328,
      "loss": 0.4939,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -1.8542261123657227,
      "rewards/margins": 1.5404595136642456,
      "rewards/rejected": -3.394686222076416,
      "step": 1860
    },
    {
      "epoch": 0.5521110126956008,
      "grad_norm": 18.494823455810547,
      "learning_rate": 1.3581015648066136e-05,
      "logits/chosen": 1.8932186365127563,
      "logits/rejected": 1.8799817562103271,
      "logps/chosen": -205.7574462890625,
      "logps/rejected": -218.01889038085938,
      "loss": 0.3717,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -1.603096604347229,
      "rewards/margins": 1.5441899299621582,
      "rewards/rejected": -3.1472864151000977,
      "step": 1870
    },
    {
      "epoch": 0.5550634780041335,
      "grad_norm": 9.70190715789795,
      "learning_rate": 1.3578240330676116e-05,
      "logits/chosen": 2.4461331367492676,
      "logits/rejected": 2.402604579925537,
      "logps/chosen": -204.447265625,
      "logps/rejected": -221.625244140625,
      "loss": 0.4144,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4334218502044678,
      "rewards/margins": 1.7850885391235352,
      "rewards/rejected": -3.218510389328003,
      "step": 1880
    },
    {
      "epoch": 0.5580159433126661,
      "grad_norm": 18.195884704589844,
      "learning_rate": 1.3575465013286093e-05,
      "logits/chosen": 1.7889354228973389,
      "logits/rejected": 1.780643105506897,
      "logps/chosen": -219.21249389648438,
      "logps/rejected": -240.5228729248047,
      "loss": 0.3485,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -2.431593418121338,
      "rewards/margins": 2.0536422729492188,
      "rewards/rejected": -4.485236167907715,
      "step": 1890
    },
    {
      "epoch": 0.5609684086211987,
      "grad_norm": 12.906248092651367,
      "learning_rate": 1.3572689695896074e-05,
      "logits/chosen": 1.4069783687591553,
      "logits/rejected": 1.3652421236038208,
      "logps/chosen": -228.88485717773438,
      "logps/rejected": -247.2256317138672,
      "loss": 0.6126,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -4.082823753356934,
      "rewards/margins": 1.169109582901001,
      "rewards/rejected": -5.2519330978393555,
      "step": 1900
    },
    {
      "epoch": 0.5639208739297313,
      "grad_norm": 10.02679443359375,
      "learning_rate": 1.3569914378506053e-05,
      "logits/chosen": 1.6921923160552979,
      "logits/rejected": 1.6810457706451416,
      "logps/chosen": -241.3960418701172,
      "logps/rejected": -252.912109375,
      "loss": 0.4979,
      "rewards/accuracies": 0.7833333015441895,
      "rewards/chosen": -4.360673904418945,
      "rewards/margins": 1.6450086832046509,
      "rewards/rejected": -6.005682945251465,
      "step": 1910
    },
    {
      "epoch": 0.566873339238264,
      "grad_norm": 26.051149368286133,
      "learning_rate": 1.3567139061116034e-05,
      "logits/chosen": 1.886042833328247,
      "logits/rejected": 1.8604122400283813,
      "logps/chosen": -235.29931640625,
      "logps/rejected": -254.4606170654297,
      "loss": 0.436,
      "rewards/accuracies": 0.7500001192092896,
      "rewards/chosen": -4.144074440002441,
      "rewards/margins": 1.6637548208236694,
      "rewards/rejected": -5.807829856872559,
      "step": 1920
    },
    {
      "epoch": 0.5698258045467965,
      "grad_norm": 5.737347602844238,
      "learning_rate": 1.3564363743726011e-05,
      "logits/chosen": 1.6549739837646484,
      "logits/rejected": 1.6258865594863892,
      "logps/chosen": -230.9759063720703,
      "logps/rejected": -245.1206512451172,
      "loss": 0.4467,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -4.100613594055176,
      "rewards/margins": 1.5774638652801514,
      "rewards/rejected": -5.678077220916748,
      "step": 1930
    },
    {
      "epoch": 0.5727782698553292,
      "grad_norm": 13.151211738586426,
      "learning_rate": 1.3561588426335992e-05,
      "logits/chosen": 1.7374343872070312,
      "logits/rejected": 1.6971461772918701,
      "logps/chosen": -235.87020874023438,
      "logps/rejected": -248.107666015625,
      "loss": 0.4827,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -4.267586708068848,
      "rewards/margins": 1.5253559350967407,
      "rewards/rejected": -5.792942523956299,
      "step": 1940
    },
    {
      "epoch": 0.5757307351638619,
      "grad_norm": 10.349345207214355,
      "learning_rate": 1.355881310894597e-05,
      "logits/chosen": 1.7755870819091797,
      "logits/rejected": 1.768372893333435,
      "logps/chosen": -235.17807006835938,
      "logps/rejected": -245.50637817382812,
      "loss": 0.5872,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -4.142346382141113,
      "rewards/margins": 1.1638643741607666,
      "rewards/rejected": -5.306210041046143,
      "step": 1950
    },
    {
      "epoch": 0.5786832004723944,
      "grad_norm": 5.75040864944458,
      "learning_rate": 1.3556037791555948e-05,
      "logits/chosen": 2.524606704711914,
      "logits/rejected": 2.493046760559082,
      "logps/chosen": -217.213623046875,
      "logps/rejected": -239.1621551513672,
      "loss": 0.37,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.4971656799316406,
      "rewards/margins": 1.9362781047821045,
      "rewards/rejected": -4.433443546295166,
      "step": 1960
    },
    {
      "epoch": 0.5816356657809271,
      "grad_norm": 1.8992551565170288,
      "learning_rate": 1.3553262474165929e-05,
      "logits/chosen": 1.5935600996017456,
      "logits/rejected": 1.5921610593795776,
      "logps/chosen": -219.0408172607422,
      "logps/rejected": -242.63931274414062,
      "loss": 0.397,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -2.496480703353882,
      "rewards/margins": 2.1562464237213135,
      "rewards/rejected": -4.652726650238037,
      "step": 1970
    },
    {
      "epoch": 0.5845881310894597,
      "grad_norm": 20.211759567260742,
      "learning_rate": 1.3550487156775908e-05,
      "logits/chosen": 1.8880058526992798,
      "logits/rejected": 1.8645970821380615,
      "logps/chosen": -224.1688232421875,
      "logps/rejected": -243.7769317626953,
      "loss": 0.5538,
      "rewards/accuracies": 0.7166666388511658,
      "rewards/chosen": -3.1108176708221436,
      "rewards/margins": 1.4632368087768555,
      "rewards/rejected": -4.574053764343262,
      "step": 1980
    },
    {
      "epoch": 0.5875405963979923,
      "grad_norm": 7.658727645874023,
      "learning_rate": 1.3547711839385889e-05,
      "logits/chosen": 2.035264730453491,
      "logits/rejected": 1.9896312952041626,
      "logps/chosen": -225.02902221679688,
      "logps/rejected": -243.33486938476562,
      "loss": 0.3452,
      "rewards/accuracies": 0.8500000834465027,
      "rewards/chosen": -3.243809938430786,
      "rewards/margins": 1.877197265625,
      "rewards/rejected": -5.121006965637207,
      "step": 1990
    },
    {
      "epoch": 0.5904930617065249,
      "grad_norm": 12.478321075439453,
      "learning_rate": 1.3544936521995866e-05,
      "logits/chosen": 1.4973925352096558,
      "logits/rejected": 1.4807231426239014,
      "logps/chosen": -224.5206756591797,
      "logps/rejected": -236.0790557861328,
      "loss": 0.5609,
      "rewards/accuracies": 0.7333332896232605,
      "rewards/chosen": -3.677720546722412,
      "rewards/margins": 1.3114778995513916,
      "rewards/rejected": -4.989198207855225,
      "step": 2000
    },
    {
      "epoch": 0.5934455270150576,
      "grad_norm": 31.778894424438477,
      "learning_rate": 1.3542161204605847e-05,
      "logits/chosen": 1.8034944534301758,
      "logits/rejected": 1.7812381982803345,
      "logps/chosen": -226.6380615234375,
      "logps/rejected": -244.3704071044922,
      "loss": 0.4081,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -3.3364646434783936,
      "rewards/margins": 1.876442551612854,
      "rewards/rejected": -5.212906837463379,
      "step": 2010
    },
    {
      "epoch": 0.5963979923235901,
      "grad_norm": 13.98127555847168,
      "learning_rate": 1.3539385887215826e-05,
      "logits/chosen": 1.4317817687988281,
      "logits/rejected": 1.3935118913650513,
      "logps/chosen": -236.33053588867188,
      "logps/rejected": -249.42221069335938,
      "loss": 0.4895,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -4.363944053649902,
      "rewards/margins": 1.2279210090637207,
      "rewards/rejected": -5.591865539550781,
      "step": 2020
    },
    {
      "epoch": 0.5993504576321228,
      "grad_norm": 13.668774604797363,
      "learning_rate": 1.3536610569825805e-05,
      "logits/chosen": 1.504664421081543,
      "logits/rejected": 1.4936225414276123,
      "logps/chosen": -227.1090545654297,
      "logps/rejected": -249.2073211669922,
      "loss": 0.3555,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -4.093752384185791,
      "rewards/margins": 1.6671100854873657,
      "rewards/rejected": -5.760862350463867,
      "step": 2030
    },
    {
      "epoch": 0.6023029229406555,
      "grad_norm": 6.522639274597168,
      "learning_rate": 1.3533835252435784e-05,
      "logits/chosen": 2.076383352279663,
      "logits/rejected": 2.026214122772217,
      "logps/chosen": -223.25723266601562,
      "logps/rejected": -235.27597045898438,
      "loss": 0.433,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.042590379714966,
      "rewards/margins": 1.4702637195587158,
      "rewards/rejected": -4.512854099273682,
      "step": 2040
    },
    {
      "epoch": 0.6052553882491881,
      "grad_norm": 9.283330917358398,
      "learning_rate": 1.3531059935045763e-05,
      "logits/chosen": 2.0535130500793457,
      "logits/rejected": 2.0173239707946777,
      "logps/chosen": -225.689453125,
      "logps/rejected": -238.03076171875,
      "loss": 0.3888,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -2.9615206718444824,
      "rewards/margins": 1.6004616022109985,
      "rewards/rejected": -4.561981678009033,
      "step": 2050
    },
    {
      "epoch": 0.6082078535577207,
      "grad_norm": 8.968916893005371,
      "learning_rate": 1.3528284617655744e-05,
      "logits/chosen": 1.8899818658828735,
      "logits/rejected": 1.8687330484390259,
      "logps/chosen": -214.4208526611328,
      "logps/rejected": -232.1885223388672,
      "loss": 0.4488,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.3540055751800537,
      "rewards/margins": 1.594180703163147,
      "rewards/rejected": -3.948186159133911,
      "step": 2060
    },
    {
      "epoch": 0.6111603188662533,
      "grad_norm": 12.452316284179688,
      "learning_rate": 1.3525509300265722e-05,
      "logits/chosen": 1.7403440475463867,
      "logits/rejected": 1.7250325679779053,
      "logps/chosen": -223.43331909179688,
      "logps/rejected": -243.54476928710938,
      "loss": 0.4286,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -3.257106065750122,
      "rewards/margins": 1.6357395648956299,
      "rewards/rejected": -4.89284610748291,
      "step": 2070
    },
    {
      "epoch": 0.614112784174786,
      "grad_norm": 9.182977676391602,
      "learning_rate": 1.35227339828757e-05,
      "logits/chosen": 1.8488614559173584,
      "logits/rejected": 1.8088678121566772,
      "logps/chosen": -237.1939697265625,
      "logps/rejected": -248.3012237548828,
      "loss": 0.5315,
      "rewards/accuracies": 0.7166667580604553,
      "rewards/chosen": -4.300778865814209,
      "rewards/margins": 1.2478586435317993,
      "rewards/rejected": -5.548637390136719,
      "step": 2080
    },
    {
      "epoch": 0.6170652494833185,
      "grad_norm": 6.772730350494385,
      "learning_rate": 1.3519958665485682e-05,
      "logits/chosen": 1.3696739673614502,
      "logits/rejected": 1.337594985961914,
      "logps/chosen": -236.8318328857422,
      "logps/rejected": -258.8675537109375,
      "loss": 0.4678,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -4.970269203186035,
      "rewards/margins": 1.56415593624115,
      "rewards/rejected": -6.534424781799316,
      "step": 2090
    },
    {
      "epoch": 0.6200177147918512,
      "grad_norm": 6.990164756774902,
      "learning_rate": 1.351718334809566e-05,
      "logits/chosen": 1.4778045415878296,
      "logits/rejected": 1.4415054321289062,
      "logps/chosen": -248.77236938476562,
      "logps/rejected": -266.4332275390625,
      "loss": 0.4521,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -5.676333427429199,
      "rewards/margins": 1.4625577926635742,
      "rewards/rejected": -7.138890743255615,
      "step": 2100
    },
    {
      "epoch": 0.6229701801003839,
      "grad_norm": 13.50905704498291,
      "learning_rate": 1.351440803070564e-05,
      "logits/chosen": 1.5923372507095337,
      "logits/rejected": 1.5700346231460571,
      "logps/chosen": -255.0437774658203,
      "logps/rejected": -267.72418212890625,
      "loss": 0.556,
      "rewards/accuracies": 0.7000001072883606,
      "rewards/chosen": -5.883848190307617,
      "rewards/margins": 1.3667175769805908,
      "rewards/rejected": -7.250565528869629,
      "step": 2110
    },
    {
      "epoch": 0.6259226454089164,
      "grad_norm": 9.517277717590332,
      "learning_rate": 1.3511632713315619e-05,
      "logits/chosen": 1.7505407333374023,
      "logits/rejected": 1.6975517272949219,
      "logps/chosen": -246.8147430419922,
      "logps/rejected": -263.2955322265625,
      "loss": 0.3265,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.309286594390869,
      "rewards/margins": 2.0168328285217285,
      "rewards/rejected": -7.326119899749756,
      "step": 2120
    },
    {
      "epoch": 0.6288751107174491,
      "grad_norm": 8.486474990844727,
      "learning_rate": 1.35088573959256e-05,
      "logits/chosen": 1.6621224880218506,
      "logits/rejected": 1.6545464992523193,
      "logps/chosen": -238.83718872070312,
      "logps/rejected": -252.0231170654297,
      "loss": 0.4823,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -4.965978622436523,
      "rewards/margins": 1.4259916543960571,
      "rewards/rejected": -6.391969680786133,
      "step": 2130
    },
    {
      "epoch": 0.6318275760259817,
      "grad_norm": 8.177766799926758,
      "learning_rate": 1.3506082078535577e-05,
      "logits/chosen": 1.800206184387207,
      "logits/rejected": 1.7559401988983154,
      "logps/chosen": -233.135009765625,
      "logps/rejected": -246.7517852783203,
      "loss": 0.3879,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.830902576446533,
      "rewards/margins": 1.889718770980835,
      "rewards/rejected": -5.720621109008789,
      "step": 2140
    },
    {
      "epoch": 0.6347800413345143,
      "grad_norm": 13.993441581726074,
      "learning_rate": 1.3503306761145556e-05,
      "logits/chosen": 1.75235915184021,
      "logits/rejected": 1.7302045822143555,
      "logps/chosen": -220.74014282226562,
      "logps/rejected": -239.58456420898438,
      "loss": 0.6128,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -3.577069044113159,
      "rewards/margins": 0.9810279011726379,
      "rewards/rejected": -4.558095932006836,
      "step": 2150
    },
    {
      "epoch": 0.6377325066430469,
      "grad_norm": 11.774426460266113,
      "learning_rate": 1.3500531443755537e-05,
      "logits/chosen": 1.5361355543136597,
      "logits/rejected": 1.4695086479187012,
      "logps/chosen": -218.120361328125,
      "logps/rejected": -241.84970092773438,
      "loss": 0.4311,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -3.0788958072662354,
      "rewards/margins": 1.724207878112793,
      "rewards/rejected": -4.803103446960449,
      "step": 2160
    },
    {
      "epoch": 0.6406849719515796,
      "grad_norm": 15.344810485839844,
      "learning_rate": 1.3497756126365516e-05,
      "logits/chosen": 1.6597483158111572,
      "logits/rejected": 1.6316022872924805,
      "logps/chosen": -229.647705078125,
      "logps/rejected": -246.96170043945312,
      "loss": 0.4627,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -3.7047946453094482,
      "rewards/margins": 1.6768817901611328,
      "rewards/rejected": -5.381677150726318,
      "step": 2170
    },
    {
      "epoch": 0.6436374372601122,
      "grad_norm": 19.584596633911133,
      "learning_rate": 1.3494980808975495e-05,
      "logits/chosen": 1.599426507949829,
      "logits/rejected": 1.5895678997039795,
      "logps/chosen": -219.2548065185547,
      "logps/rejected": -236.66006469726562,
      "loss": 0.4976,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -3.3471856117248535,
      "rewards/margins": 1.4633190631866455,
      "rewards/rejected": -4.81050443649292,
      "step": 2180
    },
    {
      "epoch": 0.6465899025686448,
      "grad_norm": 16.07794761657715,
      "learning_rate": 1.3492205491585474e-05,
      "logits/chosen": 1.8742517232894897,
      "logits/rejected": 1.832945466041565,
      "logps/chosen": -230.7783660888672,
      "logps/rejected": -245.83023071289062,
      "loss": 0.5104,
      "rewards/accuracies": 0.73333340883255,
      "rewards/chosen": -3.7160305976867676,
      "rewards/margins": 1.6130876541137695,
      "rewards/rejected": -5.329117774963379,
      "step": 2190
    },
    {
      "epoch": 0.6495423678771775,
      "grad_norm": 14.455732345581055,
      "learning_rate": 1.3489430174195455e-05,
      "logits/chosen": 1.7586157321929932,
      "logits/rejected": 1.7200095653533936,
      "logps/chosen": -218.68453979492188,
      "logps/rejected": -236.0807647705078,
      "loss": 0.493,
      "rewards/accuracies": 0.7666667699813843,
      "rewards/chosen": -2.9572536945343018,
      "rewards/margins": 1.6133859157562256,
      "rewards/rejected": -4.570639610290527,
      "step": 2200
    },
    {
      "epoch": 0.6524948331857101,
      "grad_norm": 9.684196472167969,
      "learning_rate": 1.3486654856805432e-05,
      "logits/chosen": 1.4890525341033936,
      "logits/rejected": 1.4559011459350586,
      "logps/chosen": -211.1943817138672,
      "logps/rejected": -225.76803588867188,
      "loss": 0.5473,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -2.619689464569092,
      "rewards/margins": 1.1616191864013672,
      "rewards/rejected": -3.781308650970459,
      "step": 2210
    },
    {
      "epoch": 0.6554472984942427,
      "grad_norm": 26.145715713500977,
      "learning_rate": 1.3483879539415411e-05,
      "logits/chosen": 1.0327318906784058,
      "logits/rejected": 1.0128448009490967,
      "logps/chosen": -222.3230438232422,
      "logps/rejected": -227.02273559570312,
      "loss": 0.4753,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -2.8474466800689697,
      "rewards/margins": 1.0498592853546143,
      "rewards/rejected": -3.897305965423584,
      "step": 2220
    },
    {
      "epoch": 0.6583997638027753,
      "grad_norm": 20.891019821166992,
      "learning_rate": 1.3481104222025392e-05,
      "logits/chosen": 1.601196050643921,
      "logits/rejected": 1.5953127145767212,
      "logps/chosen": -223.9537811279297,
      "logps/rejected": -236.14108276367188,
      "loss": 0.5024,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -3.162986993789673,
      "rewards/margins": 1.335449457168579,
      "rewards/rejected": -4.498436450958252,
      "step": 2230
    },
    {
      "epoch": 0.661352229111308,
      "grad_norm": 16.10728645324707,
      "learning_rate": 1.3478328904635371e-05,
      "logits/chosen": 1.68524169921875,
      "logits/rejected": 1.615313172340393,
      "logps/chosen": -227.87759399414062,
      "logps/rejected": -252.3703155517578,
      "loss": 0.4106,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -3.6117682456970215,
      "rewards/margins": 1.7749840021133423,
      "rewards/rejected": -5.386752128601074,
      "step": 2240
    },
    {
      "epoch": 0.6643046944198405,
      "grad_norm": 3.742856979370117,
      "learning_rate": 1.347555358724535e-05,
      "logits/chosen": 1.2156870365142822,
      "logits/rejected": 1.1696093082427979,
      "logps/chosen": -243.95413208007812,
      "logps/rejected": -260.34417724609375,
      "loss": 0.4342,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -4.959190845489502,
      "rewards/margins": 1.5964150428771973,
      "rewards/rejected": -6.555605888366699,
      "step": 2250
    },
    {
      "epoch": 0.6672571597283732,
      "grad_norm": 9.285175323486328,
      "learning_rate": 1.347277826985533e-05,
      "logits/chosen": 1.8180900812149048,
      "logits/rejected": 1.7885189056396484,
      "logps/chosen": -238.59866333007812,
      "logps/rejected": -256.05462646484375,
      "loss": 0.3497,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -4.7046661376953125,
      "rewards/margins": 2.2111153602600098,
      "rewards/rejected": -6.915781497955322,
      "step": 2260
    },
    {
      "epoch": 0.6702096250369058,
      "grad_norm": 13.101806640625,
      "learning_rate": 1.3470002952465309e-05,
      "logits/chosen": 1.6123281717300415,
      "logits/rejected": 1.5876528024673462,
      "logps/chosen": -244.1875457763672,
      "logps/rejected": -260.723388671875,
      "loss": 0.3964,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -4.832831382751465,
      "rewards/margins": 1.9934494495391846,
      "rewards/rejected": -6.826280117034912,
      "step": 2270
    },
    {
      "epoch": 0.6731620903454384,
      "grad_norm": 5.795004367828369,
      "learning_rate": 1.346722763507529e-05,
      "logits/chosen": 1.6466524600982666,
      "logits/rejected": 1.6251786947250366,
      "logps/chosen": -241.861328125,
      "logps/rejected": -249.494140625,
      "loss": 0.5307,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -4.791224002838135,
      "rewards/margins": 1.4060837030410767,
      "rewards/rejected": -6.19730806350708,
      "step": 2280
    },
    {
      "epoch": 0.676114555653971,
      "grad_norm": 10.529450416564941,
      "learning_rate": 1.3464452317685267e-05,
      "logits/chosen": 1.2919337749481201,
      "logits/rejected": 1.244478702545166,
      "logps/chosen": -234.5137481689453,
      "logps/rejected": -255.3479461669922,
      "loss": 0.3166,
      "rewards/accuracies": 0.8666667938232422,
      "rewards/chosen": -3.9928791522979736,
      "rewards/margins": 2.3423233032226562,
      "rewards/rejected": -6.335202693939209,
      "step": 2290
    },
    {
      "epoch": 0.6790670209625037,
      "grad_norm": 9.481734275817871,
      "learning_rate": 1.3461677000295248e-05,
      "logits/chosen": 1.9883439540863037,
      "logits/rejected": 1.9624271392822266,
      "logps/chosen": -237.67825317382812,
      "logps/rejected": -250.0701904296875,
      "loss": 0.4709,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -4.351906776428223,
      "rewards/margins": 1.6711633205413818,
      "rewards/rejected": -6.023070335388184,
      "step": 2300
    },
    {
      "epoch": 0.6820194862710364,
      "grad_norm": 8.998260498046875,
      "learning_rate": 1.3458901682905227e-05,
      "logits/chosen": 2.227842330932617,
      "logits/rejected": 2.1790027618408203,
      "logps/chosen": -228.3326873779297,
      "logps/rejected": -252.16885375976562,
      "loss": 0.4261,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -3.8716323375701904,
      "rewards/margins": 1.5997364521026611,
      "rewards/rejected": -5.47136926651001,
      "step": 2310
    },
    {
      "epoch": 0.6849719515795689,
      "grad_norm": 4.343469619750977,
      "learning_rate": 1.3456126365515206e-05,
      "logits/chosen": 2.0801570415496826,
      "logits/rejected": 2.0321195125579834,
      "logps/chosen": -233.8759307861328,
      "logps/rejected": -245.7513427734375,
      "loss": 0.4762,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -4.2544145584106445,
      "rewards/margins": 1.3997471332550049,
      "rewards/rejected": -5.6541619300842285,
      "step": 2320
    },
    {
      "epoch": 0.6879244168881016,
      "grad_norm": 16.531583786010742,
      "learning_rate": 1.3453351048125185e-05,
      "logits/chosen": 1.4432233572006226,
      "logits/rejected": 1.3933697938919067,
      "logps/chosen": -234.000732421875,
      "logps/rejected": -250.14767456054688,
      "loss": 0.4719,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -4.393177032470703,
      "rewards/margins": 1.5619419813156128,
      "rewards/rejected": -5.955118656158447,
      "step": 2330
    },
    {
      "epoch": 0.6908768821966342,
      "grad_norm": 5.333813190460205,
      "learning_rate": 1.3450575730735164e-05,
      "logits/chosen": 1.6649919748306274,
      "logits/rejected": 1.613682508468628,
      "logps/chosen": -233.9722900390625,
      "logps/rejected": -253.9030303955078,
      "loss": 0.3481,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -3.9345831871032715,
      "rewards/margins": 1.7766332626342773,
      "rewards/rejected": -5.711216926574707,
      "step": 2340
    },
    {
      "epoch": 0.6938293475051668,
      "grad_norm": 10.64805793762207,
      "learning_rate": 1.3447800413345145e-05,
      "logits/chosen": 2.27833890914917,
      "logits/rejected": 2.2645649909973145,
      "logps/chosen": -226.3809356689453,
      "logps/rejected": -238.9543914794922,
      "loss": 0.59,
      "rewards/accuracies": 0.73333340883255,
      "rewards/chosen": -3.319288730621338,
      "rewards/margins": 1.3309288024902344,
      "rewards/rejected": -4.6502180099487305,
      "step": 2350
    },
    {
      "epoch": 0.6967818128136994,
      "grad_norm": 21.095972061157227,
      "learning_rate": 1.3445025095955122e-05,
      "logits/chosen": 1.7004657983779907,
      "logits/rejected": 1.664320945739746,
      "logps/chosen": -222.7300262451172,
      "logps/rejected": -237.3887176513672,
      "loss": 0.5832,
      "rewards/accuracies": 0.7666667699813843,
      "rewards/chosen": -2.7043955326080322,
      "rewards/margins": 1.3359944820404053,
      "rewards/rejected": -4.040390491485596,
      "step": 2360
    },
    {
      "epoch": 0.6997342781222321,
      "grad_norm": 7.566328048706055,
      "learning_rate": 1.3442249778565103e-05,
      "logits/chosen": 2.241934299468994,
      "logits/rejected": 2.224870204925537,
      "logps/chosen": -212.15567016601562,
      "logps/rejected": -227.1227569580078,
      "loss": 0.4751,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -2.0360748767852783,
      "rewards/margins": 1.6208505630493164,
      "rewards/rejected": -3.656925916671753,
      "step": 2370
    },
    {
      "epoch": 0.7026867434307646,
      "grad_norm": 7.052640438079834,
      "learning_rate": 1.3439474461175082e-05,
      "logits/chosen": 1.651160478591919,
      "logits/rejected": 1.6344168186187744,
      "logps/chosen": -210.13034057617188,
      "logps/rejected": -227.03329467773438,
      "loss": 0.4153,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -1.9351472854614258,
      "rewards/margins": 1.3609774112701416,
      "rewards/rejected": -3.2961246967315674,
      "step": 2380
    },
    {
      "epoch": 0.7056392087392973,
      "grad_norm": 8.202964782714844,
      "learning_rate": 1.3436699143785061e-05,
      "logits/chosen": 1.505774974822998,
      "logits/rejected": 1.4626855850219727,
      "logps/chosen": -220.3681182861328,
      "logps/rejected": -239.55435180664062,
      "loss": 0.4166,
      "rewards/accuracies": 0.8333333134651184,
      "rewards/chosen": -2.743316888809204,
      "rewards/margins": 1.818441390991211,
      "rewards/rejected": -4.561758518218994,
      "step": 2390
    },
    {
      "epoch": 0.70859167404783,
      "grad_norm": 3.2797610759735107,
      "learning_rate": 1.343392382639504e-05,
      "logits/chosen": 1.7525250911712646,
      "logits/rejected": 1.734079360961914,
      "logps/chosen": -225.23428344726562,
      "logps/rejected": -242.56106567382812,
      "loss": 0.5246,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -3.6169910430908203,
      "rewards/margins": 1.5791720151901245,
      "rewards/rejected": -5.196162700653076,
      "step": 2400
    },
    {
      "epoch": 0.7115441393563625,
      "grad_norm": 3.9646799564361572,
      "learning_rate": 1.343114850900502e-05,
      "logits/chosen": 1.1957104206085205,
      "logits/rejected": 1.1699364185333252,
      "logps/chosen": -233.3480224609375,
      "logps/rejected": -249.3564453125,
      "loss": 0.4089,
      "rewards/accuracies": 0.8833333253860474,
      "rewards/chosen": -4.069450378417969,
      "rewards/margins": 1.8499746322631836,
      "rewards/rejected": -5.919425010681152,
      "step": 2410
    },
    {
      "epoch": 0.7144966046648952,
      "grad_norm": 15.115782737731934,
      "learning_rate": 1.3428373191615e-05,
      "logits/chosen": 1.6632356643676758,
      "logits/rejected": 1.6630780696868896,
      "logps/chosen": -231.6785125732422,
      "logps/rejected": -239.1132049560547,
      "loss": 0.561,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -3.7141201496124268,
      "rewards/margins": 1.2258572578430176,
      "rewards/rejected": -4.939977645874023,
      "step": 2420
    },
    {
      "epoch": 0.7174490699734278,
      "grad_norm": 7.266149520874023,
      "learning_rate": 1.3425597874224977e-05,
      "logits/chosen": 1.7508083581924438,
      "logits/rejected": 1.7235103845596313,
      "logps/chosen": -226.7529296875,
      "logps/rejected": -245.5639190673828,
      "loss": 0.4292,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.528123140335083,
      "rewards/margins": 1.696459412574768,
      "rewards/rejected": -5.224583148956299,
      "step": 2430
    },
    {
      "epoch": 0.7204015352819605,
      "grad_norm": 12.394981384277344,
      "learning_rate": 1.3422822556834958e-05,
      "logits/chosen": 1.6595075130462646,
      "logits/rejected": 1.6292304992675781,
      "logps/chosen": -238.4109649658203,
      "logps/rejected": -255.07803344726562,
      "loss": 0.4512,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -4.517991065979004,
      "rewards/margins": 1.4756367206573486,
      "rewards/rejected": -5.993628025054932,
      "step": 2440
    },
    {
      "epoch": 0.723354000590493,
      "grad_norm": 9.686607360839844,
      "learning_rate": 1.3420047239444937e-05,
      "logits/chosen": 1.7872474193572998,
      "logits/rejected": 1.7783632278442383,
      "logps/chosen": -225.1597442626953,
      "logps/rejected": -246.85598754882812,
      "loss": 0.4431,
      "rewards/accuracies": 0.8333333134651184,
      "rewards/chosen": -3.415158748626709,
      "rewards/margins": 1.7207212448120117,
      "rewards/rejected": -5.135880470275879,
      "step": 2450
    },
    {
      "epoch": 0.7263064658990257,
      "grad_norm": 8.06390380859375,
      "learning_rate": 1.3417271922054916e-05,
      "logits/chosen": 1.7674286365509033,
      "logits/rejected": 1.7457473278045654,
      "logps/chosen": -221.8867645263672,
      "logps/rejected": -240.35873413085938,
      "loss": 0.4595,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.2154650688171387,
      "rewards/margins": 1.7674522399902344,
      "rewards/rejected": -4.982917785644531,
      "step": 2460
    },
    {
      "epoch": 0.7292589312075584,
      "grad_norm": 6.629768371582031,
      "learning_rate": 1.3414496604664895e-05,
      "logits/chosen": 2.3482272624969482,
      "logits/rejected": 2.298130512237549,
      "logps/chosen": -221.29296875,
      "logps/rejected": -235.0601806640625,
      "loss": 0.464,
      "rewards/accuracies": 0.7833333015441895,
      "rewards/chosen": -3.204723358154297,
      "rewards/margins": 1.3429046869277954,
      "rewards/rejected": -4.547627925872803,
      "step": 2470
    },
    {
      "epoch": 0.7322113965160909,
      "grad_norm": 9.254414558410645,
      "learning_rate": 1.3411721287274875e-05,
      "logits/chosen": 1.7165155410766602,
      "logits/rejected": 1.6824452877044678,
      "logps/chosen": -220.60836791992188,
      "logps/rejected": -236.2544708251953,
      "loss": 0.3494,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.543658971786499,
      "rewards/margins": 1.5564302206039429,
      "rewards/rejected": -4.100089073181152,
      "step": 2480
    },
    {
      "epoch": 0.7351638618246236,
      "grad_norm": 15.132071495056152,
      "learning_rate": 1.3408945969884855e-05,
      "logits/chosen": 1.644031286239624,
      "logits/rejected": 1.6066020727157593,
      "logps/chosen": -222.27816772460938,
      "logps/rejected": -238.72116088867188,
      "loss": 0.4922,
      "rewards/accuracies": 0.7000000476837158,
      "rewards/chosen": -3.220592975616455,
      "rewards/margins": 1.2782717943191528,
      "rewards/rejected": -4.498864650726318,
      "step": 2490
    },
    {
      "epoch": 0.7381163271331562,
      "grad_norm": 13.642657279968262,
      "learning_rate": 1.3406170652494833e-05,
      "logits/chosen": 1.8591352701187134,
      "logits/rejected": 1.8378957509994507,
      "logps/chosen": -227.8294677734375,
      "logps/rejected": -246.09188842773438,
      "loss": 0.3441,
      "rewards/accuracies": 0.8333333134651184,
      "rewards/chosen": -3.3963286876678467,
      "rewards/margins": 1.7526044845581055,
      "rewards/rejected": -5.1489338874816895,
      "step": 2500
    }
  ],
  "logging_steps": 10,
  "max_steps": 50805,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 6,
  "trial_name": null,
  "trial_params": null
}
