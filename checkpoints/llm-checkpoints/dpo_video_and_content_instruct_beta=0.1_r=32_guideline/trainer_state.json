{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.1809861234130499,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002952465308532625,
      "grad_norm": 1.6679085493087769,
      "learning_rate": 1.409722468260998e-05,
      "logits/chosen": 1.3163950443267822,
      "logits/rejected": 1.295025110244751,
      "logps/chosen": -188.26011657714844,
      "logps/rejected": -187.53231811523438,
      "loss": 0.6938,
      "rewards/accuracies": 0.5166667103767395,
      "rewards/chosen": 0.01493812631815672,
      "rewards/margins": -0.0012866719625890255,
      "rewards/rejected": 0.016224797815084457,
      "step": 10
    },
    {
      "epoch": 0.00590493061706525,
      "grad_norm": 1.9812248945236206,
      "learning_rate": 1.4094449365219959e-05,
      "logits/chosen": 1.0816289186477661,
      "logits/rejected": 1.0566896200180054,
      "logps/chosen": -188.89474487304688,
      "logps/rejected": -193.21630859375,
      "loss": 0.6938,
      "rewards/accuracies": 0.5000000596046448,
      "rewards/chosen": -0.0006403095903806388,
      "rewards/margins": -0.0011046089930459857,
      "rewards/rejected": 0.0004642995190806687,
      "step": 20
    },
    {
      "epoch": 0.008857395925597875,
      "grad_norm": 1.9625227451324463,
      "learning_rate": 1.4091674047829938e-05,
      "logits/chosen": 1.3286247253417969,
      "logits/rejected": 1.3404796123504639,
      "logps/chosen": -192.5899200439453,
      "logps/rejected": -191.12594604492188,
      "loss": 0.692,
      "rewards/accuracies": 0.5166666507720947,
      "rewards/chosen": -0.005629756022244692,
      "rewards/margins": 0.0024397787638008595,
      "rewards/rejected": -0.008069533854722977,
      "step": 30
    },
    {
      "epoch": 0.0118098612341305,
      "grad_norm": 1.7556151151657104,
      "learning_rate": 1.4088898730439919e-05,
      "logits/chosen": 1.3959019184112549,
      "logits/rejected": 1.389626145362854,
      "logps/chosen": -190.3701171875,
      "logps/rejected": -192.5779266357422,
      "loss": 0.6854,
      "rewards/accuracies": 0.6333333253860474,
      "rewards/chosen": -0.011286011897027493,
      "rewards/margins": 0.01599980890750885,
      "rewards/rejected": -0.027285819873213768,
      "step": 40
    },
    {
      "epoch": 0.014762326542663124,
      "grad_norm": 2.2692432403564453,
      "learning_rate": 1.4086123413049898e-05,
      "logits/chosen": 1.2686465978622437,
      "logits/rejected": 1.2498760223388672,
      "logps/chosen": -197.56130981445312,
      "logps/rejected": -196.86962890625,
      "loss": 0.6785,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.03369282931089401,
      "rewards/margins": 0.030824029818177223,
      "rewards/rejected": -0.06451685726642609,
      "step": 50
    },
    {
      "epoch": 0.01771479185119575,
      "grad_norm": 2.0968775749206543,
      "learning_rate": 1.4083348095659877e-05,
      "logits/chosen": 1.1023571491241455,
      "logits/rejected": 1.1064975261688232,
      "logps/chosen": -196.503173828125,
      "logps/rejected": -197.2303466796875,
      "loss": 0.6772,
      "rewards/accuracies": 0.5833333134651184,
      "rewards/chosen": -0.08436842262744904,
      "rewards/margins": 0.03441276401281357,
      "rewards/rejected": -0.1187811866402626,
      "step": 60
    },
    {
      "epoch": 0.020667257159728374,
      "grad_norm": 1.8844558000564575,
      "learning_rate": 1.4080572778269856e-05,
      "logits/chosen": 1.223649024963379,
      "logits/rejected": 1.2093896865844727,
      "logps/chosen": -194.44735717773438,
      "logps/rejected": -191.98007202148438,
      "loss": 0.6716,
      "rewards/accuracies": 0.6833333373069763,
      "rewards/chosen": -0.14823535084724426,
      "rewards/margins": 0.047428231686353683,
      "rewards/rejected": -0.19566360116004944,
      "step": 70
    },
    {
      "epoch": 0.023619722468261,
      "grad_norm": 2.167191505432129,
      "learning_rate": 1.4077797460879835e-05,
      "logits/chosen": 1.200514316558838,
      "logits/rejected": 1.194620966911316,
      "logps/chosen": -192.8304443359375,
      "logps/rejected": -195.03567504882812,
      "loss": 0.687,
      "rewards/accuracies": 0.5333333015441895,
      "rewards/chosen": -0.19469544291496277,
      "rewards/margins": 0.020383045077323914,
      "rewards/rejected": -0.2150784432888031,
      "step": 80
    },
    {
      "epoch": 0.026572187776793623,
      "grad_norm": 1.8391653299331665,
      "learning_rate": 1.4075022143489814e-05,
      "logits/chosen": 1.1776010990142822,
      "logits/rejected": 1.164192795753479,
      "logps/chosen": -193.01126098632812,
      "logps/rejected": -197.3560028076172,
      "loss": 0.676,
      "rewards/accuracies": 0.6333333253860474,
      "rewards/chosen": -0.2179233729839325,
      "rewards/margins": 0.04631948471069336,
      "rewards/rejected": -0.26424282789230347,
      "step": 90
    },
    {
      "epoch": 0.029524653085326247,
      "grad_norm": 2.3060414791107178,
      "learning_rate": 1.4072246826099793e-05,
      "logits/chosen": 1.4481456279754639,
      "logits/rejected": 1.423404335975647,
      "logps/chosen": -190.39169311523438,
      "logps/rejected": -188.42910766601562,
      "loss": 0.6718,
      "rewards/accuracies": 0.5333333611488342,
      "rewards/chosen": -0.249594047665596,
      "rewards/margins": 0.058133114129304886,
      "rewards/rejected": -0.3077271580696106,
      "step": 100
    },
    {
      "epoch": 0.032477118393858875,
      "grad_norm": 2.4504520893096924,
      "learning_rate": 1.4069471508709774e-05,
      "logits/chosen": 1.3212354183197021,
      "logits/rejected": 1.3001505136489868,
      "logps/chosen": -191.887451171875,
      "logps/rejected": -196.02572631835938,
      "loss": 0.651,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.1926524043083191,
      "rewards/margins": 0.11011922359466553,
      "rewards/rejected": -0.3027716279029846,
      "step": 110
    },
    {
      "epoch": 0.0354295837023915,
      "grad_norm": 2.6443369388580322,
      "learning_rate": 1.4066696191319753e-05,
      "logits/chosen": 1.144884467124939,
      "logits/rejected": 1.1536208391189575,
      "logps/chosen": -191.10101318359375,
      "logps/rejected": -195.90509033203125,
      "loss": 0.6707,
      "rewards/accuracies": 0.4833332896232605,
      "rewards/chosen": -0.27623942494392395,
      "rewards/margins": 0.0764901265501976,
      "rewards/rejected": -0.35272955894470215,
      "step": 120
    },
    {
      "epoch": 0.038382049010924124,
      "grad_norm": 3.0184335708618164,
      "learning_rate": 1.406392087392973e-05,
      "logits/chosen": 1.1022096872329712,
      "logits/rejected": 1.0936453342437744,
      "logps/chosen": -193.27810668945312,
      "logps/rejected": -198.29055786132812,
      "loss": 0.6658,
      "rewards/accuracies": 0.5166666507720947,
      "rewards/chosen": -0.2800106108188629,
      "rewards/margins": 0.08543922752141953,
      "rewards/rejected": -0.36544984579086304,
      "step": 130
    },
    {
      "epoch": 0.04133451431945675,
      "grad_norm": 4.631040573120117,
      "learning_rate": 1.4061145556539711e-05,
      "logits/chosen": 1.1325372457504272,
      "logits/rejected": 1.1201159954071045,
      "logps/chosen": -192.26309204101562,
      "logps/rejected": -195.80029296875,
      "loss": 0.6797,
      "rewards/accuracies": 0.5666667222976685,
      "rewards/chosen": -0.19191798567771912,
      "rewards/margins": 0.07050926983356476,
      "rewards/rejected": -0.26242727041244507,
      "step": 140
    },
    {
      "epoch": 0.04428697962798937,
      "grad_norm": 4.540611743927002,
      "learning_rate": 1.405837023914969e-05,
      "logits/chosen": 1.4499328136444092,
      "logits/rejected": 1.4280996322631836,
      "logps/chosen": -195.67062377929688,
      "logps/rejected": -191.3633575439453,
      "loss": 0.6644,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.12889732420444489,
      "rewards/margins": 0.09265853464603424,
      "rewards/rejected": -0.22155587375164032,
      "step": 150
    },
    {
      "epoch": 0.047239444936522,
      "grad_norm": 4.287151336669922,
      "learning_rate": 1.4055594921759671e-05,
      "logits/chosen": 0.8965250253677368,
      "logits/rejected": 0.8926364779472351,
      "logps/chosen": -197.40505981445312,
      "logps/rejected": -188.66720581054688,
      "loss": 0.6792,
      "rewards/accuracies": 0.5666666626930237,
      "rewards/chosen": -0.18037454783916473,
      "rewards/margins": 0.061235349625349045,
      "rewards/rejected": -0.24160988628864288,
      "step": 160
    },
    {
      "epoch": 0.05019191024505462,
      "grad_norm": 3.9502644538879395,
      "learning_rate": 1.4052819604369648e-05,
      "logits/chosen": 1.1591306924819946,
      "logits/rejected": 1.163309097290039,
      "logps/chosen": -189.30929565429688,
      "logps/rejected": -192.555419921875,
      "loss": 0.7255,
      "rewards/accuracies": 0.5333333611488342,
      "rewards/chosen": -0.12713633477687836,
      "rewards/margins": -0.030258914455771446,
      "rewards/rejected": -0.09687741845846176,
      "step": 170
    },
    {
      "epoch": 0.053144375553587246,
      "grad_norm": 3.4528775215148926,
      "learning_rate": 1.405004428697963e-05,
      "logits/chosen": 1.4292628765106201,
      "logits/rejected": 1.4242165088653564,
      "logps/chosen": -191.7925567626953,
      "logps/rejected": -194.33726501464844,
      "loss": 0.6004,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": 0.06182248517870903,
      "rewards/margins": 0.23165583610534668,
      "rewards/rejected": -0.16983334720134735,
      "step": 180
    },
    {
      "epoch": 0.05609684086211987,
      "grad_norm": 3.3132870197296143,
      "learning_rate": 1.4047268969589608e-05,
      "logits/chosen": 1.4588228464126587,
      "logits/rejected": 1.4415382146835327,
      "logps/chosen": -189.73126220703125,
      "logps/rejected": -193.24221801757812,
      "loss": 0.669,
      "rewards/accuracies": 0.5833333730697632,
      "rewards/chosen": -0.033274997025728226,
      "rewards/margins": 0.09554506838321686,
      "rewards/rejected": -0.12882007658481598,
      "step": 190
    },
    {
      "epoch": 0.059049306170652495,
      "grad_norm": 4.620922565460205,
      "learning_rate": 1.4044493652199586e-05,
      "logits/chosen": 1.396113634109497,
      "logits/rejected": 1.4153512716293335,
      "logps/chosen": -196.70509338378906,
      "logps/rejected": -198.3530731201172,
      "loss": 0.6608,
      "rewards/accuracies": 0.6333333253860474,
      "rewards/chosen": -0.04336482658982277,
      "rewards/margins": 0.12052655220031738,
      "rewards/rejected": -0.16389136016368866,
      "step": 200
    },
    {
      "epoch": 0.06200177147918512,
      "grad_norm": 3.7829530239105225,
      "learning_rate": 1.4041718334809567e-05,
      "logits/chosen": 1.1892964839935303,
      "logits/rejected": 1.1847786903381348,
      "logps/chosen": -200.33338928222656,
      "logps/rejected": -193.14791870117188,
      "loss": 0.658,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.0833594799041748,
      "rewards/margins": 0.11519128084182739,
      "rewards/rejected": -0.1985507607460022,
      "step": 210
    },
    {
      "epoch": 0.06495423678771775,
      "grad_norm": 4.058221340179443,
      "learning_rate": 1.4038943017419546e-05,
      "logits/chosen": 1.252482295036316,
      "logits/rejected": 1.2444968223571777,
      "logps/chosen": -194.92417907714844,
      "logps/rejected": -195.31048583984375,
      "loss": 0.658,
      "rewards/accuracies": 0.6166666746139526,
      "rewards/chosen": -0.08455131947994232,
      "rewards/margins": 0.1268441379070282,
      "rewards/rejected": -0.21139545738697052,
      "step": 220
    },
    {
      "epoch": 0.06790670209625037,
      "grad_norm": 3.745450258255005,
      "learning_rate": 1.4036167700029526e-05,
      "logits/chosen": 1.385107159614563,
      "logits/rejected": 1.3698781728744507,
      "logps/chosen": -194.59793090820312,
      "logps/rejected": -196.3892822265625,
      "loss": 0.6736,
      "rewards/accuracies": 0.5666667222976685,
      "rewards/chosen": 0.08112544566392899,
      "rewards/margins": 0.08153979480266571,
      "rewards/rejected": -0.00041435210732743144,
      "step": 230
    },
    {
      "epoch": 0.070859167404783,
      "grad_norm": 2.9725348949432373,
      "learning_rate": 1.4033392382639504e-05,
      "logits/chosen": 1.1615731716156006,
      "logits/rejected": 1.1560640335083008,
      "logps/chosen": -185.8077392578125,
      "logps/rejected": -186.9185333251953,
      "loss": 0.6222,
      "rewards/accuracies": 0.6833333373069763,
      "rewards/chosen": 0.1949777603149414,
      "rewards/margins": 0.18908299505710602,
      "rewards/rejected": 0.00589474942535162,
      "step": 240
    },
    {
      "epoch": 0.07381163271331562,
      "grad_norm": 4.325450897216797,
      "learning_rate": 1.4030617065249485e-05,
      "logits/chosen": 1.5378572940826416,
      "logits/rejected": 1.5322496891021729,
      "logps/chosen": -188.58370971679688,
      "logps/rejected": -192.54074096679688,
      "loss": 0.6617,
      "rewards/accuracies": 0.5500000715255737,
      "rewards/chosen": 0.24724681675434113,
      "rewards/margins": 0.1351567804813385,
      "rewards/rejected": 0.11209002882242203,
      "step": 250
    },
    {
      "epoch": 0.07676409802184825,
      "grad_norm": 3.1030044555664062,
      "learning_rate": 1.4027841747859464e-05,
      "logits/chosen": 1.2079741954803467,
      "logits/rejected": 1.1819932460784912,
      "logps/chosen": -185.81826782226562,
      "logps/rejected": -193.75759887695312,
      "loss": 0.5707,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": 0.2342633306980133,
      "rewards/margins": 0.31327393651008606,
      "rewards/rejected": -0.07901062816381454,
      "step": 260
    },
    {
      "epoch": 0.07971656333038087,
      "grad_norm": 4.69927978515625,
      "learning_rate": 1.4025066430469443e-05,
      "logits/chosen": 1.6036651134490967,
      "logits/rejected": 1.599760890007019,
      "logps/chosen": -192.2106475830078,
      "logps/rejected": -191.76205444335938,
      "loss": 0.6552,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.25549736618995667,
      "rewards/margins": 0.15238171815872192,
      "rewards/rejected": 0.10311566293239594,
      "step": 270
    },
    {
      "epoch": 0.0826690286389135,
      "grad_norm": 3.630969524383545,
      "learning_rate": 1.4022291113079422e-05,
      "logits/chosen": 1.1886093616485596,
      "logits/rejected": 1.154433012008667,
      "logps/chosen": -183.30165100097656,
      "logps/rejected": -190.86807250976562,
      "loss": 0.5877,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": 0.38790780305862427,
      "rewards/margins": 0.3166651129722595,
      "rewards/rejected": 0.07124273478984833,
      "step": 280
    },
    {
      "epoch": 0.08562149394744611,
      "grad_norm": 4.337339878082275,
      "learning_rate": 1.4019515795689401e-05,
      "logits/chosen": 1.238832712173462,
      "logits/rejected": 1.2280035018920898,
      "logps/chosen": -187.2677459716797,
      "logps/rejected": -191.61102294921875,
      "loss": 0.6071,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": -0.0029330463148653507,
      "rewards/margins": 0.26880979537963867,
      "rewards/rejected": -0.27174288034439087,
      "step": 290
    },
    {
      "epoch": 0.08857395925597875,
      "grad_norm": 3.1550943851470947,
      "learning_rate": 1.4016740478299382e-05,
      "logits/chosen": 0.9376860857009888,
      "logits/rejected": 0.908215343952179,
      "logps/chosen": -189.13121032714844,
      "logps/rejected": -197.40408325195312,
      "loss": 0.5776,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.20738092064857483,
      "rewards/margins": 0.3554242253303528,
      "rewards/rejected": -0.14804331958293915,
      "step": 300
    },
    {
      "epoch": 0.09152642456451136,
      "grad_norm": 5.293827533721924,
      "learning_rate": 1.4013965160909359e-05,
      "logits/chosen": 1.2593042850494385,
      "logits/rejected": 1.2576757669448853,
      "logps/chosen": -193.03384399414062,
      "logps/rejected": -197.1147003173828,
      "loss": 0.5531,
      "rewards/accuracies": 0.7000000476837158,
      "rewards/chosen": 0.012028905563056469,
      "rewards/margins": 0.3902202248573303,
      "rewards/rejected": -0.3781912922859192,
      "step": 310
    },
    {
      "epoch": 0.094478889873044,
      "grad_norm": 5.352402687072754,
      "learning_rate": 1.4011189843519338e-05,
      "logits/chosen": 1.3172454833984375,
      "logits/rejected": 1.321548581123352,
      "logps/chosen": -192.3401336669922,
      "logps/rejected": -196.40338134765625,
      "loss": 0.5783,
      "rewards/accuracies": 0.6999999284744263,
      "rewards/chosen": 0.056578803807497025,
      "rewards/margins": 0.36487430334091187,
      "rewards/rejected": -0.30829551815986633,
      "step": 320
    },
    {
      "epoch": 0.09743135518157661,
      "grad_norm": 10.026690483093262,
      "learning_rate": 1.4008414526129319e-05,
      "logits/chosen": 1.1030714511871338,
      "logits/rejected": 1.1130080223083496,
      "logps/chosen": -192.13851928710938,
      "logps/rejected": -193.59088134765625,
      "loss": 0.6414,
      "rewards/accuracies": 0.6333333253860474,
      "rewards/chosen": 0.055295102298259735,
      "rewards/margins": 0.19160673022270203,
      "rewards/rejected": -0.1363116204738617,
      "step": 330
    },
    {
      "epoch": 0.10038382049010924,
      "grad_norm": 6.331115245819092,
      "learning_rate": 1.4005639208739298e-05,
      "logits/chosen": 1.6091644763946533,
      "logits/rejected": 1.6061195135116577,
      "logps/chosen": -188.35067749023438,
      "logps/rejected": -187.3347625732422,
      "loss": 0.5477,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": 0.4333586096763611,
      "rewards/margins": 0.4175632894039154,
      "rewards/rejected": 0.015795309096574783,
      "step": 340
    },
    {
      "epoch": 0.10333628579864186,
      "grad_norm": 6.189100742340088,
      "learning_rate": 1.4002863891349277e-05,
      "logits/chosen": 1.451856017112732,
      "logits/rejected": 1.4584990739822388,
      "logps/chosen": -195.68283081054688,
      "logps/rejected": -195.28054809570312,
      "loss": 0.6363,
      "rewards/accuracies": 0.6333333253860474,
      "rewards/chosen": -0.3257672190666199,
      "rewards/margins": 0.24154171347618103,
      "rewards/rejected": -0.5673089623451233,
      "step": 350
    },
    {
      "epoch": 0.10628875110717449,
      "grad_norm": 4.33870792388916,
      "learning_rate": 1.4000088573959256e-05,
      "logits/chosen": 1.721693754196167,
      "logits/rejected": 1.7042274475097656,
      "logps/chosen": -195.85984802246094,
      "logps/rejected": -202.40042114257812,
      "loss": 0.5351,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -0.377876341342926,
      "rewards/margins": 0.44985252618789673,
      "rewards/rejected": -0.8277287483215332,
      "step": 360
    },
    {
      "epoch": 0.10924121641570711,
      "grad_norm": 5.9729838371276855,
      "learning_rate": 1.3997313256569237e-05,
      "logits/chosen": 1.7267179489135742,
      "logits/rejected": 1.7092078924179077,
      "logps/chosen": -198.197265625,
      "logps/rejected": -202.08651733398438,
      "loss": 0.6305,
      "rewards/accuracies": 0.6666666269302368,
      "rewards/chosen": -0.4697350859642029,
      "rewards/margins": 0.24590475857257843,
      "rewards/rejected": -0.7156398296356201,
      "step": 370
    },
    {
      "epoch": 0.11219368172423974,
      "grad_norm": 6.878342151641846,
      "learning_rate": 1.3994537939179214e-05,
      "logits/chosen": 1.0931222438812256,
      "logits/rejected": 1.1013003587722778,
      "logps/chosen": -191.40005493164062,
      "logps/rejected": -197.43832397460938,
      "loss": 0.5716,
      "rewards/accuracies": 0.6833333373069763,
      "rewards/chosen": -0.2582472264766693,
      "rewards/margins": 0.45802420377731323,
      "rewards/rejected": -0.7162715196609497,
      "step": 380
    },
    {
      "epoch": 0.11514614703277236,
      "grad_norm": 5.161092281341553,
      "learning_rate": 1.3991762621789194e-05,
      "logits/chosen": 1.1736077070236206,
      "logits/rejected": 1.1796709299087524,
      "logps/chosen": -195.00279235839844,
      "logps/rejected": -198.90708923339844,
      "loss": 0.5535,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -0.21737010776996613,
      "rewards/margins": 0.5003905892372131,
      "rewards/rejected": -0.7177606821060181,
      "step": 390
    },
    {
      "epoch": 0.11809861234130499,
      "grad_norm": 5.3378143310546875,
      "learning_rate": 1.3988987304399174e-05,
      "logits/chosen": 1.6110525131225586,
      "logits/rejected": 1.6213066577911377,
      "logps/chosen": -198.57835388183594,
      "logps/rejected": -197.31871032714844,
      "loss": 0.6375,
      "rewards/accuracies": 0.6833333969116211,
      "rewards/chosen": -0.519882082939148,
      "rewards/margins": 0.3187263607978821,
      "rewards/rejected": -0.8386083841323853,
      "step": 400
    },
    {
      "epoch": 0.12105107764983762,
      "grad_norm": 4.281058311462402,
      "learning_rate": 1.3986211987009153e-05,
      "logits/chosen": 1.7067716121673584,
      "logits/rejected": 1.6785106658935547,
      "logps/chosen": -193.8726348876953,
      "logps/rejected": -195.8690948486328,
      "loss": 0.5377,
      "rewards/accuracies": 0.7666667699813843,
      "rewards/chosen": -0.5168667435646057,
      "rewards/margins": 0.46979039907455444,
      "rewards/rejected": -0.9866571426391602,
      "step": 410
    },
    {
      "epoch": 0.12400354295837024,
      "grad_norm": 6.924513339996338,
      "learning_rate": 1.3983436669619133e-05,
      "logits/chosen": 1.6769517660140991,
      "logits/rejected": 1.6663461923599243,
      "logps/chosen": -197.52024841308594,
      "logps/rejected": -200.78775024414062,
      "loss": 0.5269,
      "rewards/accuracies": 0.7000000476837158,
      "rewards/chosen": -0.3740094304084778,
      "rewards/margins": 0.527606189250946,
      "rewards/rejected": -0.9016156196594238,
      "step": 420
    },
    {
      "epoch": 0.12695600826690287,
      "grad_norm": 5.216395854949951,
      "learning_rate": 1.3980661352229112e-05,
      "logits/chosen": 1.582249402999878,
      "logits/rejected": 1.5770212411880493,
      "logps/chosen": -199.21463012695312,
      "logps/rejected": -200.1426544189453,
      "loss": 0.6883,
      "rewards/accuracies": 0.5833333730697632,
      "rewards/chosen": -0.569111704826355,
      "rewards/margins": 0.1844874918460846,
      "rewards/rejected": -0.7535991668701172,
      "step": 430
    },
    {
      "epoch": 0.1299084735754355,
      "grad_norm": 7.478115558624268,
      "learning_rate": 1.3977886034839092e-05,
      "logits/chosen": 1.4185559749603271,
      "logits/rejected": 1.422137975692749,
      "logps/chosen": -195.01441955566406,
      "logps/rejected": -203.3802032470703,
      "loss": 0.6275,
      "rewards/accuracies": 0.6166666746139526,
      "rewards/chosen": -0.22044813632965088,
      "rewards/margins": 0.3313215374946594,
      "rewards/rejected": -0.5517696738243103,
      "step": 440
    },
    {
      "epoch": 0.1328609388839681,
      "grad_norm": 6.546402454376221,
      "learning_rate": 1.397511071744907e-05,
      "logits/chosen": 1.4084579944610596,
      "logits/rejected": 1.3918402194976807,
      "logps/chosen": -193.29083251953125,
      "logps/rejected": -195.42774963378906,
      "loss": 0.482,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": 0.14833512902259827,
      "rewards/margins": 0.6549378633499146,
      "rewards/rejected": -0.5066027641296387,
      "step": 450
    },
    {
      "epoch": 0.13581340419250074,
      "grad_norm": 7.340824604034424,
      "learning_rate": 1.3972335400059049e-05,
      "logits/chosen": 1.3701339960098267,
      "logits/rejected": 1.3961457014083862,
      "logps/chosen": -200.71026611328125,
      "logps/rejected": -198.08091735839844,
      "loss": 0.6158,
      "rewards/accuracies": 0.5833333730697632,
      "rewards/chosen": -0.45223164558410645,
      "rewards/margins": 0.29829519987106323,
      "rewards/rejected": -0.7505267858505249,
      "step": 460
    },
    {
      "epoch": 0.13876586950103337,
      "grad_norm": 4.373767852783203,
      "learning_rate": 1.396956008266903e-05,
      "logits/chosen": 1.027295470237732,
      "logits/rejected": 1.031782627105713,
      "logps/chosen": -193.41415405273438,
      "logps/rejected": -196.322509765625,
      "loss": 0.5432,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -0.2368394434452057,
      "rewards/margins": 0.5144467949867249,
      "rewards/rejected": -0.7512862086296082,
      "step": 470
    },
    {
      "epoch": 0.141718334809566,
      "grad_norm": 5.2234206199646,
      "learning_rate": 1.3966784765279009e-05,
      "logits/chosen": 1.5841565132141113,
      "logits/rejected": 1.5681902170181274,
      "logps/chosen": -187.58705139160156,
      "logps/rejected": -196.79531860351562,
      "loss": 0.6206,
      "rewards/accuracies": 0.6666666865348816,
      "rewards/chosen": 0.0732032060623169,
      "rewards/margins": 0.3161352574825287,
      "rewards/rejected": -0.2429320514202118,
      "step": 480
    },
    {
      "epoch": 0.1446708001180986,
      "grad_norm": 4.839746952056885,
      "learning_rate": 1.3964009447888988e-05,
      "logits/chosen": 2.0335705280303955,
      "logits/rejected": 2.0044736862182617,
      "logps/chosen": -189.8508758544922,
      "logps/rejected": -192.4295654296875,
      "loss": 0.5505,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": 0.2527107298374176,
      "rewards/margins": 0.4909486174583435,
      "rewards/rejected": -0.23823793232440948,
      "step": 490
    },
    {
      "epoch": 0.14762326542663123,
      "grad_norm": 8.474494934082031,
      "learning_rate": 1.3961234130498967e-05,
      "logits/chosen": 1.5221954584121704,
      "logits/rejected": 1.5036510229110718,
      "logps/chosen": -191.12142944335938,
      "logps/rejected": -197.06878662109375,
      "loss": 0.5878,
      "rewards/accuracies": 0.6833333373069763,
      "rewards/chosen": 0.12255720794200897,
      "rewards/margins": 0.3607734143733978,
      "rewards/rejected": -0.23821623623371124,
      "step": 500
    },
    {
      "epoch": 0.15057573073516387,
      "grad_norm": 5.455799102783203,
      "learning_rate": 1.3958458813108946e-05,
      "logits/chosen": 1.6846637725830078,
      "logits/rejected": 1.6706092357635498,
      "logps/chosen": -187.89956665039062,
      "logps/rejected": -193.3470458984375,
      "loss": 0.5724,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.09783384203910828,
      "rewards/margins": 0.5389536619186401,
      "rewards/rejected": -0.44111984968185425,
      "step": 510
    },
    {
      "epoch": 0.1535281960436965,
      "grad_norm": 9.712525367736816,
      "learning_rate": 1.3955683495718927e-05,
      "logits/chosen": 1.5154314041137695,
      "logits/rejected": 1.5004998445510864,
      "logps/chosen": -193.40211486816406,
      "logps/rejected": -200.68800354003906,
      "loss": 0.5895,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.20585997402668,
      "rewards/margins": 0.43901723623275757,
      "rewards/rejected": -0.6448771357536316,
      "step": 520
    },
    {
      "epoch": 0.1564806613522291,
      "grad_norm": 7.3644561767578125,
      "learning_rate": 1.3952908178328904e-05,
      "logits/chosen": 1.651282548904419,
      "logits/rejected": 1.605571985244751,
      "logps/chosen": -197.5159454345703,
      "logps/rejected": -199.32553100585938,
      "loss": 0.5566,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -0.3843417465686798,
      "rewards/margins": 0.5140015482902527,
      "rewards/rejected": -0.8983432650566101,
      "step": 530
    },
    {
      "epoch": 0.15943312666076173,
      "grad_norm": 6.950796604156494,
      "learning_rate": 1.3950132860938885e-05,
      "logits/chosen": 1.4003444910049438,
      "logits/rejected": 1.3973586559295654,
      "logps/chosen": -197.37171936035156,
      "logps/rejected": -200.85830688476562,
      "loss": 0.5878,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -0.4141266345977783,
      "rewards/margins": 0.4524826109409332,
      "rewards/rejected": -0.8666092157363892,
      "step": 540
    },
    {
      "epoch": 0.16238559196929436,
      "grad_norm": 13.512359619140625,
      "learning_rate": 1.3947357543548864e-05,
      "logits/chosen": 1.71316397190094,
      "logits/rejected": 1.6991745233535767,
      "logps/chosen": -192.09390258789062,
      "logps/rejected": -200.2991180419922,
      "loss": 0.4426,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.31709447503089905,
      "rewards/margins": 0.9771798849105835,
      "rewards/rejected": -1.2942743301391602,
      "step": 550
    },
    {
      "epoch": 0.165338057277827,
      "grad_norm": 7.5016608238220215,
      "learning_rate": 1.3944582226158843e-05,
      "logits/chosen": 1.4190157651901245,
      "logits/rejected": 1.397769570350647,
      "logps/chosen": -196.3062744140625,
      "logps/rejected": -203.023193359375,
      "loss": 0.5747,
      "rewards/accuracies": 0.6666666865348816,
      "rewards/chosen": -0.31903892755508423,
      "rewards/margins": 0.4381542205810547,
      "rewards/rejected": -0.7571932077407837,
      "step": 560
    },
    {
      "epoch": 0.1682905225863596,
      "grad_norm": 8.862321853637695,
      "learning_rate": 1.3941806908768822e-05,
      "logits/chosen": 1.6507947444915771,
      "logits/rejected": 1.634508490562439,
      "logps/chosen": -195.4605712890625,
      "logps/rejected": -203.16168212890625,
      "loss": 0.5491,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.7009005546569824,
      "rewards/margins": 0.5517116189002991,
      "rewards/rejected": -1.2526122331619263,
      "step": 570
    },
    {
      "epoch": 0.17124298789489223,
      "grad_norm": 8.572301864624023,
      "learning_rate": 1.3939031591378801e-05,
      "logits/chosen": 1.5527796745300293,
      "logits/rejected": 1.5554765462875366,
      "logps/chosen": -203.1864471435547,
      "logps/rejected": -209.63589477539062,
      "loss": 0.6382,
      "rewards/accuracies": 0.6333333253860474,
      "rewards/chosen": -0.9296405911445618,
      "rewards/margins": 0.427315890789032,
      "rewards/rejected": -1.3569567203521729,
      "step": 580
    },
    {
      "epoch": 0.17419545320342486,
      "grad_norm": 10.827735900878906,
      "learning_rate": 1.3936256273988782e-05,
      "logits/chosen": 1.607672095298767,
      "logits/rejected": 1.5917370319366455,
      "logps/chosen": -198.20590209960938,
      "logps/rejected": -203.5550994873047,
      "loss": 0.5355,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -0.5957968235015869,
      "rewards/margins": 0.6727001070976257,
      "rewards/rejected": -1.2684969902038574,
      "step": 590
    },
    {
      "epoch": 0.1771479185119575,
      "grad_norm": 5.1767683029174805,
      "learning_rate": 1.393348095659876e-05,
      "logits/chosen": 1.7136447429656982,
      "logits/rejected": 1.7289421558380127,
      "logps/chosen": -203.92312622070312,
      "logps/rejected": -206.67843627929688,
      "loss": 0.5337,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9750642776489258,
      "rewards/margins": 0.631384015083313,
      "rewards/rejected": -1.6064484119415283,
      "step": 600
    },
    {
      "epoch": 0.18010038382049012,
      "grad_norm": 9.803211212158203,
      "learning_rate": 1.393070563920874e-05,
      "logits/chosen": 1.3029720783233643,
      "logits/rejected": 1.2817301750183105,
      "logps/chosen": -196.36660766601562,
      "logps/rejected": -203.23463439941406,
      "loss": 0.5413,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.6328852772712708,
      "rewards/margins": 0.5570027828216553,
      "rewards/rejected": -1.1898878812789917,
      "step": 610
    },
    {
      "epoch": 0.18305284912902273,
      "grad_norm": 8.100458145141602,
      "learning_rate": 1.392793032181872e-05,
      "logits/chosen": 1.6452715396881104,
      "logits/rejected": 1.6206741333007812,
      "logps/chosen": -195.28591918945312,
      "logps/rejected": -202.88424682617188,
      "loss": 0.5552,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": -0.37176576256752014,
      "rewards/margins": 0.6265665292739868,
      "rewards/rejected": -0.9983322024345398,
      "step": 620
    },
    {
      "epoch": 0.18600531443755536,
      "grad_norm": 17.513731002807617,
      "learning_rate": 1.3925155004428697e-05,
      "logits/chosen": 1.6810232400894165,
      "logits/rejected": 1.660459280014038,
      "logps/chosen": -196.9962158203125,
      "logps/rejected": -203.01724243164062,
      "loss": 0.5974,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5827935934066772,
      "rewards/margins": 0.5433915853500366,
      "rewards/rejected": -1.1261851787567139,
      "step": 630
    },
    {
      "epoch": 0.188957779746088,
      "grad_norm": 11.85683536529541,
      "learning_rate": 1.3922379687038678e-05,
      "logits/chosen": 1.4123656749725342,
      "logits/rejected": 1.3985894918441772,
      "logps/chosen": -200.14138793945312,
      "logps/rejected": -199.87423706054688,
      "loss": 0.5524,
      "rewards/accuracies": 0.7000000476837158,
      "rewards/chosen": -0.7585046291351318,
      "rewards/margins": 0.5784589648246765,
      "rewards/rejected": -1.3369635343551636,
      "step": 640
    },
    {
      "epoch": 0.19191024505462062,
      "grad_norm": 13.129853248596191,
      "learning_rate": 1.3919604369648657e-05,
      "logits/chosen": 1.2822368144989014,
      "logits/rejected": 1.2874641418457031,
      "logps/chosen": -193.5782470703125,
      "logps/rejected": -196.95626831054688,
      "loss": 0.5857,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": -0.5862565636634827,
      "rewards/margins": 0.5714415311813354,
      "rewards/rejected": -1.1576982736587524,
      "step": 650
    },
    {
      "epoch": 0.19486271036315322,
      "grad_norm": 6.484643459320068,
      "learning_rate": 1.3916829052258638e-05,
      "logits/chosen": 1.3544518947601318,
      "logits/rejected": 1.3391717672348022,
      "logps/chosen": -197.18270874023438,
      "logps/rejected": -202.9368438720703,
      "loss": 0.5777,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.3226294219493866,
      "rewards/margins": 0.6095346808433533,
      "rewards/rejected": -0.9321640729904175,
      "step": 660
    },
    {
      "epoch": 0.19781517567168586,
      "grad_norm": 15.009284019470215,
      "learning_rate": 1.3914053734868615e-05,
      "logits/chosen": 1.9556468725204468,
      "logits/rejected": 1.9356054067611694,
      "logps/chosen": -194.5548858642578,
      "logps/rejected": -204.35205078125,
      "loss": 0.5849,
      "rewards/accuracies": 0.6500000357627869,
      "rewards/chosen": -0.10491206496953964,
      "rewards/margins": 0.48025745153427124,
      "rewards/rejected": -0.5851696133613586,
      "step": 670
    },
    {
      "epoch": 0.2007676409802185,
      "grad_norm": 11.531158447265625,
      "learning_rate": 1.3911278417478596e-05,
      "logits/chosen": 1.7948713302612305,
      "logits/rejected": 1.7592147588729858,
      "logps/chosen": -202.28526306152344,
      "logps/rejected": -206.9293670654297,
      "loss": 0.5857,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.7145658135414124,
      "rewards/margins": 0.5463818311691284,
      "rewards/rejected": -1.260947585105896,
      "step": 680
    },
    {
      "epoch": 0.20372010628875112,
      "grad_norm": 8.758695602416992,
      "learning_rate": 1.3908503100088575e-05,
      "logits/chosen": 1.654526710510254,
      "logits/rejected": 1.6220977306365967,
      "logps/chosen": -205.5690460205078,
      "logps/rejected": -217.84597778320312,
      "loss": 0.5653,
      "rewards/accuracies": 0.7166666388511658,
      "rewards/chosen": -1.6412239074707031,
      "rewards/margins": 0.5346428751945496,
      "rewards/rejected": -2.1758668422698975,
      "step": 690
    },
    {
      "epoch": 0.20667257159728372,
      "grad_norm": 6.9325947761535645,
      "learning_rate": 1.3905727782698554e-05,
      "logits/chosen": 1.7840909957885742,
      "logits/rejected": 1.7705589532852173,
      "logps/chosen": -203.45840454101562,
      "logps/rejected": -211.3821563720703,
      "loss": 0.5453,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -1.3180232048034668,
      "rewards/margins": 0.5886237025260925,
      "rewards/rejected": -1.906646966934204,
      "step": 700
    },
    {
      "epoch": 0.20962503690581635,
      "grad_norm": 5.255789756774902,
      "learning_rate": 1.3902952465308533e-05,
      "logits/chosen": 1.5460247993469238,
      "logits/rejected": 1.5268275737762451,
      "logps/chosen": -196.31495666503906,
      "logps/rejected": -205.9846954345703,
      "loss": 0.4597,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.4804108142852783,
      "rewards/margins": 0.9415706396102905,
      "rewards/rejected": -1.4219814538955688,
      "step": 710
    },
    {
      "epoch": 0.21257750221434898,
      "grad_norm": 5.02420711517334,
      "learning_rate": 1.3900177147918512e-05,
      "logits/chosen": 1.8122316598892212,
      "logits/rejected": 1.7924606800079346,
      "logps/chosen": -200.14515686035156,
      "logps/rejected": -206.4359588623047,
      "loss": 0.6315,
      "rewards/accuracies": 0.6833333373069763,
      "rewards/chosen": -0.9444215893745422,
      "rewards/margins": 0.559006929397583,
      "rewards/rejected": -1.503428339958191,
      "step": 720
    },
    {
      "epoch": 0.21552996752288162,
      "grad_norm": 7.677519798278809,
      "learning_rate": 1.3897401830528493e-05,
      "logits/chosen": 1.045641303062439,
      "logits/rejected": 1.0404492616653442,
      "logps/chosen": -207.1392364501953,
      "logps/rejected": -212.0641632080078,
      "loss": 0.6271,
      "rewards/accuracies": 0.6333333253860474,
      "rewards/chosen": -1.9417740106582642,
      "rewards/margins": 0.3787049651145935,
      "rewards/rejected": -2.320478916168213,
      "step": 730
    },
    {
      "epoch": 0.21848243283141422,
      "grad_norm": 4.300086498260498,
      "learning_rate": 1.389462651313847e-05,
      "logits/chosen": 1.6318432092666626,
      "logits/rejected": 1.5932117700576782,
      "logps/chosen": -217.016357421875,
      "logps/rejected": -219.87918090820312,
      "loss": 0.4817,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.1930506229400635,
      "rewards/margins": 0.7295680642127991,
      "rewards/rejected": -2.9226186275482178,
      "step": 740
    },
    {
      "epoch": 0.22143489813994685,
      "grad_norm": 8.665371894836426,
      "learning_rate": 1.3891851195748451e-05,
      "logits/chosen": 1.3674259185791016,
      "logits/rejected": 1.3547977209091187,
      "logps/chosen": -216.1984100341797,
      "logps/rejected": -223.07373046875,
      "loss": 0.5746,
      "rewards/accuracies": 0.6833333373069763,
      "rewards/chosen": -2.12206768989563,
      "rewards/margins": 0.5470091104507446,
      "rewards/rejected": -2.669076681137085,
      "step": 750
    },
    {
      "epoch": 0.22438736344847948,
      "grad_norm": 8.332193374633789,
      "learning_rate": 1.388907587835843e-05,
      "logits/chosen": 1.9906949996948242,
      "logits/rejected": 1.9765859842300415,
      "logps/chosen": -213.06509399414062,
      "logps/rejected": -218.3328857421875,
      "loss": 0.5744,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": -1.9199966192245483,
      "rewards/margins": 0.6769169569015503,
      "rewards/rejected": -2.5969138145446777,
      "step": 760
    },
    {
      "epoch": 0.2273398287570121,
      "grad_norm": 6.103339672088623,
      "learning_rate": 1.388630056096841e-05,
      "logits/chosen": 1.928613305091858,
      "logits/rejected": 1.9054968357086182,
      "logps/chosen": -200.99964904785156,
      "logps/rejected": -209.3754119873047,
      "loss": 0.5345,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.1689717769622803,
      "rewards/margins": 0.7331969141960144,
      "rewards/rejected": -1.90216863155365,
      "step": 770
    },
    {
      "epoch": 0.23029229406554472,
      "grad_norm": 6.418448448181152,
      "learning_rate": 1.3883525243578388e-05,
      "logits/chosen": 1.4570674896240234,
      "logits/rejected": 1.4235891103744507,
      "logps/chosen": -200.81253051757812,
      "logps/rejected": -211.59170532226562,
      "loss": 0.5046,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -1.007707953453064,
      "rewards/margins": 0.8069156408309937,
      "rewards/rejected": -1.8146235942840576,
      "step": 780
    },
    {
      "epoch": 0.23324475937407735,
      "grad_norm": 8.33934497833252,
      "learning_rate": 1.3880749926188367e-05,
      "logits/chosen": 1.5619279146194458,
      "logits/rejected": 1.5374114513397217,
      "logps/chosen": -203.60739135742188,
      "logps/rejected": -211.75296020507812,
      "loss": 0.4851,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -1.087677001953125,
      "rewards/margins": 0.9038565754890442,
      "rewards/rejected": -1.991533637046814,
      "step": 790
    },
    {
      "epoch": 0.23619722468260998,
      "grad_norm": 5.138166427612305,
      "learning_rate": 1.3877974608798348e-05,
      "logits/chosen": 1.9492590427398682,
      "logits/rejected": 1.931825876235962,
      "logps/chosen": -201.5854034423828,
      "logps/rejected": -209.51974487304688,
      "loss": 0.5435,
      "rewards/accuracies": 0.7166666388511658,
      "rewards/chosen": -1.1496951580047607,
      "rewards/margins": 0.755763590335846,
      "rewards/rejected": -1.9054588079452515,
      "step": 800
    },
    {
      "epoch": 0.2391496899911426,
      "grad_norm": 10.359140396118164,
      "learning_rate": 1.3875199291408326e-05,
      "logits/chosen": 1.820840835571289,
      "logits/rejected": 1.8106231689453125,
      "logps/chosen": -203.36721801757812,
      "logps/rejected": -212.40322875976562,
      "loss": 0.5742,
      "rewards/accuracies": 0.6666666269302368,
      "rewards/chosen": -1.1280142068862915,
      "rewards/margins": 0.7798991203308105,
      "rewards/rejected": -1.9079134464263916,
      "step": 810
    },
    {
      "epoch": 0.24210215529967524,
      "grad_norm": 9.49273681640625,
      "learning_rate": 1.3872423974018305e-05,
      "logits/chosen": 1.947005271911621,
      "logits/rejected": 1.9435631036758423,
      "logps/chosen": -207.2179412841797,
      "logps/rejected": -214.86788940429688,
      "loss": 0.4776,
      "rewards/accuracies": 0.7333332896232605,
      "rewards/chosen": -1.1342576742172241,
      "rewards/margins": 0.8822417259216309,
      "rewards/rejected": -2.0164995193481445,
      "step": 820
    },
    {
      "epoch": 0.24505462060820785,
      "grad_norm": 7.151697158813477,
      "learning_rate": 1.3869648656628285e-05,
      "logits/chosen": 1.7463388442993164,
      "logits/rejected": 1.6956487894058228,
      "logps/chosen": -209.41506958007812,
      "logps/rejected": -221.5378875732422,
      "loss": 0.4828,
      "rewards/accuracies": 0.7666667699813843,
      "rewards/chosen": -1.4422399997711182,
      "rewards/margins": 0.7942317128181458,
      "rewards/rejected": -2.236471652984619,
      "step": 830
    },
    {
      "epoch": 0.24800708591674048,
      "grad_norm": 8.914382934570312,
      "learning_rate": 1.3866873339238265e-05,
      "logits/chosen": 1.6714146137237549,
      "logits/rejected": 1.646619439125061,
      "logps/chosen": -205.0666046142578,
      "logps/rejected": -207.4016571044922,
      "loss": 0.5002,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -1.0493441820144653,
      "rewards/margins": 0.8461869359016418,
      "rewards/rejected": -1.8955309391021729,
      "step": 840
    },
    {
      "epoch": 0.2509595512252731,
      "grad_norm": 7.256534576416016,
      "learning_rate": 1.3864098021848244e-05,
      "logits/chosen": 2.1807210445404053,
      "logits/rejected": 2.1766488552093506,
      "logps/chosen": -198.8083953857422,
      "logps/rejected": -208.1200714111328,
      "loss": 0.5044,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -1.16326105594635,
      "rewards/margins": 0.8944520950317383,
      "rewards/rejected": -2.057713031768799,
      "step": 850
    },
    {
      "epoch": 0.25391201653380574,
      "grad_norm": 9.827410697937012,
      "learning_rate": 1.3861322704458223e-05,
      "logits/chosen": 1.2667344808578491,
      "logits/rejected": 1.2566596269607544,
      "logps/chosen": -208.36416625976562,
      "logps/rejected": -217.05545043945312,
      "loss": 0.5421,
      "rewards/accuracies": 0.6666666269302368,
      "rewards/chosen": -1.1700646877288818,
      "rewards/margins": 0.8592768907546997,
      "rewards/rejected": -2.029341697692871,
      "step": 860
    },
    {
      "epoch": 0.25686448184233834,
      "grad_norm": 9.706259727478027,
      "learning_rate": 1.3858547387068204e-05,
      "logits/chosen": 1.587172031402588,
      "logits/rejected": 1.560068130493164,
      "logps/chosen": -199.06927490234375,
      "logps/rejected": -210.4639892578125,
      "loss": 0.4636,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.101255178451538,
      "rewards/margins": 0.9410642385482788,
      "rewards/rejected": -2.0423197746276855,
      "step": 870
    },
    {
      "epoch": 0.259816947150871,
      "grad_norm": 7.526109218597412,
      "learning_rate": 1.3855772069678183e-05,
      "logits/chosen": 1.9598249197006226,
      "logits/rejected": 1.923606514930725,
      "logps/chosen": -212.5594024658203,
      "logps/rejected": -219.98583984375,
      "loss": 0.5473,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.8117889165878296,
      "rewards/margins": 0.8612030148506165,
      "rewards/rejected": -2.6729917526245117,
      "step": 880
    },
    {
      "epoch": 0.2627694124594036,
      "grad_norm": 9.555264472961426,
      "learning_rate": 1.385299675228816e-05,
      "logits/chosen": 1.4182078838348389,
      "logits/rejected": 1.3990509510040283,
      "logps/chosen": -209.5186767578125,
      "logps/rejected": -221.25466918945312,
      "loss": 0.5549,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -2.3261451721191406,
      "rewards/margins": 0.7999902367591858,
      "rewards/rejected": -3.1261353492736816,
      "step": 890
    },
    {
      "epoch": 0.2657218777679362,
      "grad_norm": 7.747138500213623,
      "learning_rate": 1.385022143489814e-05,
      "logits/chosen": 2.2562527656555176,
      "logits/rejected": 2.2515735626220703,
      "logps/chosen": -213.87930297851562,
      "logps/rejected": -224.92611694335938,
      "loss": 0.5679,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": -2.6030449867248535,
      "rewards/margins": 0.6296696066856384,
      "rewards/rejected": -3.232714891433716,
      "step": 900
    },
    {
      "epoch": 0.26867434307646887,
      "grad_norm": 10.982300758361816,
      "learning_rate": 1.384744611750812e-05,
      "logits/chosen": 1.9108693599700928,
      "logits/rejected": 1.9344346523284912,
      "logps/chosen": -214.9486846923828,
      "logps/rejected": -222.2103271484375,
      "loss": 0.4867,
      "rewards/accuracies": 0.73333340883255,
      "rewards/chosen": -1.9787464141845703,
      "rewards/margins": 1.0253312587738037,
      "rewards/rejected": -3.004077911376953,
      "step": 910
    },
    {
      "epoch": 0.2716268083850015,
      "grad_norm": 10.776519775390625,
      "learning_rate": 1.3844670800118099e-05,
      "logits/chosen": 2.1133971214294434,
      "logits/rejected": 2.0974297523498535,
      "logps/chosen": -213.1396026611328,
      "logps/rejected": -223.69729614257812,
      "loss": 0.5238,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -2.2478902339935303,
      "rewards/margins": 0.9503337740898132,
      "rewards/rejected": -3.1982243061065674,
      "step": 920
    },
    {
      "epoch": 0.2745792736935341,
      "grad_norm": 10.14970588684082,
      "learning_rate": 1.3841895482728078e-05,
      "logits/chosen": 1.256277322769165,
      "logits/rejected": 1.2374504804611206,
      "logps/chosen": -216.58889770507812,
      "logps/rejected": -223.6951141357422,
      "loss": 0.5859,
      "rewards/accuracies": 0.6833332777023315,
      "rewards/chosen": -2.5083537101745605,
      "rewards/margins": 0.841750979423523,
      "rewards/rejected": -3.3501052856445312,
      "step": 930
    },
    {
      "epoch": 0.27753173900206674,
      "grad_norm": 5.421786308288574,
      "learning_rate": 1.3839120165338059e-05,
      "logits/chosen": 2.100062131881714,
      "logits/rejected": 2.0663318634033203,
      "logps/chosen": -214.3224639892578,
      "logps/rejected": -225.01339721679688,
      "loss": 0.5295,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.4520602226257324,
      "rewards/margins": 1.0149857997894287,
      "rewards/rejected": -3.4670462608337402,
      "step": 940
    },
    {
      "epoch": 0.28048420431059934,
      "grad_norm": 15.477884292602539,
      "learning_rate": 1.3836344847948038e-05,
      "logits/chosen": 2.082733392715454,
      "logits/rejected": 2.0627031326293945,
      "logps/chosen": -219.08181762695312,
      "logps/rejected": -225.2157440185547,
      "loss": 0.5279,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -2.5814857482910156,
      "rewards/margins": 0.8895920515060425,
      "rewards/rejected": -3.4710781574249268,
      "step": 950
    },
    {
      "epoch": 0.283436669619132,
      "grad_norm": 5.351193428039551,
      "learning_rate": 1.3833569530558015e-05,
      "logits/chosen": 1.722224473953247,
      "logits/rejected": 1.6951875686645508,
      "logps/chosen": -213.6050262451172,
      "logps/rejected": -221.3406524658203,
      "loss": 0.4873,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -1.5938340425491333,
      "rewards/margins": 0.9869332313537598,
      "rewards/rejected": -2.5807671546936035,
      "step": 960
    },
    {
      "epoch": 0.2863891349276646,
      "grad_norm": 10.514854431152344,
      "learning_rate": 1.3830794213167996e-05,
      "logits/chosen": 1.3077778816223145,
      "logits/rejected": 1.307377815246582,
      "logps/chosen": -207.8743438720703,
      "logps/rejected": -213.96475219726562,
      "loss": 0.6194,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": -1.8218564987182617,
      "rewards/margins": 0.6280580759048462,
      "rewards/rejected": -2.4499144554138184,
      "step": 970
    },
    {
      "epoch": 0.2893416002361972,
      "grad_norm": 14.9252290725708,
      "learning_rate": 1.3828018895777975e-05,
      "logits/chosen": 1.6916170120239258,
      "logits/rejected": 1.6623926162719727,
      "logps/chosen": -204.11453247070312,
      "logps/rejected": -218.81735229492188,
      "loss": 0.5994,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -1.5576375722885132,
      "rewards/margins": 0.7740439176559448,
      "rewards/rejected": -2.331681489944458,
      "step": 980
    },
    {
      "epoch": 0.29229406554472986,
      "grad_norm": 6.4273457527160645,
      "learning_rate": 1.3825243578387954e-05,
      "logits/chosen": 1.7818095684051514,
      "logits/rejected": 1.7813279628753662,
      "logps/chosen": -204.68600463867188,
      "logps/rejected": -217.4008331298828,
      "loss": 0.5894,
      "rewards/accuracies": 0.6666666269302368,
      "rewards/chosen": -1.725433349609375,
      "rewards/margins": 0.7360233068466187,
      "rewards/rejected": -2.461456537246704,
      "step": 990
    },
    {
      "epoch": 0.29524653085326247,
      "grad_norm": 10.012327194213867,
      "learning_rate": 1.3822468260997933e-05,
      "logits/chosen": 2.072169542312622,
      "logits/rejected": 2.065290927886963,
      "logps/chosen": -213.41702270507812,
      "logps/rejected": -222.50375366210938,
      "loss": 0.5415,
      "rewards/accuracies": 0.7166666388511658,
      "rewards/chosen": -2.2047152519226074,
      "rewards/margins": 0.6676673889160156,
      "rewards/rejected": -2.872382640838623,
      "step": 1000
    },
    {
      "epoch": 0.29819899616179507,
      "grad_norm": 11.485982894897461,
      "learning_rate": 1.3819692943607913e-05,
      "logits/chosen": 1.6578937768936157,
      "logits/rejected": 1.652907133102417,
      "logps/chosen": -218.9358367919922,
      "logps/rejected": -227.8074493408203,
      "loss": 0.5169,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.855656623840332,
      "rewards/margins": 1.0421665906906128,
      "rewards/rejected": -3.8978238105773926,
      "step": 1010
    },
    {
      "epoch": 0.30115146147032773,
      "grad_norm": 7.439169406890869,
      "learning_rate": 1.3816917626217893e-05,
      "logits/chosen": 1.8739023208618164,
      "logits/rejected": 1.8308055400848389,
      "logps/chosen": -217.2263641357422,
      "logps/rejected": -228.4720001220703,
      "loss": 0.5313,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.5108461380004883,
      "rewards/margins": 0.8468034863471985,
      "rewards/rejected": -3.357649564743042,
      "step": 1020
    },
    {
      "epoch": 0.30410392677886033,
      "grad_norm": 9.529221534729004,
      "learning_rate": 1.381414230882787e-05,
      "logits/chosen": 1.9741023778915405,
      "logits/rejected": 1.9687042236328125,
      "logps/chosen": -212.3037109375,
      "logps/rejected": -229.2590789794922,
      "loss": 0.324,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.9908777475357056,
      "rewards/margins": 1.6339921951293945,
      "rewards/rejected": -3.6248695850372314,
      "step": 1030
    },
    {
      "epoch": 0.307056392087393,
      "grad_norm": 14.02534008026123,
      "learning_rate": 1.3811366991437851e-05,
      "logits/chosen": 1.7309894561767578,
      "logits/rejected": 1.722938895225525,
      "logps/chosen": -214.36196899414062,
      "logps/rejected": -222.6759796142578,
      "loss": 0.5693,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.339090347290039,
      "rewards/margins": 1.0474903583526611,
      "rewards/rejected": -3.3865807056427,
      "step": 1040
    },
    {
      "epoch": 0.3100088573959256,
      "grad_norm": 16.860857009887695,
      "learning_rate": 1.380859167404783e-05,
      "logits/chosen": 1.4350665807724,
      "logits/rejected": 1.4386931657791138,
      "logps/chosen": -221.4638671875,
      "logps/rejected": -232.4891815185547,
      "loss": 0.4943,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -2.4540696144104004,
      "rewards/margins": 1.0868152379989624,
      "rewards/rejected": -3.5408847332000732,
      "step": 1050
    },
    {
      "epoch": 0.3129613227044582,
      "grad_norm": 6.349522113800049,
      "learning_rate": 1.380581635665781e-05,
      "logits/chosen": 1.9555385112762451,
      "logits/rejected": 1.939695954322815,
      "logps/chosen": -215.0701141357422,
      "logps/rejected": -228.73526000976562,
      "loss": 0.4948,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -2.744551658630371,
      "rewards/margins": 1.2981369495391846,
      "rewards/rejected": -4.042688369750977,
      "step": 1060
    },
    {
      "epoch": 0.31591378801299086,
      "grad_norm": 17.8336124420166,
      "learning_rate": 1.3803041039267789e-05,
      "logits/chosen": 1.732016921043396,
      "logits/rejected": 1.7191989421844482,
      "logps/chosen": -219.24044799804688,
      "logps/rejected": -232.5294952392578,
      "loss": 0.4507,
      "rewards/accuracies": 0.8000000715255737,
      "rewards/chosen": -2.580195903778076,
      "rewards/margins": 1.3831874132156372,
      "rewards/rejected": -3.963383197784424,
      "step": 1070
    },
    {
      "epoch": 0.31886625332152346,
      "grad_norm": 3.9702541828155518,
      "learning_rate": 1.3800265721877768e-05,
      "logits/chosen": 1.9763418436050415,
      "logits/rejected": 1.95572030544281,
      "logps/chosen": -220.8898468017578,
      "logps/rejected": -233.2143096923828,
      "loss": 0.7277,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -3.104234218597412,
      "rewards/margins": 0.845171332359314,
      "rewards/rejected": -3.9494051933288574,
      "step": 1080
    },
    {
      "epoch": 0.3218187186300561,
      "grad_norm": 12.855263710021973,
      "learning_rate": 1.3797490404487749e-05,
      "logits/chosen": 1.8954505920410156,
      "logits/rejected": 1.8821500539779663,
      "logps/chosen": -220.39614868164062,
      "logps/rejected": -228.66812133789062,
      "loss": 0.4637,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.870349407196045,
      "rewards/margins": 1.136059045791626,
      "rewards/rejected": -4.006407737731934,
      "step": 1090
    },
    {
      "epoch": 0.3247711839385887,
      "grad_norm": 21.506155014038086,
      "learning_rate": 1.3794715087097726e-05,
      "logits/chosen": 1.7802226543426514,
      "logits/rejected": 1.7805248498916626,
      "logps/chosen": -211.2801971435547,
      "logps/rejected": -226.8338623046875,
      "loss": 0.4927,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.4609179496765137,
      "rewards/margins": 1.1869043111801147,
      "rewards/rejected": -3.647822141647339,
      "step": 1100
    },
    {
      "epoch": 0.32772364924712133,
      "grad_norm": 5.560802936553955,
      "learning_rate": 1.3791939769707707e-05,
      "logits/chosen": 1.980316162109375,
      "logits/rejected": 1.980513334274292,
      "logps/chosen": -219.9320068359375,
      "logps/rejected": -231.6981201171875,
      "loss": 0.4685,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.5042405128479004,
      "rewards/margins": 1.2848763465881348,
      "rewards/rejected": -3.7891170978546143,
      "step": 1110
    },
    {
      "epoch": 0.330676114555654,
      "grad_norm": 12.213945388793945,
      "learning_rate": 1.3789164452317686e-05,
      "logits/chosen": 2.115111827850342,
      "logits/rejected": 2.1002206802368164,
      "logps/chosen": -221.154541015625,
      "logps/rejected": -229.95828247070312,
      "loss": 0.578,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.5855820178985596,
      "rewards/margins": 0.7789326906204224,
      "rewards/rejected": -3.3645145893096924,
      "step": 1120
    },
    {
      "epoch": 0.3336285798641866,
      "grad_norm": 8.087267875671387,
      "learning_rate": 1.3786389134927667e-05,
      "logits/chosen": 2.16579008102417,
      "logits/rejected": 2.1590890884399414,
      "logps/chosen": -214.2847900390625,
      "logps/rejected": -222.20614624023438,
      "loss": 0.5636,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": -2.05302095413208,
      "rewards/margins": 0.8976022601127625,
      "rewards/rejected": -2.950623035430908,
      "step": 1130
    },
    {
      "epoch": 0.3365810451727192,
      "grad_norm": 8.870088577270508,
      "learning_rate": 1.3783613817537644e-05,
      "logits/chosen": 2.4099674224853516,
      "logits/rejected": 2.406712293624878,
      "logps/chosen": -218.5517120361328,
      "logps/rejected": -226.0723114013672,
      "loss": 0.5312,
      "rewards/accuracies": 0.7166666388511658,
      "rewards/chosen": -2.0577595233917236,
      "rewards/margins": 0.9043012857437134,
      "rewards/rejected": -2.9620609283447266,
      "step": 1140
    },
    {
      "epoch": 0.33953351048125185,
      "grad_norm": 11.521981239318848,
      "learning_rate": 1.3780838500147623e-05,
      "logits/chosen": 1.8213729858398438,
      "logits/rejected": 1.7872745990753174,
      "logps/chosen": -218.8849334716797,
      "logps/rejected": -231.4100799560547,
      "loss": 0.4788,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.8948044776916504,
      "rewards/margins": 1.2837425470352173,
      "rewards/rejected": -4.178546905517578,
      "step": 1150
    },
    {
      "epoch": 0.34248597578978446,
      "grad_norm": 5.543089389801025,
      "learning_rate": 1.3778063182757604e-05,
      "logits/chosen": 1.6957380771636963,
      "logits/rejected": 1.687414526939392,
      "logps/chosen": -228.29525756835938,
      "logps/rejected": -240.8555908203125,
      "loss": 0.5282,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -3.2915797233581543,
      "rewards/margins": 0.9044113159179688,
      "rewards/rejected": -4.195991516113281,
      "step": 1160
    },
    {
      "epoch": 0.3454384410983171,
      "grad_norm": 13.544578552246094,
      "learning_rate": 1.3775287865367581e-05,
      "logits/chosen": 1.850188970565796,
      "logits/rejected": 1.835333228111267,
      "logps/chosen": -230.42709350585938,
      "logps/rejected": -236.2783966064453,
      "loss": 0.5726,
      "rewards/accuracies": 0.6833333969116211,
      "rewards/chosen": -3.8688015937805176,
      "rewards/margins": 0.6987537145614624,
      "rewards/rejected": -4.567554950714111,
      "step": 1170
    },
    {
      "epoch": 0.3483909064068497,
      "grad_norm": 13.035003662109375,
      "learning_rate": 1.3772512547977562e-05,
      "logits/chosen": 1.7601511478424072,
      "logits/rejected": 1.754481315612793,
      "logps/chosen": -217.6327362060547,
      "logps/rejected": -235.26278686523438,
      "loss": 0.4613,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.7457189559936523,
      "rewards/margins": 1.2735373973846436,
      "rewards/rejected": -4.019256114959717,
      "step": 1180
    },
    {
      "epoch": 0.3513433717153823,
      "grad_norm": 5.458191394805908,
      "learning_rate": 1.3769737230587541e-05,
      "logits/chosen": 2.1032357215881348,
      "logits/rejected": 2.1085989475250244,
      "logps/chosen": -218.1141357421875,
      "logps/rejected": -226.9083709716797,
      "loss": 0.5658,
      "rewards/accuracies": 0.6666666269302368,
      "rewards/chosen": -2.3842384815216064,
      "rewards/margins": 0.8993189930915833,
      "rewards/rejected": -3.283557415008545,
      "step": 1190
    },
    {
      "epoch": 0.354295837023915,
      "grad_norm": 12.18082046508789,
      "learning_rate": 1.376696191319752e-05,
      "logits/chosen": 2.082583427429199,
      "logits/rejected": 2.0681283473968506,
      "logps/chosen": -216.634033203125,
      "logps/rejected": -229.59848022460938,
      "loss": 0.4585,
      "rewards/accuracies": 0.8000000715255737,
      "rewards/chosen": -2.401216983795166,
      "rewards/margins": 1.360975980758667,
      "rewards/rejected": -3.762192487716675,
      "step": 1200
    },
    {
      "epoch": 0.3572483023324476,
      "grad_norm": 10.940686225891113,
      "learning_rate": 1.37641865958075e-05,
      "logits/chosen": 2.0348174571990967,
      "logits/rejected": 1.9974712133407593,
      "logps/chosen": -208.80331420898438,
      "logps/rejected": -224.99911499023438,
      "loss": 0.485,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -2.2392098903656006,
      "rewards/margins": 1.4007337093353271,
      "rewards/rejected": -3.6399435997009277,
      "step": 1210
    },
    {
      "epoch": 0.36020076764098025,
      "grad_norm": 11.344941139221191,
      "learning_rate": 1.3761411278417479e-05,
      "logits/chosen": 1.4156608581542969,
      "logits/rejected": 1.3916361331939697,
      "logps/chosen": -221.9427032470703,
      "logps/rejected": -233.4093017578125,
      "loss": 0.5148,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -2.602412700653076,
      "rewards/margins": 1.2618510723114014,
      "rewards/rejected": -3.8642640113830566,
      "step": 1220
    },
    {
      "epoch": 0.36315323294951285,
      "grad_norm": 7.801835060119629,
      "learning_rate": 1.375863596102746e-05,
      "logits/chosen": 1.80277419090271,
      "logits/rejected": 1.7832691669464111,
      "logps/chosen": -211.4281463623047,
      "logps/rejected": -219.17129516601562,
      "loss": 0.6266,
      "rewards/accuracies": 0.6833332777023315,
      "rewards/chosen": -1.983661413192749,
      "rewards/margins": 0.8334311246871948,
      "rewards/rejected": -2.8170924186706543,
      "step": 1230
    },
    {
      "epoch": 0.36610569825804545,
      "grad_norm": 10.663352966308594,
      "learning_rate": 1.3755860643637437e-05,
      "logits/chosen": 2.0886025428771973,
      "logits/rejected": 2.0843446254730225,
      "logps/chosen": -202.31692504882812,
      "logps/rejected": -212.079833984375,
      "loss": 0.5593,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -1.3286370038986206,
      "rewards/margins": 0.7676858901977539,
      "rewards/rejected": -2.096322774887085,
      "step": 1240
    },
    {
      "epoch": 0.3690581635665781,
      "grad_norm": 10.333218574523926,
      "learning_rate": 1.3753085326247417e-05,
      "logits/chosen": 2.266921043395996,
      "logits/rejected": 2.2500052452087402,
      "logps/chosen": -205.0960693359375,
      "logps/rejected": -213.87637329101562,
      "loss": 0.5461,
      "rewards/accuracies": 0.7166666388511658,
      "rewards/chosen": -1.557697057723999,
      "rewards/margins": 0.7934540510177612,
      "rewards/rejected": -2.35115122795105,
      "step": 1250
    },
    {
      "epoch": 0.3720106288751107,
      "grad_norm": 6.346786022186279,
      "learning_rate": 1.3750310008857397e-05,
      "logits/chosen": 1.9328693151474,
      "logits/rejected": 1.8828283548355103,
      "logps/chosen": -212.33773803710938,
      "logps/rejected": -235.36471557617188,
      "loss": 0.412,
      "rewards/accuracies": 0.8166667819023132,
      "rewards/chosen": -2.4529500007629395,
      "rewards/margins": 1.2962747812271118,
      "rewards/rejected": -3.749224901199341,
      "step": 1260
    },
    {
      "epoch": 0.3749630941836433,
      "grad_norm": 6.169670104980469,
      "learning_rate": 1.3747534691467376e-05,
      "logits/chosen": 1.1433370113372803,
      "logits/rejected": 1.1611034870147705,
      "logps/chosen": -221.8472900390625,
      "logps/rejected": -227.82937622070312,
      "loss": 0.574,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -2.9512619972229004,
      "rewards/margins": 0.8556710481643677,
      "rewards/rejected": -3.8069329261779785,
      "step": 1270
    },
    {
      "epoch": 0.377915559492176,
      "grad_norm": 12.513062477111816,
      "learning_rate": 1.3744759374077355e-05,
      "logits/chosen": 1.6488815546035767,
      "logits/rejected": 1.6456187963485718,
      "logps/chosen": -221.9256134033203,
      "logps/rejected": -227.60696411132812,
      "loss": 0.5024,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.9174017906188965,
      "rewards/margins": 1.0509783029556274,
      "rewards/rejected": -3.9683804512023926,
      "step": 1280
    },
    {
      "epoch": 0.3808680248007086,
      "grad_norm": 17.250574111938477,
      "learning_rate": 1.3741984056687334e-05,
      "logits/chosen": 1.6531445980072021,
      "logits/rejected": 1.6497787237167358,
      "logps/chosen": -225.02810668945312,
      "logps/rejected": -230.06448364257812,
      "loss": 0.7343,
      "rewards/accuracies": 0.5333333611488342,
      "rewards/chosen": -3.2623162269592285,
      "rewards/margins": 0.49406471848487854,
      "rewards/rejected": -3.7563815116882324,
      "step": 1290
    },
    {
      "epoch": 0.38382049010924124,
      "grad_norm": 13.133663177490234,
      "learning_rate": 1.3739208739297315e-05,
      "logits/chosen": 2.0162134170532227,
      "logits/rejected": 1.9927009344100952,
      "logps/chosen": -224.71884155273438,
      "logps/rejected": -229.5316619873047,
      "loss": 0.4748,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -3.0771050453186035,
      "rewards/margins": 1.062684416770935,
      "rewards/rejected": -4.139789581298828,
      "step": 1300
    },
    {
      "epoch": 0.38677295541777384,
      "grad_norm": 10.483170509338379,
      "learning_rate": 1.3736433421907294e-05,
      "logits/chosen": 1.5577936172485352,
      "logits/rejected": 1.5437971353530884,
      "logps/chosen": -220.3124542236328,
      "logps/rejected": -230.45034790039062,
      "loss": 0.5577,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.8609237670898438,
      "rewards/margins": 0.9044517278671265,
      "rewards/rejected": -3.7653756141662598,
      "step": 1310
    },
    {
      "epoch": 0.38972542072630645,
      "grad_norm": 6.518091201782227,
      "learning_rate": 1.3733658104517273e-05,
      "logits/chosen": 1.8137454986572266,
      "logits/rejected": 1.8029327392578125,
      "logps/chosen": -217.33517456054688,
      "logps/rejected": -228.5708465576172,
      "loss": 0.5361,
      "rewards/accuracies": 0.6666666269302368,
      "rewards/chosen": -2.175438642501831,
      "rewards/margins": 1.0663999319076538,
      "rewards/rejected": -3.2418389320373535,
      "step": 1320
    },
    {
      "epoch": 0.3926778860348391,
      "grad_norm": 8.882863998413086,
      "learning_rate": 1.3730882787127252e-05,
      "logits/chosen": 1.6356346607208252,
      "logits/rejected": 1.637589693069458,
      "logps/chosen": -202.528076171875,
      "logps/rejected": -211.1672821044922,
      "loss": 0.4934,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4117660522460938,
      "rewards/margins": 0.8523308634757996,
      "rewards/rejected": -2.264096975326538,
      "step": 1330
    },
    {
      "epoch": 0.3956303513433717,
      "grad_norm": 12.818718910217285,
      "learning_rate": 1.3728107469737231e-05,
      "logits/chosen": 1.8591057062149048,
      "logits/rejected": 1.8289158344268799,
      "logps/chosen": -208.8351287841797,
      "logps/rejected": -221.6759033203125,
      "loss": 0.5102,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -1.6498727798461914,
      "rewards/margins": 1.1612746715545654,
      "rewards/rejected": -2.8111472129821777,
      "step": 1340
    },
    {
      "epoch": 0.3985828166519043,
      "grad_norm": 7.211512565612793,
      "learning_rate": 1.372533215234721e-05,
      "logits/chosen": 1.5977344512939453,
      "logits/rejected": 1.5836025476455688,
      "logps/chosen": -211.8744659423828,
      "logps/rejected": -221.554931640625,
      "loss": 0.6129,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -1.9586708545684814,
      "rewards/margins": 1.0027716159820557,
      "rewards/rejected": -2.961442470550537,
      "step": 1350
    },
    {
      "epoch": 0.401535281960437,
      "grad_norm": 5.497565269470215,
      "learning_rate": 1.372255683495719e-05,
      "logits/chosen": 2.093667984008789,
      "logits/rejected": 2.0454821586608887,
      "logps/chosen": -214.49874877929688,
      "logps/rejected": -228.67825317382812,
      "loss": 0.4172,
      "rewards/accuracies": 0.8666667938232422,
      "rewards/chosen": -2.2145543098449707,
      "rewards/margins": 1.3450396060943604,
      "rewards/rejected": -3.559593677520752,
      "step": 1360
    },
    {
      "epoch": 0.4044877472689696,
      "grad_norm": 12.209760665893555,
      "learning_rate": 1.371978151756717e-05,
      "logits/chosen": 1.842495322227478,
      "logits/rejected": 1.803160309791565,
      "logps/chosen": -212.26327514648438,
      "logps/rejected": -226.1024627685547,
      "loss": 0.4916,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -2.247070789337158,
      "rewards/margins": 1.2144203186035156,
      "rewards/rejected": -3.461491346359253,
      "step": 1370
    },
    {
      "epoch": 0.40744021257750224,
      "grad_norm": 8.238576889038086,
      "learning_rate": 1.3717006200177149e-05,
      "logits/chosen": 1.5510226488113403,
      "logits/rejected": 1.509584665298462,
      "logps/chosen": -206.6161346435547,
      "logps/rejected": -220.59521484375,
      "loss": 0.5904,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -1.8386774063110352,
      "rewards/margins": 1.0830117464065552,
      "rewards/rejected": -2.921689033508301,
      "step": 1380
    },
    {
      "epoch": 0.41039267788603484,
      "grad_norm": 10.410922050476074,
      "learning_rate": 1.3714230882787126e-05,
      "logits/chosen": 1.8549950122833252,
      "logits/rejected": 1.8649299144744873,
      "logps/chosen": -214.55966186523438,
      "logps/rejected": -223.87490844726562,
      "loss": 0.5597,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -1.8828332424163818,
      "rewards/margins": 0.9564754366874695,
      "rewards/rejected": -2.839308500289917,
      "step": 1390
    },
    {
      "epoch": 0.41334514319456744,
      "grad_norm": 12.684691429138184,
      "learning_rate": 1.3711455565397107e-05,
      "logits/chosen": 1.9625962972640991,
      "logits/rejected": 1.9356422424316406,
      "logps/chosen": -211.6839141845703,
      "logps/rejected": -219.6362762451172,
      "loss": 0.6239,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -1.9281479120254517,
      "rewards/margins": 0.616747260093689,
      "rewards/rejected": -2.5448951721191406,
      "step": 1400
    },
    {
      "epoch": 0.4162976085031001,
      "grad_norm": 7.307606220245361,
      "learning_rate": 1.3708680248007086e-05,
      "logits/chosen": 1.9638292789459229,
      "logits/rejected": 1.914389967918396,
      "logps/chosen": -207.5119171142578,
      "logps/rejected": -225.87222290039062,
      "loss": 0.4557,
      "rewards/accuracies": 0.7666667699813843,
      "rewards/chosen": -1.8299411535263062,
      "rewards/margins": 1.1650432348251343,
      "rewards/rejected": -2.9949843883514404,
      "step": 1410
    },
    {
      "epoch": 0.4192500738116327,
      "grad_norm": 12.257874488830566,
      "learning_rate": 1.3705904930617065e-05,
      "logits/chosen": 1.391054391860962,
      "logits/rejected": 1.3818986415863037,
      "logps/chosen": -214.1422576904297,
      "logps/rejected": -222.73483276367188,
      "loss": 0.4544,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.209418773651123,
      "rewards/margins": 1.234089970588684,
      "rewards/rejected": -3.4435086250305176,
      "step": 1420
    },
    {
      "epoch": 0.42220253912016537,
      "grad_norm": 8.540604591369629,
      "learning_rate": 1.3703129613227045e-05,
      "logits/chosen": 1.6971172094345093,
      "logits/rejected": 1.6461479663848877,
      "logps/chosen": -211.138427734375,
      "logps/rejected": -226.9855499267578,
      "loss": 0.4452,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -2.346330165863037,
      "rewards/margins": 1.2418601512908936,
      "rewards/rejected": -3.5881905555725098,
      "step": 1430
    },
    {
      "epoch": 0.42515500442869797,
      "grad_norm": 9.268149375915527,
      "learning_rate": 1.3700354295837025e-05,
      "logits/chosen": 1.9548860788345337,
      "logits/rejected": 1.9177993535995483,
      "logps/chosen": -215.9374237060547,
      "logps/rejected": -232.84793090820312,
      "loss": 0.402,
      "rewards/accuracies": 0.76666659116745,
      "rewards/chosen": -2.377653121948242,
      "rewards/margins": 1.3045767545700073,
      "rewards/rejected": -3.682229518890381,
      "step": 1440
    },
    {
      "epoch": 0.4281074697372306,
      "grad_norm": 21.954275131225586,
      "learning_rate": 1.3697578978447004e-05,
      "logits/chosen": 1.3979498147964478,
      "logits/rejected": 1.3677526712417603,
      "logps/chosen": -210.64718627929688,
      "logps/rejected": -228.50210571289062,
      "loss": 0.5304,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.5609898567199707,
      "rewards/margins": 1.1258093118667603,
      "rewards/rejected": -3.6867988109588623,
      "step": 1450
    },
    {
      "epoch": 0.43105993504576323,
      "grad_norm": 6.470329761505127,
      "learning_rate": 1.3694803661056982e-05,
      "logits/chosen": 1.86702561378479,
      "logits/rejected": 1.8463395833969116,
      "logps/chosen": -210.182861328125,
      "logps/rejected": -222.9962615966797,
      "loss": 0.4301,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.1927437782287598,
      "rewards/margins": 1.3028995990753174,
      "rewards/rejected": -3.495642900466919,
      "step": 1460
    },
    {
      "epoch": 0.43401240035429584,
      "grad_norm": 10.098443984985352,
      "learning_rate": 1.3692028343666963e-05,
      "logits/chosen": 1.8360755443572998,
      "logits/rejected": 1.8288065195083618,
      "logps/chosen": -212.3291778564453,
      "logps/rejected": -230.2407989501953,
      "loss": 0.4633,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -2.4677927494049072,
      "rewards/margins": 1.3908017873764038,
      "rewards/rejected": -3.8585944175720215,
      "step": 1470
    },
    {
      "epoch": 0.43696486566282844,
      "grad_norm": 12.44874095916748,
      "learning_rate": 1.3689253026276942e-05,
      "logits/chosen": 2.090280532836914,
      "logits/rejected": 2.044217586517334,
      "logps/chosen": -215.22946166992188,
      "logps/rejected": -227.16513061523438,
      "loss": 0.5509,
      "rewards/accuracies": 0.6833333969116211,
      "rewards/chosen": -2.303443670272827,
      "rewards/margins": 1.3296005725860596,
      "rewards/rejected": -3.6330440044403076,
      "step": 1480
    },
    {
      "epoch": 0.4399173309713611,
      "grad_norm": 11.090987205505371,
      "learning_rate": 1.368647770888692e-05,
      "logits/chosen": 1.7956199645996094,
      "logits/rejected": 1.7700704336166382,
      "logps/chosen": -210.5890350341797,
      "logps/rejected": -226.54629516601562,
      "loss": 0.4757,
      "rewards/accuracies": 0.8000000715255737,
      "rewards/chosen": -2.070655345916748,
      "rewards/margins": 1.3257092237472534,
      "rewards/rejected": -3.396364688873291,
      "step": 1490
    },
    {
      "epoch": 0.4428697962798937,
      "grad_norm": 5.824823379516602,
      "learning_rate": 1.36837023914969e-05,
      "logits/chosen": 1.9223756790161133,
      "logits/rejected": 1.9066959619522095,
      "logps/chosen": -211.0733184814453,
      "logps/rejected": -219.2902069091797,
      "loss": 0.4481,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.8967406749725342,
      "rewards/margins": 1.0397989749908447,
      "rewards/rejected": -2.9365394115448,
      "step": 1500
    },
    {
      "epoch": 0.44582226158842636,
      "grad_norm": 7.674006462097168,
      "learning_rate": 1.368092707410688e-05,
      "logits/chosen": 2.1385536193847656,
      "logits/rejected": 2.1098129749298096,
      "logps/chosen": -215.989990234375,
      "logps/rejected": -233.7119598388672,
      "loss": 0.4264,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.4696831703186035,
      "rewards/margins": 1.5908679962158203,
      "rewards/rejected": -4.060551643371582,
      "step": 1510
    },
    {
      "epoch": 0.44877472689695896,
      "grad_norm": 6.420853614807129,
      "learning_rate": 1.367815175671686e-05,
      "logits/chosen": 2.0408225059509277,
      "logits/rejected": 2.022550344467163,
      "logps/chosen": -226.0774383544922,
      "logps/rejected": -238.9863739013672,
      "loss": 0.3821,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -3.3092453479766846,
      "rewards/margins": 1.5551948547363281,
      "rewards/rejected": -4.864439964294434,
      "step": 1520
    },
    {
      "epoch": 0.45172719220549157,
      "grad_norm": 15.518784523010254,
      "learning_rate": 1.3675376439326837e-05,
      "logits/chosen": 1.6517670154571533,
      "logits/rejected": 1.6276919841766357,
      "logps/chosen": -220.96597290039062,
      "logps/rejected": -233.22994995117188,
      "loss": 0.6264,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -3.0785157680511475,
      "rewards/margins": 0.9479033350944519,
      "rewards/rejected": -4.026418685913086,
      "step": 1530
    },
    {
      "epoch": 0.4546796575140242,
      "grad_norm": 5.152675151824951,
      "learning_rate": 1.3672601121936818e-05,
      "logits/chosen": 1.9268500804901123,
      "logits/rejected": 1.9107993841171265,
      "logps/chosen": -213.47293090820312,
      "logps/rejected": -223.3741912841797,
      "loss": 0.4393,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -2.232581615447998,
      "rewards/margins": 1.3964608907699585,
      "rewards/rejected": -3.629042387008667,
      "step": 1540
    },
    {
      "epoch": 0.45763212282255683,
      "grad_norm": 11.195971488952637,
      "learning_rate": 1.3669825804546797e-05,
      "logits/chosen": 2.092090129852295,
      "logits/rejected": 2.0562055110931396,
      "logps/chosen": -207.5973663330078,
      "logps/rejected": -219.9665985107422,
      "loss": 0.5258,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -1.6384203433990479,
      "rewards/margins": 1.2694920301437378,
      "rewards/rejected": -2.907912254333496,
      "step": 1550
    },
    {
      "epoch": 0.46058458813108943,
      "grad_norm": 5.433038711547852,
      "learning_rate": 1.3667050487156778e-05,
      "logits/chosen": 2.0838725566864014,
      "logits/rejected": 2.0633792877197266,
      "logps/chosen": -214.7119598388672,
      "logps/rejected": -231.4275360107422,
      "loss": 0.339,
      "rewards/accuracies": 0.8333333134651184,
      "rewards/chosen": -2.225616216659546,
      "rewards/margins": 1.7597196102142334,
      "rewards/rejected": -3.9853358268737793,
      "step": 1560
    },
    {
      "epoch": 0.4635370534396221,
      "grad_norm": 3.5557994842529297,
      "learning_rate": 1.3664275169766755e-05,
      "logits/chosen": 1.6766105890274048,
      "logits/rejected": 1.6569492816925049,
      "logps/chosen": -216.2813720703125,
      "logps/rejected": -228.3469696044922,
      "loss": 0.3606,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -2.377837896347046,
      "rewards/margins": 1.597261667251587,
      "rewards/rejected": -3.975100040435791,
      "step": 1570
    },
    {
      "epoch": 0.4664895187481547,
      "grad_norm": 8.185144424438477,
      "learning_rate": 1.3661499852376734e-05,
      "logits/chosen": 1.7583338022232056,
      "logits/rejected": 1.7287986278533936,
      "logps/chosen": -217.25326538085938,
      "logps/rejected": -235.4297332763672,
      "loss": 0.3391,
      "rewards/accuracies": 0.8666666150093079,
      "rewards/chosen": -2.7011170387268066,
      "rewards/margins": 1.6880295276641846,
      "rewards/rejected": -4.389146327972412,
      "step": 1580
    },
    {
      "epoch": 0.46944198405668736,
      "grad_norm": 12.313129425048828,
      "learning_rate": 1.3658724534986715e-05,
      "logits/chosen": 2.467402219772339,
      "logits/rejected": 2.436138153076172,
      "logps/chosen": -219.18435668945312,
      "logps/rejected": -240.09249877929688,
      "loss": 0.4521,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -2.8630428314208984,
      "rewards/margins": 1.5054595470428467,
      "rewards/rejected": -4.368502616882324,
      "step": 1590
    },
    {
      "epoch": 0.47239444936521996,
      "grad_norm": 20.70305824279785,
      "learning_rate": 1.3655949217596692e-05,
      "logits/chosen": 1.1246540546417236,
      "logits/rejected": 1.103082537651062,
      "logps/chosen": -218.1312255859375,
      "logps/rejected": -231.3955535888672,
      "loss": 0.5178,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -3.012030839920044,
      "rewards/margins": 1.1094756126403809,
      "rewards/rejected": -4.121506690979004,
      "step": 1600
    },
    {
      "epoch": 0.47534691467375256,
      "grad_norm": 20.012422561645508,
      "learning_rate": 1.3653173900206673e-05,
      "logits/chosen": 1.9295810461044312,
      "logits/rejected": 1.9109834432601929,
      "logps/chosen": -221.8497772216797,
      "logps/rejected": -234.19540405273438,
      "loss": 0.669,
      "rewards/accuracies": 0.6166666746139526,
      "rewards/chosen": -3.0872931480407715,
      "rewards/margins": 1.0524697303771973,
      "rewards/rejected": -4.139763355255127,
      "step": 1610
    },
    {
      "epoch": 0.4782993799822852,
      "grad_norm": 10.924357414245605,
      "learning_rate": 1.3650398582816652e-05,
      "logits/chosen": 2.226010799407959,
      "logits/rejected": 2.2022106647491455,
      "logps/chosen": -226.2699737548828,
      "logps/rejected": -235.23703002929688,
      "loss": 0.5711,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -3.1082897186279297,
      "rewards/margins": 0.7846865653991699,
      "rewards/rejected": -3.8929762840270996,
      "step": 1620
    },
    {
      "epoch": 0.4812518452908178,
      "grad_norm": 5.985132694244385,
      "learning_rate": 1.3647623265426633e-05,
      "logits/chosen": 1.758713722229004,
      "logits/rejected": 1.7222049236297607,
      "logps/chosen": -222.83529663085938,
      "logps/rejected": -226.83230590820312,
      "loss": 0.5465,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -2.6711649894714355,
      "rewards/margins": 1.063751220703125,
      "rewards/rejected": -3.7349166870117188,
      "step": 1630
    },
    {
      "epoch": 0.4842043105993505,
      "grad_norm": 13.286523818969727,
      "learning_rate": 1.364484794803661e-05,
      "logits/chosen": 1.8418067693710327,
      "logits/rejected": 1.8069814443588257,
      "logps/chosen": -215.5402374267578,
      "logps/rejected": -229.61776733398438,
      "loss": 0.5514,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -1.976281762123108,
      "rewards/margins": 1.3927664756774902,
      "rewards/rejected": -3.3690483570098877,
      "step": 1640
    },
    {
      "epoch": 0.4871567759078831,
      "grad_norm": 11.771552085876465,
      "learning_rate": 1.364207263064659e-05,
      "logits/chosen": 2.2157530784606934,
      "logits/rejected": 2.1916890144348145,
      "logps/chosen": -215.77099609375,
      "logps/rejected": -234.46713256835938,
      "loss": 0.5072,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.270838499069214,
      "rewards/margins": 1.2623354196548462,
      "rewards/rejected": -3.5331740379333496,
      "step": 1650
    },
    {
      "epoch": 0.4901092412164157,
      "grad_norm": 6.383574485778809,
      "learning_rate": 1.363929731325657e-05,
      "logits/chosen": 1.7555738687515259,
      "logits/rejected": 1.7417335510253906,
      "logps/chosen": -214.7494659423828,
      "logps/rejected": -223.4855499267578,
      "loss": 0.5991,
      "rewards/accuracies": 0.7333332896232605,
      "rewards/chosen": -2.2431271076202393,
      "rewards/margins": 0.7948106527328491,
      "rewards/rejected": -3.037937641143799,
      "step": 1660
    },
    {
      "epoch": 0.49306170652494835,
      "grad_norm": 9.047196388244629,
      "learning_rate": 1.363652199586655e-05,
      "logits/chosen": 1.7017238140106201,
      "logits/rejected": 1.671651840209961,
      "logps/chosen": -207.5101318359375,
      "logps/rejected": -219.2568359375,
      "loss": 0.3798,
      "rewards/accuracies": 0.8000000715255737,
      "rewards/chosen": -1.4072130918502808,
      "rewards/margins": 1.801683783531189,
      "rewards/rejected": -3.2088966369628906,
      "step": 1670
    },
    {
      "epoch": 0.49601417183348095,
      "grad_norm": 9.652542114257812,
      "learning_rate": 1.3633746678476529e-05,
      "logits/chosen": 2.100886344909668,
      "logits/rejected": 2.07208251953125,
      "logps/chosen": -208.528076171875,
      "logps/rejected": -223.0659637451172,
      "loss": 0.4214,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.795819640159607,
      "rewards/margins": 1.6873962879180908,
      "rewards/rejected": -3.48321533203125,
      "step": 1680
    },
    {
      "epoch": 0.49896663714201356,
      "grad_norm": 5.488962173461914,
      "learning_rate": 1.3630971361086508e-05,
      "logits/chosen": 1.456458568572998,
      "logits/rejected": 1.4290472269058228,
      "logps/chosen": -211.7396240234375,
      "logps/rejected": -232.5260009765625,
      "loss": 0.3524,
      "rewards/accuracies": 0.8833333849906921,
      "rewards/chosen": -2.33013916015625,
      "rewards/margins": 1.6171772480010986,
      "rewards/rejected": -3.9473166465759277,
      "step": 1690
    },
    {
      "epoch": 0.5019191024505462,
      "grad_norm": 9.461639404296875,
      "learning_rate": 1.3628196043696488e-05,
      "logits/chosen": 1.2098820209503174,
      "logits/rejected": 1.1752185821533203,
      "logps/chosen": -215.4205322265625,
      "logps/rejected": -233.56668090820312,
      "loss": 0.4349,
      "rewards/accuracies": 0.8166666030883789,
      "rewards/chosen": -2.6936964988708496,
      "rewards/margins": 1.462408185005188,
      "rewards/rejected": -4.15610408782959,
      "step": 1700
    },
    {
      "epoch": 0.5048715677590788,
      "grad_norm": 14.905614852905273,
      "learning_rate": 1.3625420726306466e-05,
      "logits/chosen": 1.6375011205673218,
      "logits/rejected": 1.602940559387207,
      "logps/chosen": -223.638916015625,
      "logps/rejected": -242.69064331054688,
      "loss": 0.4219,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.2713170051574707,
      "rewards/margins": 1.5532879829406738,
      "rewards/rejected": -4.8246049880981445,
      "step": 1710
    },
    {
      "epoch": 0.5078240330676115,
      "grad_norm": 17.574359893798828,
      "learning_rate": 1.3622645408916445e-05,
      "logits/chosen": 1.41639244556427,
      "logits/rejected": 1.4115097522735596,
      "logps/chosen": -218.8412628173828,
      "logps/rejected": -233.05191040039062,
      "loss": 0.4117,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.414156913757324,
      "rewards/margins": 1.5347868204116821,
      "rewards/rejected": -3.948943614959717,
      "step": 1720
    },
    {
      "epoch": 0.510776498376144,
      "grad_norm": 7.096879482269287,
      "learning_rate": 1.3619870091526426e-05,
      "logits/chosen": 1.9362733364105225,
      "logits/rejected": 1.8924524784088135,
      "logps/chosen": -213.8209686279297,
      "logps/rejected": -232.6898193359375,
      "loss": 0.4478,
      "rewards/accuracies": 0.8166667819023132,
      "rewards/chosen": -2.5080599784851074,
      "rewards/margins": 1.512339472770691,
      "rewards/rejected": -4.0203986167907715,
      "step": 1730
    },
    {
      "epoch": 0.5137289636846767,
      "grad_norm": 10.205978393554688,
      "learning_rate": 1.3617094774136405e-05,
      "logits/chosen": 1.705865502357483,
      "logits/rejected": 1.6761407852172852,
      "logps/chosen": -214.02694702148438,
      "logps/rejected": -233.987060546875,
      "loss": 0.432,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.457549810409546,
      "rewards/margins": 1.748765230178833,
      "rewards/rejected": -4.206315040588379,
      "step": 1740
    },
    {
      "epoch": 0.5166814289932093,
      "grad_norm": 9.89065170288086,
      "learning_rate": 1.3614319456746384e-05,
      "logits/chosen": 1.7233545780181885,
      "logits/rejected": 1.6838144063949585,
      "logps/chosen": -213.57470703125,
      "logps/rejected": -230.47579956054688,
      "loss": 0.5118,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -2.562201976776123,
      "rewards/margins": 1.5503149032592773,
      "rewards/rejected": -4.1125168800354,
      "step": 1750
    },
    {
      "epoch": 0.519633894301742,
      "grad_norm": 5.909658432006836,
      "learning_rate": 1.3611544139356363e-05,
      "logits/chosen": 1.881115198135376,
      "logits/rejected": 1.8846698999404907,
      "logps/chosen": -217.54592895507812,
      "logps/rejected": -233.6405487060547,
      "loss": 0.3637,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.7034945487976074,
      "rewards/margins": 1.8425480127334595,
      "rewards/rejected": -4.546042442321777,
      "step": 1760
    },
    {
      "epoch": 0.5225863596102746,
      "grad_norm": 7.261380672454834,
      "learning_rate": 1.3608768821966342e-05,
      "logits/chosen": 2.1151416301727295,
      "logits/rejected": 2.0793769359588623,
      "logps/chosen": -221.4873809814453,
      "logps/rejected": -238.36001586914062,
      "loss": 0.404,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -3.1679484844207764,
      "rewards/margins": 1.775097131729126,
      "rewards/rejected": -4.943045616149902,
      "step": 1770
    },
    {
      "epoch": 0.5255388249188072,
      "grad_norm": 9.798108100891113,
      "learning_rate": 1.3605993504576321e-05,
      "logits/chosen": 2.1483030319213867,
      "logits/rejected": 2.1052119731903076,
      "logps/chosen": -221.1150360107422,
      "logps/rejected": -238.43179321289062,
      "loss": 0.4617,
      "rewards/accuracies": 0.7833333015441895,
      "rewards/chosen": -2.9746711254119873,
      "rewards/margins": 1.7289714813232422,
      "rewards/rejected": -4.703642845153809,
      "step": 1780
    },
    {
      "epoch": 0.5284912902273399,
      "grad_norm": 15.364336013793945,
      "learning_rate": 1.36032181871863e-05,
      "logits/chosen": 1.8836174011230469,
      "logits/rejected": 1.8350496292114258,
      "logps/chosen": -217.30429077148438,
      "logps/rejected": -232.18112182617188,
      "loss": 0.526,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -3.0188276767730713,
      "rewards/margins": 1.4717059135437012,
      "rewards/rejected": -4.490532875061035,
      "step": 1790
    },
    {
      "epoch": 0.5314437555358724,
      "grad_norm": 17.891401290893555,
      "learning_rate": 1.3600442869796281e-05,
      "logits/chosen": 2.1916515827178955,
      "logits/rejected": 2.1705522537231445,
      "logps/chosen": -223.8739013671875,
      "logps/rejected": -234.02182006835938,
      "loss": 0.609,
      "rewards/accuracies": 0.73333340883255,
      "rewards/chosen": -3.0375161170959473,
      "rewards/margins": 1.091819405555725,
      "rewards/rejected": -4.129336357116699,
      "step": 1800
    },
    {
      "epoch": 0.5343962208444051,
      "grad_norm": 13.366281509399414,
      "learning_rate": 1.359766755240626e-05,
      "logits/chosen": 1.8447974920272827,
      "logits/rejected": 1.819527268409729,
      "logps/chosen": -221.0160675048828,
      "logps/rejected": -235.2687530517578,
      "loss": 0.4544,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -2.8818764686584473,
      "rewards/margins": 1.5959842205047607,
      "rewards/rejected": -4.477861404418945,
      "step": 1810
    },
    {
      "epoch": 0.5373486861529377,
      "grad_norm": 7.008061408996582,
      "learning_rate": 1.359489223501624e-05,
      "logits/chosen": 1.8874187469482422,
      "logits/rejected": 1.877894639968872,
      "logps/chosen": -214.2112579345703,
      "logps/rejected": -230.3230438232422,
      "loss": 0.4161,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.683110475540161,
      "rewards/margins": 1.721260666847229,
      "rewards/rejected": -4.4043707847595215,
      "step": 1820
    },
    {
      "epoch": 0.5403011514614703,
      "grad_norm": 7.282690048217773,
      "learning_rate": 1.3592116917626218e-05,
      "logits/chosen": 1.6366586685180664,
      "logits/rejected": 1.615143060684204,
      "logps/chosen": -230.55203247070312,
      "logps/rejected": -241.218017578125,
      "loss": 0.4357,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -3.637394666671753,
      "rewards/margins": 1.6582340002059937,
      "rewards/rejected": -5.295628547668457,
      "step": 1830
    },
    {
      "epoch": 0.543253616770003,
      "grad_norm": 7.909693241119385,
      "learning_rate": 1.3589341600236197e-05,
      "logits/chosen": 1.8665746450424194,
      "logits/rejected": 1.8289117813110352,
      "logps/chosen": -219.9162139892578,
      "logps/rejected": -236.56179809570312,
      "loss": 0.5136,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -2.729038715362549,
      "rewards/margins": 1.4635531902313232,
      "rewards/rejected": -4.192591667175293,
      "step": 1840
    },
    {
      "epoch": 0.5462060820785356,
      "grad_norm": 5.152673244476318,
      "learning_rate": 1.3586566282846177e-05,
      "logits/chosen": 1.8958371877670288,
      "logits/rejected": 1.8452669382095337,
      "logps/chosen": -215.92074584960938,
      "logps/rejected": -232.5720672607422,
      "loss": 0.4022,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -2.890207290649414,
      "rewards/margins": 1.4724963903427124,
      "rewards/rejected": -4.362703800201416,
      "step": 1850
    },
    {
      "epoch": 0.5491585473870682,
      "grad_norm": 16.869836807250977,
      "learning_rate": 1.3583790965456156e-05,
      "logits/chosen": 1.7068731784820557,
      "logits/rejected": 1.6766220331192017,
      "logps/chosen": -209.456787109375,
      "logps/rejected": -221.5702667236328,
      "loss": 0.4939,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -1.8542261123657227,
      "rewards/margins": 1.5404595136642456,
      "rewards/rejected": -3.394686222076416,
      "step": 1860
    },
    {
      "epoch": 0.5521110126956008,
      "grad_norm": 18.494823455810547,
      "learning_rate": 1.3581015648066136e-05,
      "logits/chosen": 1.8932186365127563,
      "logits/rejected": 1.8799817562103271,
      "logps/chosen": -205.7574462890625,
      "logps/rejected": -218.01889038085938,
      "loss": 0.3717,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -1.603096604347229,
      "rewards/margins": 1.5441899299621582,
      "rewards/rejected": -3.1472864151000977,
      "step": 1870
    },
    {
      "epoch": 0.5550634780041335,
      "grad_norm": 9.70190715789795,
      "learning_rate": 1.3578240330676116e-05,
      "logits/chosen": 2.4461331367492676,
      "logits/rejected": 2.402604579925537,
      "logps/chosen": -204.447265625,
      "logps/rejected": -221.625244140625,
      "loss": 0.4144,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4334218502044678,
      "rewards/margins": 1.7850885391235352,
      "rewards/rejected": -3.218510389328003,
      "step": 1880
    },
    {
      "epoch": 0.5580159433126661,
      "grad_norm": 18.195884704589844,
      "learning_rate": 1.3575465013286093e-05,
      "logits/chosen": 1.7889354228973389,
      "logits/rejected": 1.780643105506897,
      "logps/chosen": -219.21249389648438,
      "logps/rejected": -240.5228729248047,
      "loss": 0.3485,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -2.431593418121338,
      "rewards/margins": 2.0536422729492188,
      "rewards/rejected": -4.485236167907715,
      "step": 1890
    },
    {
      "epoch": 0.5609684086211987,
      "grad_norm": 12.906248092651367,
      "learning_rate": 1.3572689695896074e-05,
      "logits/chosen": 1.4069783687591553,
      "logits/rejected": 1.3652421236038208,
      "logps/chosen": -228.88485717773438,
      "logps/rejected": -247.2256317138672,
      "loss": 0.6126,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -4.082823753356934,
      "rewards/margins": 1.169109582901001,
      "rewards/rejected": -5.2519330978393555,
      "step": 1900
    },
    {
      "epoch": 0.5639208739297313,
      "grad_norm": 10.02679443359375,
      "learning_rate": 1.3569914378506053e-05,
      "logits/chosen": 1.6921923160552979,
      "logits/rejected": 1.6810457706451416,
      "logps/chosen": -241.3960418701172,
      "logps/rejected": -252.912109375,
      "loss": 0.4979,
      "rewards/accuracies": 0.7833333015441895,
      "rewards/chosen": -4.360673904418945,
      "rewards/margins": 1.6450086832046509,
      "rewards/rejected": -6.005682945251465,
      "step": 1910
    },
    {
      "epoch": 0.566873339238264,
      "grad_norm": 26.051149368286133,
      "learning_rate": 1.3567139061116034e-05,
      "logits/chosen": 1.886042833328247,
      "logits/rejected": 1.8604122400283813,
      "logps/chosen": -235.29931640625,
      "logps/rejected": -254.4606170654297,
      "loss": 0.436,
      "rewards/accuracies": 0.7500001192092896,
      "rewards/chosen": -4.144074440002441,
      "rewards/margins": 1.6637548208236694,
      "rewards/rejected": -5.807829856872559,
      "step": 1920
    },
    {
      "epoch": 0.5698258045467965,
      "grad_norm": 5.737347602844238,
      "learning_rate": 1.3564363743726011e-05,
      "logits/chosen": 1.6549739837646484,
      "logits/rejected": 1.6258865594863892,
      "logps/chosen": -230.9759063720703,
      "logps/rejected": -245.1206512451172,
      "loss": 0.4467,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -4.100613594055176,
      "rewards/margins": 1.5774638652801514,
      "rewards/rejected": -5.678077220916748,
      "step": 1930
    },
    {
      "epoch": 0.5727782698553292,
      "grad_norm": 13.151211738586426,
      "learning_rate": 1.3561588426335992e-05,
      "logits/chosen": 1.7374343872070312,
      "logits/rejected": 1.6971461772918701,
      "logps/chosen": -235.87020874023438,
      "logps/rejected": -248.107666015625,
      "loss": 0.4827,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -4.267586708068848,
      "rewards/margins": 1.5253559350967407,
      "rewards/rejected": -5.792942523956299,
      "step": 1940
    },
    {
      "epoch": 0.5757307351638619,
      "grad_norm": 10.349345207214355,
      "learning_rate": 1.355881310894597e-05,
      "logits/chosen": 1.7755870819091797,
      "logits/rejected": 1.768372893333435,
      "logps/chosen": -235.17807006835938,
      "logps/rejected": -245.50637817382812,
      "loss": 0.5872,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -4.142346382141113,
      "rewards/margins": 1.1638643741607666,
      "rewards/rejected": -5.306210041046143,
      "step": 1950
    },
    {
      "epoch": 0.5786832004723944,
      "grad_norm": 5.75040864944458,
      "learning_rate": 1.3556037791555948e-05,
      "logits/chosen": 2.524606704711914,
      "logits/rejected": 2.493046760559082,
      "logps/chosen": -217.213623046875,
      "logps/rejected": -239.1621551513672,
      "loss": 0.37,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.4971656799316406,
      "rewards/margins": 1.9362781047821045,
      "rewards/rejected": -4.433443546295166,
      "step": 1960
    },
    {
      "epoch": 0.5816356657809271,
      "grad_norm": 1.8992551565170288,
      "learning_rate": 1.3553262474165929e-05,
      "logits/chosen": 1.5935600996017456,
      "logits/rejected": 1.5921610593795776,
      "logps/chosen": -219.0408172607422,
      "logps/rejected": -242.63931274414062,
      "loss": 0.397,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -2.496480703353882,
      "rewards/margins": 2.1562464237213135,
      "rewards/rejected": -4.652726650238037,
      "step": 1970
    },
    {
      "epoch": 0.5845881310894597,
      "grad_norm": 20.211759567260742,
      "learning_rate": 1.3550487156775908e-05,
      "logits/chosen": 1.8880058526992798,
      "logits/rejected": 1.8645970821380615,
      "logps/chosen": -224.1688232421875,
      "logps/rejected": -243.7769317626953,
      "loss": 0.5538,
      "rewards/accuracies": 0.7166666388511658,
      "rewards/chosen": -3.1108176708221436,
      "rewards/margins": 1.4632368087768555,
      "rewards/rejected": -4.574053764343262,
      "step": 1980
    },
    {
      "epoch": 0.5875405963979923,
      "grad_norm": 7.658727645874023,
      "learning_rate": 1.3547711839385889e-05,
      "logits/chosen": 2.035264730453491,
      "logits/rejected": 1.9896312952041626,
      "logps/chosen": -225.02902221679688,
      "logps/rejected": -243.33486938476562,
      "loss": 0.3452,
      "rewards/accuracies": 0.8500000834465027,
      "rewards/chosen": -3.243809938430786,
      "rewards/margins": 1.877197265625,
      "rewards/rejected": -5.121006965637207,
      "step": 1990
    },
    {
      "epoch": 0.5904930617065249,
      "grad_norm": 12.478321075439453,
      "learning_rate": 1.3544936521995866e-05,
      "logits/chosen": 1.4973925352096558,
      "logits/rejected": 1.4807231426239014,
      "logps/chosen": -224.5206756591797,
      "logps/rejected": -236.0790557861328,
      "loss": 0.5609,
      "rewards/accuracies": 0.7333332896232605,
      "rewards/chosen": -3.677720546722412,
      "rewards/margins": 1.3114778995513916,
      "rewards/rejected": -4.989198207855225,
      "step": 2000
    },
    {
      "epoch": 0.5934455270150576,
      "grad_norm": 31.778894424438477,
      "learning_rate": 1.3542161204605847e-05,
      "logits/chosen": 1.8034944534301758,
      "logits/rejected": 1.7812381982803345,
      "logps/chosen": -226.6380615234375,
      "logps/rejected": -244.3704071044922,
      "loss": 0.4081,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -3.3364646434783936,
      "rewards/margins": 1.876442551612854,
      "rewards/rejected": -5.212906837463379,
      "step": 2010
    },
    {
      "epoch": 0.5963979923235901,
      "grad_norm": 13.98127555847168,
      "learning_rate": 1.3539385887215826e-05,
      "logits/chosen": 1.4317817687988281,
      "logits/rejected": 1.3935118913650513,
      "logps/chosen": -236.33053588867188,
      "logps/rejected": -249.42221069335938,
      "loss": 0.4895,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -4.363944053649902,
      "rewards/margins": 1.2279210090637207,
      "rewards/rejected": -5.591865539550781,
      "step": 2020
    },
    {
      "epoch": 0.5993504576321228,
      "grad_norm": 13.668774604797363,
      "learning_rate": 1.3536610569825805e-05,
      "logits/chosen": 1.504664421081543,
      "logits/rejected": 1.4936225414276123,
      "logps/chosen": -227.1090545654297,
      "logps/rejected": -249.2073211669922,
      "loss": 0.3555,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -4.093752384185791,
      "rewards/margins": 1.6671100854873657,
      "rewards/rejected": -5.760862350463867,
      "step": 2030
    },
    {
      "epoch": 0.6023029229406555,
      "grad_norm": 6.522639274597168,
      "learning_rate": 1.3533835252435784e-05,
      "logits/chosen": 2.076383352279663,
      "logits/rejected": 2.026214122772217,
      "logps/chosen": -223.25723266601562,
      "logps/rejected": -235.27597045898438,
      "loss": 0.433,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.042590379714966,
      "rewards/margins": 1.4702637195587158,
      "rewards/rejected": -4.512854099273682,
      "step": 2040
    },
    {
      "epoch": 0.6052553882491881,
      "grad_norm": 9.283330917358398,
      "learning_rate": 1.3531059935045763e-05,
      "logits/chosen": 2.0535130500793457,
      "logits/rejected": 2.0173239707946777,
      "logps/chosen": -225.689453125,
      "logps/rejected": -238.03076171875,
      "loss": 0.3888,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -2.9615206718444824,
      "rewards/margins": 1.6004616022109985,
      "rewards/rejected": -4.561981678009033,
      "step": 2050
    },
    {
      "epoch": 0.6082078535577207,
      "grad_norm": 8.968916893005371,
      "learning_rate": 1.3528284617655744e-05,
      "logits/chosen": 1.8899818658828735,
      "logits/rejected": 1.8687330484390259,
      "logps/chosen": -214.4208526611328,
      "logps/rejected": -232.1885223388672,
      "loss": 0.4488,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -2.3540055751800537,
      "rewards/margins": 1.594180703163147,
      "rewards/rejected": -3.948186159133911,
      "step": 2060
    },
    {
      "epoch": 0.6111603188662533,
      "grad_norm": 12.452316284179688,
      "learning_rate": 1.3525509300265722e-05,
      "logits/chosen": 1.7403440475463867,
      "logits/rejected": 1.7250325679779053,
      "logps/chosen": -223.43331909179688,
      "logps/rejected": -243.54476928710938,
      "loss": 0.4286,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -3.257106065750122,
      "rewards/margins": 1.6357395648956299,
      "rewards/rejected": -4.89284610748291,
      "step": 2070
    },
    {
      "epoch": 0.614112784174786,
      "grad_norm": 9.182977676391602,
      "learning_rate": 1.35227339828757e-05,
      "logits/chosen": 1.8488614559173584,
      "logits/rejected": 1.8088678121566772,
      "logps/chosen": -237.1939697265625,
      "logps/rejected": -248.3012237548828,
      "loss": 0.5315,
      "rewards/accuracies": 0.7166667580604553,
      "rewards/chosen": -4.300778865814209,
      "rewards/margins": 1.2478586435317993,
      "rewards/rejected": -5.548637390136719,
      "step": 2080
    },
    {
      "epoch": 0.6170652494833185,
      "grad_norm": 6.772730350494385,
      "learning_rate": 1.3519958665485682e-05,
      "logits/chosen": 1.3696739673614502,
      "logits/rejected": 1.337594985961914,
      "logps/chosen": -236.8318328857422,
      "logps/rejected": -258.8675537109375,
      "loss": 0.4678,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -4.970269203186035,
      "rewards/margins": 1.56415593624115,
      "rewards/rejected": -6.534424781799316,
      "step": 2090
    },
    {
      "epoch": 0.6200177147918512,
      "grad_norm": 6.990164756774902,
      "learning_rate": 1.351718334809566e-05,
      "logits/chosen": 1.4778045415878296,
      "logits/rejected": 1.4415054321289062,
      "logps/chosen": -248.77236938476562,
      "logps/rejected": -266.4332275390625,
      "loss": 0.4521,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -5.676333427429199,
      "rewards/margins": 1.4625577926635742,
      "rewards/rejected": -7.138890743255615,
      "step": 2100
    },
    {
      "epoch": 0.6229701801003839,
      "grad_norm": 13.50905704498291,
      "learning_rate": 1.351440803070564e-05,
      "logits/chosen": 1.5923372507095337,
      "logits/rejected": 1.5700346231460571,
      "logps/chosen": -255.0437774658203,
      "logps/rejected": -267.72418212890625,
      "loss": 0.556,
      "rewards/accuracies": 0.7000001072883606,
      "rewards/chosen": -5.883848190307617,
      "rewards/margins": 1.3667175769805908,
      "rewards/rejected": -7.250565528869629,
      "step": 2110
    },
    {
      "epoch": 0.6259226454089164,
      "grad_norm": 9.517277717590332,
      "learning_rate": 1.3511632713315619e-05,
      "logits/chosen": 1.7505407333374023,
      "logits/rejected": 1.6975517272949219,
      "logps/chosen": -246.8147430419922,
      "logps/rejected": -263.2955322265625,
      "loss": 0.3265,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -5.309286594390869,
      "rewards/margins": 2.0168328285217285,
      "rewards/rejected": -7.326119899749756,
      "step": 2120
    },
    {
      "epoch": 0.6288751107174491,
      "grad_norm": 8.486474990844727,
      "learning_rate": 1.35088573959256e-05,
      "logits/chosen": 1.6621224880218506,
      "logits/rejected": 1.6545464992523193,
      "logps/chosen": -238.83718872070312,
      "logps/rejected": -252.0231170654297,
      "loss": 0.4823,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -4.965978622436523,
      "rewards/margins": 1.4259916543960571,
      "rewards/rejected": -6.391969680786133,
      "step": 2130
    },
    {
      "epoch": 0.6318275760259817,
      "grad_norm": 8.177766799926758,
      "learning_rate": 1.3506082078535577e-05,
      "logits/chosen": 1.800206184387207,
      "logits/rejected": 1.7559401988983154,
      "logps/chosen": -233.135009765625,
      "logps/rejected": -246.7517852783203,
      "loss": 0.3879,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.830902576446533,
      "rewards/margins": 1.889718770980835,
      "rewards/rejected": -5.720621109008789,
      "step": 2140
    },
    {
      "epoch": 0.6347800413345143,
      "grad_norm": 13.993441581726074,
      "learning_rate": 1.3503306761145556e-05,
      "logits/chosen": 1.75235915184021,
      "logits/rejected": 1.7302045822143555,
      "logps/chosen": -220.74014282226562,
      "logps/rejected": -239.58456420898438,
      "loss": 0.6128,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -3.577069044113159,
      "rewards/margins": 0.9810279011726379,
      "rewards/rejected": -4.558095932006836,
      "step": 2150
    },
    {
      "epoch": 0.6377325066430469,
      "grad_norm": 11.774426460266113,
      "learning_rate": 1.3500531443755537e-05,
      "logits/chosen": 1.5361355543136597,
      "logits/rejected": 1.4695086479187012,
      "logps/chosen": -218.120361328125,
      "logps/rejected": -241.84970092773438,
      "loss": 0.4311,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -3.0788958072662354,
      "rewards/margins": 1.724207878112793,
      "rewards/rejected": -4.803103446960449,
      "step": 2160
    },
    {
      "epoch": 0.6406849719515796,
      "grad_norm": 15.344810485839844,
      "learning_rate": 1.3497756126365516e-05,
      "logits/chosen": 1.6597483158111572,
      "logits/rejected": 1.6316022872924805,
      "logps/chosen": -229.647705078125,
      "logps/rejected": -246.96170043945312,
      "loss": 0.4627,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -3.7047946453094482,
      "rewards/margins": 1.6768817901611328,
      "rewards/rejected": -5.381677150726318,
      "step": 2170
    },
    {
      "epoch": 0.6436374372601122,
      "grad_norm": 19.584596633911133,
      "learning_rate": 1.3494980808975495e-05,
      "logits/chosen": 1.599426507949829,
      "logits/rejected": 1.5895678997039795,
      "logps/chosen": -219.2548065185547,
      "logps/rejected": -236.66006469726562,
      "loss": 0.4976,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -3.3471856117248535,
      "rewards/margins": 1.4633190631866455,
      "rewards/rejected": -4.81050443649292,
      "step": 2180
    },
    {
      "epoch": 0.6465899025686448,
      "grad_norm": 16.07794761657715,
      "learning_rate": 1.3492205491585474e-05,
      "logits/chosen": 1.8742517232894897,
      "logits/rejected": 1.832945466041565,
      "logps/chosen": -230.7783660888672,
      "logps/rejected": -245.83023071289062,
      "loss": 0.5104,
      "rewards/accuracies": 0.73333340883255,
      "rewards/chosen": -3.7160305976867676,
      "rewards/margins": 1.6130876541137695,
      "rewards/rejected": -5.329117774963379,
      "step": 2190
    },
    {
      "epoch": 0.6495423678771775,
      "grad_norm": 14.455732345581055,
      "learning_rate": 1.3489430174195455e-05,
      "logits/chosen": 1.7586157321929932,
      "logits/rejected": 1.7200095653533936,
      "logps/chosen": -218.68453979492188,
      "logps/rejected": -236.0807647705078,
      "loss": 0.493,
      "rewards/accuracies": 0.7666667699813843,
      "rewards/chosen": -2.9572536945343018,
      "rewards/margins": 1.6133859157562256,
      "rewards/rejected": -4.570639610290527,
      "step": 2200
    },
    {
      "epoch": 0.6524948331857101,
      "grad_norm": 9.684196472167969,
      "learning_rate": 1.3486654856805432e-05,
      "logits/chosen": 1.4890525341033936,
      "logits/rejected": 1.4559011459350586,
      "logps/chosen": -211.1943817138672,
      "logps/rejected": -225.76803588867188,
      "loss": 0.5473,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -2.619689464569092,
      "rewards/margins": 1.1616191864013672,
      "rewards/rejected": -3.781308650970459,
      "step": 2210
    },
    {
      "epoch": 0.6554472984942427,
      "grad_norm": 26.145715713500977,
      "learning_rate": 1.3483879539415411e-05,
      "logits/chosen": 1.0327318906784058,
      "logits/rejected": 1.0128448009490967,
      "logps/chosen": -222.3230438232422,
      "logps/rejected": -227.02273559570312,
      "loss": 0.4753,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -2.8474466800689697,
      "rewards/margins": 1.0498592853546143,
      "rewards/rejected": -3.897305965423584,
      "step": 2220
    },
    {
      "epoch": 0.6583997638027753,
      "grad_norm": 20.891019821166992,
      "learning_rate": 1.3481104222025392e-05,
      "logits/chosen": 1.601196050643921,
      "logits/rejected": 1.5953127145767212,
      "logps/chosen": -223.9537811279297,
      "logps/rejected": -236.14108276367188,
      "loss": 0.5024,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -3.162986993789673,
      "rewards/margins": 1.335449457168579,
      "rewards/rejected": -4.498436450958252,
      "step": 2230
    },
    {
      "epoch": 0.661352229111308,
      "grad_norm": 16.10728645324707,
      "learning_rate": 1.3478328904635371e-05,
      "logits/chosen": 1.68524169921875,
      "logits/rejected": 1.615313172340393,
      "logps/chosen": -227.87759399414062,
      "logps/rejected": -252.3703155517578,
      "loss": 0.4106,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -3.6117682456970215,
      "rewards/margins": 1.7749840021133423,
      "rewards/rejected": -5.386752128601074,
      "step": 2240
    },
    {
      "epoch": 0.6643046944198405,
      "grad_norm": 3.742856979370117,
      "learning_rate": 1.347555358724535e-05,
      "logits/chosen": 1.2156870365142822,
      "logits/rejected": 1.1696093082427979,
      "logps/chosen": -243.95413208007812,
      "logps/rejected": -260.34417724609375,
      "loss": 0.4342,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -4.959190845489502,
      "rewards/margins": 1.5964150428771973,
      "rewards/rejected": -6.555605888366699,
      "step": 2250
    },
    {
      "epoch": 0.6672571597283732,
      "grad_norm": 9.285175323486328,
      "learning_rate": 1.347277826985533e-05,
      "logits/chosen": 1.8180900812149048,
      "logits/rejected": 1.7885189056396484,
      "logps/chosen": -238.59866333007812,
      "logps/rejected": -256.05462646484375,
      "loss": 0.3497,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -4.7046661376953125,
      "rewards/margins": 2.2111153602600098,
      "rewards/rejected": -6.915781497955322,
      "step": 2260
    },
    {
      "epoch": 0.6702096250369058,
      "grad_norm": 13.101806640625,
      "learning_rate": 1.3470002952465309e-05,
      "logits/chosen": 1.6123281717300415,
      "logits/rejected": 1.5876528024673462,
      "logps/chosen": -244.1875457763672,
      "logps/rejected": -260.723388671875,
      "loss": 0.3964,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -4.832831382751465,
      "rewards/margins": 1.9934494495391846,
      "rewards/rejected": -6.826280117034912,
      "step": 2270
    },
    {
      "epoch": 0.6731620903454384,
      "grad_norm": 5.795004367828369,
      "learning_rate": 1.346722763507529e-05,
      "logits/chosen": 1.6466524600982666,
      "logits/rejected": 1.6251786947250366,
      "logps/chosen": -241.861328125,
      "logps/rejected": -249.494140625,
      "loss": 0.5307,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -4.791224002838135,
      "rewards/margins": 1.4060837030410767,
      "rewards/rejected": -6.19730806350708,
      "step": 2280
    },
    {
      "epoch": 0.676114555653971,
      "grad_norm": 10.529450416564941,
      "learning_rate": 1.3464452317685267e-05,
      "logits/chosen": 1.2919337749481201,
      "logits/rejected": 1.244478702545166,
      "logps/chosen": -234.5137481689453,
      "logps/rejected": -255.3479461669922,
      "loss": 0.3166,
      "rewards/accuracies": 0.8666667938232422,
      "rewards/chosen": -3.9928791522979736,
      "rewards/margins": 2.3423233032226562,
      "rewards/rejected": -6.335202693939209,
      "step": 2290
    },
    {
      "epoch": 0.6790670209625037,
      "grad_norm": 9.481734275817871,
      "learning_rate": 1.3461677000295248e-05,
      "logits/chosen": 1.9883439540863037,
      "logits/rejected": 1.9624271392822266,
      "logps/chosen": -237.67825317382812,
      "logps/rejected": -250.0701904296875,
      "loss": 0.4709,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -4.351906776428223,
      "rewards/margins": 1.6711633205413818,
      "rewards/rejected": -6.023070335388184,
      "step": 2300
    },
    {
      "epoch": 0.6820194862710364,
      "grad_norm": 8.998260498046875,
      "learning_rate": 1.3458901682905227e-05,
      "logits/chosen": 2.227842330932617,
      "logits/rejected": 2.1790027618408203,
      "logps/chosen": -228.3326873779297,
      "logps/rejected": -252.16885375976562,
      "loss": 0.4261,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -3.8716323375701904,
      "rewards/margins": 1.5997364521026611,
      "rewards/rejected": -5.47136926651001,
      "step": 2310
    },
    {
      "epoch": 0.6849719515795689,
      "grad_norm": 4.343469619750977,
      "learning_rate": 1.3456126365515206e-05,
      "logits/chosen": 2.0801570415496826,
      "logits/rejected": 2.0321195125579834,
      "logps/chosen": -233.8759307861328,
      "logps/rejected": -245.7513427734375,
      "loss": 0.4762,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -4.2544145584106445,
      "rewards/margins": 1.3997471332550049,
      "rewards/rejected": -5.6541619300842285,
      "step": 2320
    },
    {
      "epoch": 0.6879244168881016,
      "grad_norm": 16.531583786010742,
      "learning_rate": 1.3453351048125185e-05,
      "logits/chosen": 1.4432233572006226,
      "logits/rejected": 1.3933697938919067,
      "logps/chosen": -234.000732421875,
      "logps/rejected": -250.14767456054688,
      "loss": 0.4719,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -4.393177032470703,
      "rewards/margins": 1.5619419813156128,
      "rewards/rejected": -5.955118656158447,
      "step": 2330
    },
    {
      "epoch": 0.6908768821966342,
      "grad_norm": 5.333813190460205,
      "learning_rate": 1.3450575730735164e-05,
      "logits/chosen": 1.6649919748306274,
      "logits/rejected": 1.613682508468628,
      "logps/chosen": -233.9722900390625,
      "logps/rejected": -253.9030303955078,
      "loss": 0.3481,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -3.9345831871032715,
      "rewards/margins": 1.7766332626342773,
      "rewards/rejected": -5.711216926574707,
      "step": 2340
    },
    {
      "epoch": 0.6938293475051668,
      "grad_norm": 10.64805793762207,
      "learning_rate": 1.3447800413345145e-05,
      "logits/chosen": 2.27833890914917,
      "logits/rejected": 2.2645649909973145,
      "logps/chosen": -226.3809356689453,
      "logps/rejected": -238.9543914794922,
      "loss": 0.59,
      "rewards/accuracies": 0.73333340883255,
      "rewards/chosen": -3.319288730621338,
      "rewards/margins": 1.3309288024902344,
      "rewards/rejected": -4.6502180099487305,
      "step": 2350
    },
    {
      "epoch": 0.6967818128136994,
      "grad_norm": 21.095972061157227,
      "learning_rate": 1.3445025095955122e-05,
      "logits/chosen": 1.7004657983779907,
      "logits/rejected": 1.664320945739746,
      "logps/chosen": -222.7300262451172,
      "logps/rejected": -237.3887176513672,
      "loss": 0.5832,
      "rewards/accuracies": 0.7666667699813843,
      "rewards/chosen": -2.7043955326080322,
      "rewards/margins": 1.3359944820404053,
      "rewards/rejected": -4.040390491485596,
      "step": 2360
    },
    {
      "epoch": 0.6997342781222321,
      "grad_norm": 7.566328048706055,
      "learning_rate": 1.3442249778565103e-05,
      "logits/chosen": 2.241934299468994,
      "logits/rejected": 2.224870204925537,
      "logps/chosen": -212.15567016601562,
      "logps/rejected": -227.1227569580078,
      "loss": 0.4751,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -2.0360748767852783,
      "rewards/margins": 1.6208505630493164,
      "rewards/rejected": -3.656925916671753,
      "step": 2370
    },
    {
      "epoch": 0.7026867434307646,
      "grad_norm": 7.052640438079834,
      "learning_rate": 1.3439474461175082e-05,
      "logits/chosen": 1.651160478591919,
      "logits/rejected": 1.6344168186187744,
      "logps/chosen": -210.13034057617188,
      "logps/rejected": -227.03329467773438,
      "loss": 0.4153,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -1.9351472854614258,
      "rewards/margins": 1.3609774112701416,
      "rewards/rejected": -3.2961246967315674,
      "step": 2380
    },
    {
      "epoch": 0.7056392087392973,
      "grad_norm": 8.202964782714844,
      "learning_rate": 1.3436699143785061e-05,
      "logits/chosen": 1.505774974822998,
      "logits/rejected": 1.4626855850219727,
      "logps/chosen": -220.3681182861328,
      "logps/rejected": -239.55435180664062,
      "loss": 0.4166,
      "rewards/accuracies": 0.8333333134651184,
      "rewards/chosen": -2.743316888809204,
      "rewards/margins": 1.818441390991211,
      "rewards/rejected": -4.561758518218994,
      "step": 2390
    },
    {
      "epoch": 0.70859167404783,
      "grad_norm": 3.2797610759735107,
      "learning_rate": 1.343392382639504e-05,
      "logits/chosen": 1.7525250911712646,
      "logits/rejected": 1.734079360961914,
      "logps/chosen": -225.23428344726562,
      "logps/rejected": -242.56106567382812,
      "loss": 0.5246,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -3.6169910430908203,
      "rewards/margins": 1.5791720151901245,
      "rewards/rejected": -5.196162700653076,
      "step": 2400
    },
    {
      "epoch": 0.7115441393563625,
      "grad_norm": 3.9646799564361572,
      "learning_rate": 1.343114850900502e-05,
      "logits/chosen": 1.1957104206085205,
      "logits/rejected": 1.1699364185333252,
      "logps/chosen": -233.3480224609375,
      "logps/rejected": -249.3564453125,
      "loss": 0.4089,
      "rewards/accuracies": 0.8833333253860474,
      "rewards/chosen": -4.069450378417969,
      "rewards/margins": 1.8499746322631836,
      "rewards/rejected": -5.919425010681152,
      "step": 2410
    },
    {
      "epoch": 0.7144966046648952,
      "grad_norm": 15.115782737731934,
      "learning_rate": 1.3428373191615e-05,
      "logits/chosen": 1.6632356643676758,
      "logits/rejected": 1.6630780696868896,
      "logps/chosen": -231.6785125732422,
      "logps/rejected": -239.1132049560547,
      "loss": 0.561,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -3.7141201496124268,
      "rewards/margins": 1.2258572578430176,
      "rewards/rejected": -4.939977645874023,
      "step": 2420
    },
    {
      "epoch": 0.7174490699734278,
      "grad_norm": 7.266149520874023,
      "learning_rate": 1.3425597874224977e-05,
      "logits/chosen": 1.7508083581924438,
      "logits/rejected": 1.7235103845596313,
      "logps/chosen": -226.7529296875,
      "logps/rejected": -245.5639190673828,
      "loss": 0.4292,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.528123140335083,
      "rewards/margins": 1.696459412574768,
      "rewards/rejected": -5.224583148956299,
      "step": 2430
    },
    {
      "epoch": 0.7204015352819605,
      "grad_norm": 12.394981384277344,
      "learning_rate": 1.3422822556834958e-05,
      "logits/chosen": 1.6595075130462646,
      "logits/rejected": 1.6292304992675781,
      "logps/chosen": -238.4109649658203,
      "logps/rejected": -255.07803344726562,
      "loss": 0.4512,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -4.517991065979004,
      "rewards/margins": 1.4756367206573486,
      "rewards/rejected": -5.993628025054932,
      "step": 2440
    },
    {
      "epoch": 0.723354000590493,
      "grad_norm": 9.686607360839844,
      "learning_rate": 1.3420047239444937e-05,
      "logits/chosen": 1.7872474193572998,
      "logits/rejected": 1.7783632278442383,
      "logps/chosen": -225.1597442626953,
      "logps/rejected": -246.85598754882812,
      "loss": 0.4431,
      "rewards/accuracies": 0.8333333134651184,
      "rewards/chosen": -3.415158748626709,
      "rewards/margins": 1.7207212448120117,
      "rewards/rejected": -5.135880470275879,
      "step": 2450
    },
    {
      "epoch": 0.7263064658990257,
      "grad_norm": 8.06390380859375,
      "learning_rate": 1.3417271922054916e-05,
      "logits/chosen": 1.7674286365509033,
      "logits/rejected": 1.7457473278045654,
      "logps/chosen": -221.8867645263672,
      "logps/rejected": -240.35873413085938,
      "loss": 0.4595,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.2154650688171387,
      "rewards/margins": 1.7674522399902344,
      "rewards/rejected": -4.982917785644531,
      "step": 2460
    },
    {
      "epoch": 0.7292589312075584,
      "grad_norm": 6.629768371582031,
      "learning_rate": 1.3414496604664895e-05,
      "logits/chosen": 2.3482272624969482,
      "logits/rejected": 2.298130512237549,
      "logps/chosen": -221.29296875,
      "logps/rejected": -235.0601806640625,
      "loss": 0.464,
      "rewards/accuracies": 0.7833333015441895,
      "rewards/chosen": -3.204723358154297,
      "rewards/margins": 1.3429046869277954,
      "rewards/rejected": -4.547627925872803,
      "step": 2470
    },
    {
      "epoch": 0.7322113965160909,
      "grad_norm": 9.254414558410645,
      "learning_rate": 1.3411721287274875e-05,
      "logits/chosen": 1.7165155410766602,
      "logits/rejected": 1.6824452877044678,
      "logps/chosen": -220.60836791992188,
      "logps/rejected": -236.2544708251953,
      "loss": 0.3494,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.543658971786499,
      "rewards/margins": 1.5564302206039429,
      "rewards/rejected": -4.100089073181152,
      "step": 2480
    },
    {
      "epoch": 0.7351638618246236,
      "grad_norm": 15.132071495056152,
      "learning_rate": 1.3408945969884855e-05,
      "logits/chosen": 1.644031286239624,
      "logits/rejected": 1.6066020727157593,
      "logps/chosen": -222.27816772460938,
      "logps/rejected": -238.72116088867188,
      "loss": 0.4922,
      "rewards/accuracies": 0.7000000476837158,
      "rewards/chosen": -3.220592975616455,
      "rewards/margins": 1.2782717943191528,
      "rewards/rejected": -4.498864650726318,
      "step": 2490
    },
    {
      "epoch": 0.7381163271331562,
      "grad_norm": 13.642657279968262,
      "learning_rate": 1.3406170652494833e-05,
      "logits/chosen": 1.8591352701187134,
      "logits/rejected": 1.8378957509994507,
      "logps/chosen": -227.8294677734375,
      "logps/rejected": -246.09188842773438,
      "loss": 0.3441,
      "rewards/accuracies": 0.8333333134651184,
      "rewards/chosen": -3.3963286876678467,
      "rewards/margins": 1.7526044845581055,
      "rewards/rejected": -5.1489338874816895,
      "step": 2500
    },
    {
      "epoch": 0.7410687924416888,
      "grad_norm": 11.771068572998047,
      "learning_rate": 1.3403395335104814e-05,
      "logits/chosen": 1.6808137893676758,
      "logits/rejected": 1.647444486618042,
      "logps/chosen": -233.53781127929688,
      "logps/rejected": -241.0928192138672,
      "loss": 0.5759,
      "rewards/accuracies": 0.7333332896232605,
      "rewards/chosen": -4.526597499847412,
      "rewards/margins": 1.252535104751587,
      "rewards/rejected": -5.77913236618042,
      "step": 2510
    },
    {
      "epoch": 0.7440212577502214,
      "grad_norm": 9.431434631347656,
      "learning_rate": 1.3400620017714793e-05,
      "logits/chosen": 1.7388464212417603,
      "logits/rejected": 1.7170991897583008,
      "logps/chosen": -249.14309692382812,
      "logps/rejected": -264.8706359863281,
      "loss": 0.351,
      "rewards/accuracies": 0.8833333849906921,
      "rewards/chosen": -5.6199164390563965,
      "rewards/margins": 1.5822842121124268,
      "rewards/rejected": -7.202200889587402,
      "step": 2520
    },
    {
      "epoch": 0.7469737230587541,
      "grad_norm": 12.756147384643555,
      "learning_rate": 1.3397844700324772e-05,
      "logits/chosen": 1.4888737201690674,
      "logits/rejected": 1.500072956085205,
      "logps/chosen": -249.2912139892578,
      "logps/rejected": -257.7295227050781,
      "loss": 0.3617,
      "rewards/accuracies": 0.8833333253860474,
      "rewards/chosen": -5.489395618438721,
      "rewards/margins": 1.6116209030151367,
      "rewards/rejected": -7.101016044616699,
      "step": 2530
    },
    {
      "epoch": 0.7499261883672866,
      "grad_norm": 10.537861824035645,
      "learning_rate": 1.339506938293475e-05,
      "logits/chosen": 1.816738486289978,
      "logits/rejected": 1.7873451709747314,
      "logps/chosen": -249.53500366210938,
      "logps/rejected": -266.4341735839844,
      "loss": 0.5053,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -5.644336223602295,
      "rewards/margins": 1.3840121030807495,
      "rewards/rejected": -7.028348445892334,
      "step": 2540
    },
    {
      "epoch": 0.7528786536758193,
      "grad_norm": 13.80566120147705,
      "learning_rate": 1.339229406554473e-05,
      "logits/chosen": 1.9275859594345093,
      "logits/rejected": 1.9134845733642578,
      "logps/chosen": -242.1443634033203,
      "logps/rejected": -258.7532653808594,
      "loss": 0.4416,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -5.1263747215271,
      "rewards/margins": 1.4631366729736328,
      "rewards/rejected": -6.589510917663574,
      "step": 2550
    },
    {
      "epoch": 0.755831118984352,
      "grad_norm": 23.0699520111084,
      "learning_rate": 1.338951874815471e-05,
      "logits/chosen": 1.845823884010315,
      "logits/rejected": 1.8365917205810547,
      "logps/chosen": -230.4671630859375,
      "logps/rejected": -245.8060760498047,
      "loss": 0.3942,
      "rewards/accuracies": 0.8000000715255737,
      "rewards/chosen": -4.130305290222168,
      "rewards/margins": 1.794734239578247,
      "rewards/rejected": -5.925039291381836,
      "step": 2560
    },
    {
      "epoch": 0.7587835842928845,
      "grad_norm": 24.328031539916992,
      "learning_rate": 1.3386743430764688e-05,
      "logits/chosen": 1.280505895614624,
      "logits/rejected": 1.2575253248214722,
      "logps/chosen": -236.17471313476562,
      "logps/rejected": -253.02798461914062,
      "loss": 0.4475,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -4.209868907928467,
      "rewards/margins": 1.761461615562439,
      "rewards/rejected": -5.971330642700195,
      "step": 2570
    },
    {
      "epoch": 0.7617360496014172,
      "grad_norm": 10.664253234863281,
      "learning_rate": 1.3383968113374669e-05,
      "logits/chosen": 1.5993231534957886,
      "logits/rejected": 1.5650861263275146,
      "logps/chosen": -237.09011840820312,
      "logps/rejected": -264.7799987792969,
      "loss": 0.3721,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -4.254899978637695,
      "rewards/margins": 2.3437681198120117,
      "rewards/rejected": -6.598668098449707,
      "step": 2580
    },
    {
      "epoch": 0.7646885149099498,
      "grad_norm": 3.974543333053589,
      "learning_rate": 1.3381192795984648e-05,
      "logits/chosen": 1.9601688385009766,
      "logits/rejected": 1.9144971370697021,
      "logps/chosen": -241.25717163085938,
      "logps/rejected": -260.1230163574219,
      "loss": 0.3892,
      "rewards/accuracies": 0.7666667699813843,
      "rewards/chosen": -4.792645454406738,
      "rewards/margins": 2.0907504558563232,
      "rewards/rejected": -6.883396148681641,
      "step": 2590
    },
    {
      "epoch": 0.7676409802184825,
      "grad_norm": 17.852161407470703,
      "learning_rate": 1.3378417478594627e-05,
      "logits/chosen": 2.0537538528442383,
      "logits/rejected": 2.0375828742980957,
      "logps/chosen": -243.23690795898438,
      "logps/rejected": -264.3807373046875,
      "loss": 0.3646,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -5.24772834777832,
      "rewards/margins": 2.352879524230957,
      "rewards/rejected": -7.600607872009277,
      "step": 2600
    },
    {
      "epoch": 0.770593445527015,
      "grad_norm": 4.179238319396973,
      "learning_rate": 1.3375642161204606e-05,
      "logits/chosen": 1.8308980464935303,
      "logits/rejected": 1.7665717601776123,
      "logps/chosen": -251.68051147460938,
      "logps/rejected": -274.1708679199219,
      "loss": 0.4216,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -5.981488227844238,
      "rewards/margins": 1.9682178497314453,
      "rewards/rejected": -7.949706077575684,
      "step": 2610
    },
    {
      "epoch": 0.7735459108355477,
      "grad_norm": 6.608105182647705,
      "learning_rate": 1.3372866843814585e-05,
      "logits/chosen": 1.7054383754730225,
      "logits/rejected": 1.676379919052124,
      "logps/chosen": -251.63601684570312,
      "logps/rejected": -267.3368225097656,
      "loss": 0.4823,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -5.923998832702637,
      "rewards/margins": 2.0606024265289307,
      "rewards/rejected": -7.984601020812988,
      "step": 2620
    },
    {
      "epoch": 0.7764983761440803,
      "grad_norm": 11.150504112243652,
      "learning_rate": 1.3370091526424566e-05,
      "logits/chosen": 1.5328174829483032,
      "logits/rejected": 1.477830171585083,
      "logps/chosen": -243.7900848388672,
      "logps/rejected": -273.1423034667969,
      "loss": 0.4004,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -5.429393768310547,
      "rewards/margins": 2.227504253387451,
      "rewards/rejected": -7.65689754486084,
      "step": 2630
    },
    {
      "epoch": 0.7794508414526129,
      "grad_norm": 4.457523822784424,
      "learning_rate": 1.3367316209034545e-05,
      "logits/chosen": 2.071924924850464,
      "logits/rejected": 2.008505344390869,
      "logps/chosen": -242.3470458984375,
      "logps/rejected": -270.0126037597656,
      "loss": 0.4247,
      "rewards/accuracies": 0.8500000834465027,
      "rewards/chosen": -4.93048620223999,
      "rewards/margins": 2.620312213897705,
      "rewards/rejected": -7.5507988929748535,
      "step": 2640
    },
    {
      "epoch": 0.7824033067611456,
      "grad_norm": 11.27305793762207,
      "learning_rate": 1.3364540891644523e-05,
      "logits/chosen": 1.999228835105896,
      "logits/rejected": 1.934348702430725,
      "logps/chosen": -240.60580444335938,
      "logps/rejected": -268.4480895996094,
      "loss": 0.3352,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -4.6401753425598145,
      "rewards/margins": 2.8007724285125732,
      "rewards/rejected": -7.44094705581665,
      "step": 2650
    },
    {
      "epoch": 0.7853557720696782,
      "grad_norm": 3.16184401512146,
      "learning_rate": 1.3361765574254503e-05,
      "logits/chosen": 1.4247567653656006,
      "logits/rejected": 1.3610819578170776,
      "logps/chosen": -238.6754608154297,
      "logps/rejected": -263.87786865234375,
      "loss": 0.3132,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -4.959012031555176,
      "rewards/margins": 2.5006542205810547,
      "rewards/rejected": -7.4596662521362305,
      "step": 2660
    },
    {
      "epoch": 0.7883082373782108,
      "grad_norm": 6.182461738586426,
      "learning_rate": 1.3358990256864482e-05,
      "logits/chosen": 1.7136027812957764,
      "logits/rejected": 1.6764005422592163,
      "logps/chosen": -238.6610565185547,
      "logps/rejected": -262.7388000488281,
      "loss": 0.4797,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -4.6100664138793945,
      "rewards/margins": 1.8431684970855713,
      "rewards/rejected": -6.453234672546387,
      "step": 2670
    },
    {
      "epoch": 0.7912607026867434,
      "grad_norm": 10.036079406738281,
      "learning_rate": 1.3356214939474461e-05,
      "logits/chosen": 2.134854793548584,
      "logits/rejected": 2.100802183151245,
      "logps/chosen": -231.7191925048828,
      "logps/rejected": -256.3919677734375,
      "loss": 0.498,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -4.458333492279053,
      "rewards/margins": 1.9010595083236694,
      "rewards/rejected": -6.359393119812012,
      "step": 2680
    },
    {
      "epoch": 0.7942131679952761,
      "grad_norm": 10.951508522033691,
      "learning_rate": 1.335343962208444e-05,
      "logits/chosen": 2.409749984741211,
      "logits/rejected": 2.3733713626861572,
      "logps/chosen": -244.2689208984375,
      "logps/rejected": -258.9924621582031,
      "loss": 0.5364,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -5.173091411590576,
      "rewards/margins": 1.3859598636627197,
      "rewards/rejected": -6.559051513671875,
      "step": 2690
    },
    {
      "epoch": 0.7971656333038086,
      "grad_norm": 10.297005653381348,
      "learning_rate": 1.3350664304694421e-05,
      "logits/chosen": 1.9035123586654663,
      "logits/rejected": 1.8540548086166382,
      "logps/chosen": -247.46218872070312,
      "logps/rejected": -268.3414001464844,
      "loss": 0.482,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -5.858069896697998,
      "rewards/margins": 1.65804123878479,
      "rewards/rejected": -7.516111850738525,
      "step": 2700
    },
    {
      "epoch": 0.8001180986123413,
      "grad_norm": 21.168245315551758,
      "learning_rate": 1.33478889873044e-05,
      "logits/chosen": 1.8319380283355713,
      "logits/rejected": 1.825060486793518,
      "logps/chosen": -253.51058959960938,
      "logps/rejected": -271.57098388671875,
      "loss": 0.4091,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -5.904909133911133,
      "rewards/margins": 1.8534977436065674,
      "rewards/rejected": -7.758406639099121,
      "step": 2710
    },
    {
      "epoch": 0.803070563920874,
      "grad_norm": 17.55923843383789,
      "learning_rate": 1.3345113669914378e-05,
      "logits/chosen": 1.795570731163025,
      "logits/rejected": 1.7469676733016968,
      "logps/chosen": -238.065673828125,
      "logps/rejected": -264.3460693359375,
      "loss": 0.4368,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -4.836581230163574,
      "rewards/margins": 2.484616756439209,
      "rewards/rejected": -7.321198463439941,
      "step": 2720
    },
    {
      "epoch": 0.8060230292294066,
      "grad_norm": 11.434313774108887,
      "learning_rate": 1.3342338352524359e-05,
      "logits/chosen": 1.669029951095581,
      "logits/rejected": 1.6695903539657593,
      "logps/chosen": -238.06735229492188,
      "logps/rejected": -252.9189453125,
      "loss": 0.4868,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -4.735990047454834,
      "rewards/margins": 1.4618206024169922,
      "rewards/rejected": -6.197810173034668,
      "step": 2730
    },
    {
      "epoch": 0.8089754945379392,
      "grad_norm": 23.105010986328125,
      "learning_rate": 1.3339563035134338e-05,
      "logits/chosen": 1.4371103048324585,
      "logits/rejected": 1.4153692722320557,
      "logps/chosen": -241.7360382080078,
      "logps/rejected": -257.27947998046875,
      "loss": 0.4981,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -4.804509162902832,
      "rewards/margins": 1.7569952011108398,
      "rewards/rejected": -6.5615034103393555,
      "step": 2740
    },
    {
      "epoch": 0.8119279598464718,
      "grad_norm": 10.26120376586914,
      "learning_rate": 1.3336787717744317e-05,
      "logits/chosen": 2.171462297439575,
      "logits/rejected": 2.160189151763916,
      "logps/chosen": -230.92202758789062,
      "logps/rejected": -248.5690460205078,
      "loss": 0.3414,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -4.397122383117676,
      "rewards/margins": 1.9134109020233154,
      "rewards/rejected": -6.310534477233887,
      "step": 2750
    },
    {
      "epoch": 0.8148804251550045,
      "grad_norm": 14.660733222961426,
      "learning_rate": 1.3334012400354296e-05,
      "logits/chosen": 1.5914760828018188,
      "logits/rejected": 1.5621037483215332,
      "logps/chosen": -235.47946166992188,
      "logps/rejected": -254.29690551757812,
      "loss": 0.4564,
      "rewards/accuracies": 0.7166666388511658,
      "rewards/chosen": -4.629134178161621,
      "rewards/margins": 1.6277179718017578,
      "rewards/rejected": -6.256852149963379,
      "step": 2760
    },
    {
      "epoch": 0.817832890463537,
      "grad_norm": 6.888092517852783,
      "learning_rate": 1.3331237082964277e-05,
      "logits/chosen": 1.7123874425888062,
      "logits/rejected": 1.6654632091522217,
      "logps/chosen": -245.5713653564453,
      "logps/rejected": -272.95831298828125,
      "loss": 0.3188,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -5.619174957275391,
      "rewards/margins": 2.427351951599121,
      "rewards/rejected": -8.046526908874512,
      "step": 2770
    },
    {
      "epoch": 0.8207853557720697,
      "grad_norm": 14.324542999267578,
      "learning_rate": 1.3328461765574256e-05,
      "logits/chosen": 1.8719091415405273,
      "logits/rejected": 1.834575891494751,
      "logps/chosen": -251.0049285888672,
      "logps/rejected": -273.02056884765625,
      "loss": 0.4309,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -6.3194780349731445,
      "rewards/margins": 2.0960536003112793,
      "rewards/rejected": -8.415533065795898,
      "step": 2780
    },
    {
      "epoch": 0.8237378210806023,
      "grad_norm": 4.466433048248291,
      "learning_rate": 1.3325686448184233e-05,
      "logits/chosen": 1.9998033046722412,
      "logits/rejected": 1.9692509174346924,
      "logps/chosen": -254.4224090576172,
      "logps/rejected": -277.0865783691406,
      "loss": 0.2985,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -6.055428981781006,
      "rewards/margins": 2.3235161304473877,
      "rewards/rejected": -8.378945350646973,
      "step": 2790
    },
    {
      "epoch": 0.8266902863891349,
      "grad_norm": 17.197568893432617,
      "learning_rate": 1.3322911130794214e-05,
      "logits/chosen": 1.647760033607483,
      "logits/rejected": 1.6005092859268188,
      "logps/chosen": -254.66903686523438,
      "logps/rejected": -271.08087158203125,
      "loss": 0.4414,
      "rewards/accuracies": 0.7833333015441895,
      "rewards/chosen": -5.964147090911865,
      "rewards/margins": 1.9285484552383423,
      "rewards/rejected": -7.89269495010376,
      "step": 2800
    },
    {
      "epoch": 0.8296427516976675,
      "grad_norm": 14.119647979736328,
      "learning_rate": 1.3320135813404193e-05,
      "logits/chosen": 1.3376798629760742,
      "logits/rejected": 1.316976547241211,
      "logps/chosen": -245.3262176513672,
      "logps/rejected": -265.84088134765625,
      "loss": 0.3643,
      "rewards/accuracies": 0.8666667938232422,
      "rewards/chosen": -5.700783729553223,
      "rewards/margins": 1.9827136993408203,
      "rewards/rejected": -7.683498382568359,
      "step": 2810
    },
    {
      "epoch": 0.8325952170062002,
      "grad_norm": 10.657768249511719,
      "learning_rate": 1.3317360496014172e-05,
      "logits/chosen": 1.654627799987793,
      "logits/rejected": 1.6553523540496826,
      "logps/chosen": -251.3500518798828,
      "logps/rejected": -264.16009521484375,
      "loss": 0.6555,
      "rewards/accuracies": 0.6833333969116211,
      "rewards/chosen": -5.966770172119141,
      "rewards/margins": 1.3009307384490967,
      "rewards/rejected": -7.267701148986816,
      "step": 2820
    },
    {
      "epoch": 0.8355476823147328,
      "grad_norm": 20.43616485595703,
      "learning_rate": 1.3314585178624151e-05,
      "logits/chosen": 2.0694308280944824,
      "logits/rejected": 2.052708148956299,
      "logps/chosen": -252.3549041748047,
      "logps/rejected": -276.04754638671875,
      "loss": 0.4194,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -5.892794609069824,
      "rewards/margins": 1.9730974435806274,
      "rewards/rejected": -7.865891933441162,
      "step": 2830
    },
    {
      "epoch": 0.8385001476232654,
      "grad_norm": 11.037577629089355,
      "learning_rate": 1.331180986123413e-05,
      "logits/chosen": 2.171482563018799,
      "logits/rejected": 2.121962070465088,
      "logps/chosen": -264.2300109863281,
      "logps/rejected": -276.23187255859375,
      "loss": 0.4755,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -7.032765865325928,
      "rewards/margins": 1.622155785560608,
      "rewards/rejected": -8.654922485351562,
      "step": 2840
    },
    {
      "epoch": 0.8414526129317981,
      "grad_norm": 9.856927871704102,
      "learning_rate": 1.3309034543844111e-05,
      "logits/chosen": 1.8728437423706055,
      "logits/rejected": 1.8315082788467407,
      "logps/chosen": -262.2685852050781,
      "logps/rejected": -289.2478942871094,
      "loss": 0.349,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -7.149012088775635,
      "rewards/margins": 2.5169081687927246,
      "rewards/rejected": -9.665921211242676,
      "step": 2850
    },
    {
      "epoch": 0.8444050782403307,
      "grad_norm": 8.971355438232422,
      "learning_rate": 1.3306259226454089e-05,
      "logits/chosen": 1.4708524942398071,
      "logits/rejected": 1.420526385307312,
      "logps/chosen": -266.77294921875,
      "logps/rejected": -288.76153564453125,
      "loss": 0.4618,
      "rewards/accuracies": 0.7833333015441895,
      "rewards/chosen": -7.74569845199585,
      "rewards/margins": 2.114204168319702,
      "rewards/rejected": -9.859904289245605,
      "step": 2860
    },
    {
      "epoch": 0.8473575435488633,
      "grad_norm": 1.8128509521484375,
      "learning_rate": 1.330348390906407e-05,
      "logits/chosen": 1.6498119831085205,
      "logits/rejected": 1.5832607746124268,
      "logps/chosen": -283.00274658203125,
      "logps/rejected": -305.797119140625,
      "loss": 0.3746,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -9.060656547546387,
      "rewards/margins": 2.2532906532287598,
      "rewards/rejected": -11.313946723937988,
      "step": 2870
    },
    {
      "epoch": 0.8503100088573959,
      "grad_norm": 21.191694259643555,
      "learning_rate": 1.3300708591674048e-05,
      "logits/chosen": 1.6646220684051514,
      "logits/rejected": 1.6098798513412476,
      "logps/chosen": -285.8505859375,
      "logps/rejected": -304.4947204589844,
      "loss": 0.541,
      "rewards/accuracies": 0.7166666984558105,
      "rewards/chosen": -9.37657642364502,
      "rewards/margins": 1.7458921670913696,
      "rewards/rejected": -11.122467041015625,
      "step": 2880
    },
    {
      "epoch": 0.8532624741659286,
      "grad_norm": 14.45644474029541,
      "learning_rate": 1.329793327428403e-05,
      "logits/chosen": 1.5735158920288086,
      "logits/rejected": 1.5053097009658813,
      "logps/chosen": -277.87396240234375,
      "logps/rejected": -302.256103515625,
      "loss": 0.2739,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -8.487276077270508,
      "rewards/margins": 2.3486533164978027,
      "rewards/rejected": -10.835927963256836,
      "step": 2890
    },
    {
      "epoch": 0.8562149394744611,
      "grad_norm": 11.694518089294434,
      "learning_rate": 1.3295157956894007e-05,
      "logits/chosen": 1.2872204780578613,
      "logits/rejected": 1.2591532468795776,
      "logps/chosen": -278.8903503417969,
      "logps/rejected": -294.6697998046875,
      "loss": 0.4948,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -8.95665168762207,
      "rewards/margins": 1.65414297580719,
      "rewards/rejected": -10.610795974731445,
      "step": 2900
    },
    {
      "epoch": 0.8591674047829938,
      "grad_norm": 18.62244415283203,
      "learning_rate": 1.3292382639503986e-05,
      "logits/chosen": 1.5454537868499756,
      "logits/rejected": 1.4505410194396973,
      "logps/chosen": -293.6468200683594,
      "logps/rejected": -314.6730041503906,
      "loss": 0.4025,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -9.76935863494873,
      "rewards/margins": 2.296422004699707,
      "rewards/rejected": -12.065780639648438,
      "step": 2910
    },
    {
      "epoch": 0.8621198700915265,
      "grad_norm": 15.534807205200195,
      "learning_rate": 1.3289607322113966e-05,
      "logits/chosen": 1.5841622352600098,
      "logits/rejected": 1.5570766925811768,
      "logps/chosen": -290.5137939453125,
      "logps/rejected": -308.4744873046875,
      "loss": 0.5717,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -9.790321350097656,
      "rewards/margins": 1.6715519428253174,
      "rewards/rejected": -11.461874008178711,
      "step": 2920
    },
    {
      "epoch": 0.865072335400059,
      "grad_norm": 6.768592834472656,
      "learning_rate": 1.3286832004723944e-05,
      "logits/chosen": 1.801452398300171,
      "logits/rejected": 1.7509618997573853,
      "logps/chosen": -280.267333984375,
      "logps/rejected": -297.47125244140625,
      "loss": 0.5219,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -8.36961841583252,
      "rewards/margins": 2.0041604042053223,
      "rewards/rejected": -10.373779296875,
      "step": 2930
    },
    {
      "epoch": 0.8680248007085917,
      "grad_norm": 9.914046287536621,
      "learning_rate": 1.3284056687333925e-05,
      "logits/chosen": 1.0488011837005615,
      "logits/rejected": 1.0089941024780273,
      "logps/chosen": -264.17877197265625,
      "logps/rejected": -287.1211853027344,
      "loss": 0.4914,
      "rewards/accuracies": 0.7666667699813843,
      "rewards/chosen": -7.376272678375244,
      "rewards/margins": 1.9041343927383423,
      "rewards/rejected": -9.280406951904297,
      "step": 2940
    },
    {
      "epoch": 0.8709772660171243,
      "grad_norm": 12.779129981994629,
      "learning_rate": 1.3281281369943904e-05,
      "logits/chosen": 1.5115623474121094,
      "logits/rejected": 1.4326189756393433,
      "logps/chosen": -258.0809326171875,
      "logps/rejected": -274.5574645996094,
      "loss": 0.3051,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -6.416189670562744,
      "rewards/margins": 2.0673232078552246,
      "rewards/rejected": -8.483513832092285,
      "step": 2950
    },
    {
      "epoch": 0.8739297313256569,
      "grad_norm": 18.44586753845215,
      "learning_rate": 1.3278506052553885e-05,
      "logits/chosen": 1.3928598165512085,
      "logits/rejected": 1.337924838066101,
      "logps/chosen": -256.1123046875,
      "logps/rejected": -272.1076354980469,
      "loss": 0.6111,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -6.447245121002197,
      "rewards/margins": 1.5968029499053955,
      "rewards/rejected": -8.044047355651855,
      "step": 2960
    },
    {
      "epoch": 0.8768821966341895,
      "grad_norm": 11.251091957092285,
      "learning_rate": 1.3275730735163862e-05,
      "logits/chosen": 1.9031355381011963,
      "logits/rejected": 1.896731972694397,
      "logps/chosen": -244.6492462158203,
      "logps/rejected": -263.42767333984375,
      "loss": 0.5462,
      "rewards/accuracies": 0.7333332896232605,
      "rewards/chosen": -5.308390140533447,
      "rewards/margins": 1.5405476093292236,
      "rewards/rejected": -6.84893798828125,
      "step": 2970
    },
    {
      "epoch": 0.8798346619427222,
      "grad_norm": 3.754075765609741,
      "learning_rate": 1.3272955417773841e-05,
      "logits/chosen": 1.6938501596450806,
      "logits/rejected": 1.683863878250122,
      "logps/chosen": -236.094970703125,
      "logps/rejected": -248.4314422607422,
      "loss": 0.54,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -4.208281993865967,
      "rewards/margins": 1.7601112127304077,
      "rewards/rejected": -5.968392848968506,
      "step": 2980
    },
    {
      "epoch": 0.8827871272512547,
      "grad_norm": 15.658319473266602,
      "learning_rate": 1.3270180100383822e-05,
      "logits/chosen": 2.1633808612823486,
      "logits/rejected": 2.0952308177948,
      "logps/chosen": -236.1529541015625,
      "logps/rejected": -259.26531982421875,
      "loss": 0.4322,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -4.70351505279541,
      "rewards/margins": 1.8153455257415771,
      "rewards/rejected": -6.518860816955566,
      "step": 2990
    },
    {
      "epoch": 0.8857395925597874,
      "grad_norm": 13.638282775878906,
      "learning_rate": 1.32674047829938e-05,
      "logits/chosen": 1.3909242153167725,
      "logits/rejected": 1.3490570783615112,
      "logps/chosen": -240.69662475585938,
      "logps/rejected": -255.9873046875,
      "loss": 0.4134,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -4.865976810455322,
      "rewards/margins": 1.8362267017364502,
      "rewards/rejected": -6.702203273773193,
      "step": 3000
    },
    {
      "epoch": 0.8886920578683201,
      "grad_norm": 13.374686241149902,
      "learning_rate": 1.326462946560378e-05,
      "logits/chosen": 1.5085018873214722,
      "logits/rejected": 1.4487152099609375,
      "logps/chosen": -242.27297973632812,
      "logps/rejected": -257.96478271484375,
      "loss": 0.4702,
      "rewards/accuracies": 0.7666667103767395,
      "rewards/chosen": -5.170873641967773,
      "rewards/margins": 1.7321170568466187,
      "rewards/rejected": -6.902990818023682,
      "step": 3010
    },
    {
      "epoch": 0.8916445231768527,
      "grad_norm": 12.2987060546875,
      "learning_rate": 1.3261854148213759e-05,
      "logits/chosen": 1.7791109085083008,
      "logits/rejected": 1.7377516031265259,
      "logps/chosen": -241.3758544921875,
      "logps/rejected": -261.485595703125,
      "loss": 0.3556,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -4.953756809234619,
      "rewards/margins": 1.974958062171936,
      "rewards/rejected": -6.928713798522949,
      "step": 3020
    },
    {
      "epoch": 0.8945969884853853,
      "grad_norm": 10.725205421447754,
      "learning_rate": 1.3259078830823738e-05,
      "logits/chosen": 1.4304133653640747,
      "logits/rejected": 1.4066088199615479,
      "logps/chosen": -249.0398406982422,
      "logps/rejected": -266.79541015625,
      "loss": 0.6216,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -5.787106513977051,
      "rewards/margins": 1.5763267278671265,
      "rewards/rejected": -7.363433837890625,
      "step": 3030
    },
    {
      "epoch": 0.8975494537939179,
      "grad_norm": 11.681480407714844,
      "learning_rate": 1.3256303513433717e-05,
      "logits/chosen": 1.836707353591919,
      "logits/rejected": 1.7942771911621094,
      "logps/chosen": -247.09176635742188,
      "logps/rejected": -268.43255615234375,
      "loss": 0.4264,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -5.793015956878662,
      "rewards/margins": 1.994370698928833,
      "rewards/rejected": -7.7873854637146,
      "step": 3040
    },
    {
      "epoch": 0.9005019191024506,
      "grad_norm": 6.504594326019287,
      "learning_rate": 1.3253528196043696e-05,
      "logits/chosen": 1.4818928241729736,
      "logits/rejected": 1.431213617324829,
      "logps/chosen": -256.16400146484375,
      "logps/rejected": -272.9295959472656,
      "loss": 0.3716,
      "rewards/accuracies": 0.8333333134651184,
      "rewards/chosen": -6.258927345275879,
      "rewards/margins": 2.0493290424346924,
      "rewards/rejected": -8.308256149291992,
      "step": 3050
    },
    {
      "epoch": 0.9034543844109831,
      "grad_norm": 5.829302787780762,
      "learning_rate": 1.3250752878653677e-05,
      "logits/chosen": 1.680281400680542,
      "logits/rejected": 1.6428568363189697,
      "logps/chosen": -251.74270629882812,
      "logps/rejected": -274.03509521484375,
      "loss": 0.376,
      "rewards/accuracies": 0.8500000834465027,
      "rewards/chosen": -6.187534809112549,
      "rewards/margins": 2.008575677871704,
      "rewards/rejected": -8.196109771728516,
      "step": 3060
    },
    {
      "epoch": 0.9064068497195158,
      "grad_norm": 25.16523551940918,
      "learning_rate": 1.3247977561263656e-05,
      "logits/chosen": 1.7258758544921875,
      "logits/rejected": 1.6646066904067993,
      "logps/chosen": -265.00482177734375,
      "logps/rejected": -276.6694641113281,
      "loss": 0.6583,
      "rewards/accuracies": 0.76666659116745,
      "rewards/chosen": -7.037074089050293,
      "rewards/margins": 1.6075595617294312,
      "rewards/rejected": -8.644633293151855,
      "step": 3070
    },
    {
      "epoch": 0.9093593150280485,
      "grad_norm": 14.901409149169922,
      "learning_rate": 1.3245202243873635e-05,
      "logits/chosen": 1.4121084213256836,
      "logits/rejected": 1.3741744756698608,
      "logps/chosen": -255.4169921875,
      "logps/rejected": -272.0849914550781,
      "loss": 0.4105,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -6.24207878112793,
      "rewards/margins": 1.8929229974746704,
      "rewards/rejected": -8.135001182556152,
      "step": 3080
    },
    {
      "epoch": 0.912311780336581,
      "grad_norm": 11.77573299407959,
      "learning_rate": 1.3242426926483614e-05,
      "logits/chosen": 1.784369707107544,
      "logits/rejected": 1.756548523902893,
      "logps/chosen": -261.264404296875,
      "logps/rejected": -274.2457275390625,
      "loss": 0.5776,
      "rewards/accuracies": 0.6833333373069763,
      "rewards/chosen": -6.922667026519775,
      "rewards/margins": 1.2755677700042725,
      "rewards/rejected": -8.198234558105469,
      "step": 3090
    },
    {
      "epoch": 0.9152642456451137,
      "grad_norm": 15.165863990783691,
      "learning_rate": 1.3239651609093594e-05,
      "logits/chosen": 1.3242043256759644,
      "logits/rejected": 1.2832257747650146,
      "logps/chosen": -260.23907470703125,
      "logps/rejected": -279.4714050292969,
      "loss": 0.468,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -6.45790958404541,
      "rewards/margins": 1.8362728357315063,
      "rewards/rejected": -8.294182777404785,
      "step": 3100
    },
    {
      "epoch": 0.9182167109536463,
      "grad_norm": 4.948995113372803,
      "learning_rate": 1.3236876291703573e-05,
      "logits/chosen": 1.1523597240447998,
      "logits/rejected": 1.1178374290466309,
      "logps/chosen": -252.6334991455078,
      "logps/rejected": -271.37603759765625,
      "loss": 0.3597,
      "rewards/accuracies": 0.8833333253860474,
      "rewards/chosen": -6.096531867980957,
      "rewards/margins": 1.8894479274749756,
      "rewards/rejected": -7.9859795570373535,
      "step": 3110
    },
    {
      "epoch": 0.9211691762621789,
      "grad_norm": 17.782054901123047,
      "learning_rate": 1.3234100974313552e-05,
      "logits/chosen": 1.4602515697479248,
      "logits/rejected": 1.456504464149475,
      "logps/chosen": -249.89306640625,
      "logps/rejected": -263.3929443359375,
      "loss": 0.5271,
      "rewards/accuracies": 0.8333333134651184,
      "rewards/chosen": -5.887560844421387,
      "rewards/margins": 1.421481966972351,
      "rewards/rejected": -7.309042930603027,
      "step": 3120
    },
    {
      "epoch": 0.9241216415707115,
      "grad_norm": 14.11458969116211,
      "learning_rate": 1.3231325656923532e-05,
      "logits/chosen": 1.3507205247879028,
      "logits/rejected": 1.300984501838684,
      "logps/chosen": -250.4106903076172,
      "logps/rejected": -271.62603759765625,
      "loss": 0.409,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -5.898097038269043,
      "rewards/margins": 1.850616693496704,
      "rewards/rejected": -7.74871301651001,
      "step": 3130
    },
    {
      "epoch": 0.9270741068792442,
      "grad_norm": 11.083711624145508,
      "learning_rate": 1.3228550339533512e-05,
      "logits/chosen": 1.5098741054534912,
      "logits/rejected": 1.450758695602417,
      "logps/chosen": -246.9630584716797,
      "logps/rejected": -267.94403076171875,
      "loss": 0.3664,
      "rewards/accuracies": 0.8666667938232422,
      "rewards/chosen": -5.7855448722839355,
      "rewards/margins": 1.6937376260757446,
      "rewards/rejected": -7.479281425476074,
      "step": 3140
    },
    {
      "epoch": 0.9300265721877768,
      "grad_norm": 13.045709609985352,
      "learning_rate": 1.3225775022143489e-05,
      "logits/chosen": 1.8984880447387695,
      "logits/rejected": 1.8418853282928467,
      "logps/chosen": -253.41708374023438,
      "logps/rejected": -279.0598449707031,
      "loss": 0.4951,
      "rewards/accuracies": 0.7666667699813843,
      "rewards/chosen": -6.566128730773926,
      "rewards/margins": 1.7925249338150024,
      "rewards/rejected": -8.358654022216797,
      "step": 3150
    },
    {
      "epoch": 0.9329790374963094,
      "grad_norm": 18.502473831176758,
      "learning_rate": 1.322299970475347e-05,
      "logits/chosen": 1.5568758249282837,
      "logits/rejected": 1.5055983066558838,
      "logps/chosen": -265.91473388671875,
      "logps/rejected": -282.25262451171875,
      "loss": 0.5396,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -7.280808925628662,
      "rewards/margins": 1.7507107257843018,
      "rewards/rejected": -9.031518936157227,
      "step": 3160
    },
    {
      "epoch": 0.935931502804842,
      "grad_norm": 11.022493362426758,
      "learning_rate": 1.3220224387363449e-05,
      "logits/chosen": 1.7806504964828491,
      "logits/rejected": 1.732848882675171,
      "logps/chosen": -256.5837097167969,
      "logps/rejected": -278.5194091796875,
      "loss": 0.5215,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -6.874762058258057,
      "rewards/margins": 2.078705310821533,
      "rewards/rejected": -8.953466415405273,
      "step": 3170
    },
    {
      "epoch": 0.9388839681133747,
      "grad_norm": 18.66131591796875,
      "learning_rate": 1.3217449069973428e-05,
      "logits/chosen": 1.987839698791504,
      "logits/rejected": 1.9629474878311157,
      "logps/chosen": -256.25115966796875,
      "logps/rejected": -276.16204833984375,
      "loss": 0.4279,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -6.510622978210449,
      "rewards/margins": 1.9224287271499634,
      "rewards/rejected": -8.433051109313965,
      "step": 3180
    },
    {
      "epoch": 0.9418364334219073,
      "grad_norm": 16.07537269592285,
      "learning_rate": 1.3214673752583407e-05,
      "logits/chosen": 1.6790672540664673,
      "logits/rejected": 1.6133924722671509,
      "logps/chosen": -247.19088745117188,
      "logps/rejected": -272.8966064453125,
      "loss": 0.3942,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -6.061711311340332,
      "rewards/margins": 2.3595943450927734,
      "rewards/rejected": -8.421305656433105,
      "step": 3190
    },
    {
      "epoch": 0.9447888987304399,
      "grad_norm": 13.656707763671875,
      "learning_rate": 1.3211898435193388e-05,
      "logits/chosen": 1.32317316532135,
      "logits/rejected": 1.2621068954467773,
      "logps/chosen": -274.30987548828125,
      "logps/rejected": -299.3420104980469,
      "loss": 0.3058,
      "rewards/accuracies": 0.8666667938232422,
      "rewards/chosen": -7.5434088706970215,
      "rewards/margins": 2.6967504024505615,
      "rewards/rejected": -10.24015998840332,
      "step": 3200
    },
    {
      "epoch": 0.9477413640389726,
      "grad_norm": 12.990083694458008,
      "learning_rate": 1.3209123117803367e-05,
      "logits/chosen": 1.087052822113037,
      "logits/rejected": 1.0182263851165771,
      "logps/chosen": -269.35345458984375,
      "logps/rejected": -291.5362548828125,
      "loss": 0.2856,
      "rewards/accuracies": 0.8666667938232422,
      "rewards/chosen": -7.597662448883057,
      "rewards/margins": 2.263962984085083,
      "rewards/rejected": -9.861624717712402,
      "step": 3210
    },
    {
      "epoch": 0.9506938293475051,
      "grad_norm": 5.07531213760376,
      "learning_rate": 1.3206347800413344e-05,
      "logits/chosen": 1.2438087463378906,
      "logits/rejected": 1.1939241886138916,
      "logps/chosen": -274.26409912109375,
      "logps/rejected": -295.6121826171875,
      "loss": 0.4279,
      "rewards/accuracies": 0.8500000834465027,
      "rewards/chosen": -8.28117561340332,
      "rewards/margins": 1.9502719640731812,
      "rewards/rejected": -10.231447219848633,
      "step": 3220
    },
    {
      "epoch": 0.9536462946560378,
      "grad_norm": 18.259033203125,
      "learning_rate": 1.3203572483023325e-05,
      "logits/chosen": 1.9480104446411133,
      "logits/rejected": 1.9030284881591797,
      "logps/chosen": -270.5530090332031,
      "logps/rejected": -290.024658203125,
      "loss": 0.4598,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -7.866705894470215,
      "rewards/margins": 1.942850112915039,
      "rewards/rejected": -9.80955696105957,
      "step": 3230
    },
    {
      "epoch": 0.9565987599645704,
      "grad_norm": 6.355633735656738,
      "learning_rate": 1.3200797165633304e-05,
      "logits/chosen": 1.335245132446289,
      "logits/rejected": 1.3113055229187012,
      "logps/chosen": -265.134033203125,
      "logps/rejected": -278.2129821777344,
      "loss": 0.4104,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -7.278372764587402,
      "rewards/margins": 1.9217491149902344,
      "rewards/rejected": -9.200121879577637,
      "step": 3240
    },
    {
      "epoch": 0.959551225273103,
      "grad_norm": 4.730133056640625,
      "learning_rate": 1.3198021848243283e-05,
      "logits/chosen": 1.5622107982635498,
      "logits/rejected": 1.5168368816375732,
      "logps/chosen": -257.0769958496094,
      "logps/rejected": -278.2945861816406,
      "loss": 0.4922,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -6.436378479003906,
      "rewards/margins": 2.2523598670959473,
      "rewards/rejected": -8.688738822937012,
      "step": 3250
    },
    {
      "epoch": 0.9625036905816357,
      "grad_norm": 11.6077880859375,
      "learning_rate": 1.3195246530853262e-05,
      "logits/chosen": 1.8780800104141235,
      "logits/rejected": 1.7949422597885132,
      "logps/chosen": -254.9095001220703,
      "logps/rejected": -285.103759765625,
      "loss": 0.2859,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -6.147800922393799,
      "rewards/margins": 3.122497081756592,
      "rewards/rejected": -9.270298957824707,
      "step": 3260
    },
    {
      "epoch": 0.9654561558901683,
      "grad_norm": 10.753357887268066,
      "learning_rate": 1.3192471213463243e-05,
      "logits/chosen": 1.301247477531433,
      "logits/rejected": 1.2781046628952026,
      "logps/chosen": -255.3294219970703,
      "logps/rejected": -278.6102600097656,
      "loss": 0.3538,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -6.144237995147705,
      "rewards/margins": 2.426858425140381,
      "rewards/rejected": -8.571096420288086,
      "step": 3270
    },
    {
      "epoch": 0.968408621198701,
      "grad_norm": 18.150882720947266,
      "learning_rate": 1.3189695896073222e-05,
      "logits/chosen": 1.7905235290527344,
      "logits/rejected": 1.7418749332427979,
      "logps/chosen": -267.0331726074219,
      "logps/rejected": -282.67413330078125,
      "loss": 0.4826,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -7.332475185394287,
      "rewards/margins": 1.9074856042861938,
      "rewards/rejected": -9.239961624145508,
      "step": 3280
    },
    {
      "epoch": 0.9713610865072335,
      "grad_norm": 7.081390857696533,
      "learning_rate": 1.31869205786832e-05,
      "logits/chosen": 1.2974333763122559,
      "logits/rejected": 1.2694975137710571,
      "logps/chosen": -256.0501403808594,
      "logps/rejected": -278.04754638671875,
      "loss": 0.4543,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -6.6028852462768555,
      "rewards/margins": 1.9082180261611938,
      "rewards/rejected": -8.511103630065918,
      "step": 3290
    },
    {
      "epoch": 0.9743135518157662,
      "grad_norm": 3.9167139530181885,
      "learning_rate": 1.318414526129318e-05,
      "logits/chosen": 1.2592546939849854,
      "logits/rejected": 1.252767562866211,
      "logps/chosen": -247.43917846679688,
      "logps/rejected": -266.4688415527344,
      "loss": 0.5225,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -5.492032051086426,
      "rewards/margins": 1.5026628971099854,
      "rewards/rejected": -6.994694709777832,
      "step": 3300
    },
    {
      "epoch": 0.9772660171242988,
      "grad_norm": 14.146896362304688,
      "learning_rate": 1.318136994390316e-05,
      "logits/chosen": 1.4853968620300293,
      "logits/rejected": 1.440394639968872,
      "logps/chosen": -248.11795043945312,
      "logps/rejected": -273.76165771484375,
      "loss": 0.3881,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -5.007119655609131,
      "rewards/margins": 2.2613611221313477,
      "rewards/rejected": -7.2684807777404785,
      "step": 3310
    },
    {
      "epoch": 0.9802184824328314,
      "grad_norm": 20.277263641357422,
      "learning_rate": 1.317859462651314e-05,
      "logits/chosen": 1.4569566249847412,
      "logits/rejected": 1.4307544231414795,
      "logps/chosen": -244.9174041748047,
      "logps/rejected": -266.2756042480469,
      "loss": 0.3423,
      "rewards/accuracies": 0.7833333611488342,
      "rewards/chosen": -5.407546043395996,
      "rewards/margins": 2.159956932067871,
      "rewards/rejected": -7.567503452301025,
      "step": 3320
    },
    {
      "epoch": 0.983170947741364,
      "grad_norm": 11.516429901123047,
      "learning_rate": 1.3175819309123118e-05,
      "logits/chosen": 1.8550071716308594,
      "logits/rejected": 1.8194580078125,
      "logps/chosen": -251.12252807617188,
      "logps/rejected": -272.0694274902344,
      "loss": 0.3627,
      "rewards/accuracies": 0.8833333849906921,
      "rewards/chosen": -5.8637285232543945,
      "rewards/margins": 2.3514106273651123,
      "rewards/rejected": -8.215139389038086,
      "step": 3330
    },
    {
      "epoch": 0.9861234130498967,
      "grad_norm": 4.935647010803223,
      "learning_rate": 1.3173043991733097e-05,
      "logits/chosen": 1.4711494445800781,
      "logits/rejected": 1.4435946941375732,
      "logps/chosen": -262.4474182128906,
      "logps/rejected": -289.0701904296875,
      "loss": 0.2805,
      "rewards/accuracies": 0.8833333253860474,
      "rewards/chosen": -6.987551689147949,
      "rewards/margins": 2.121981382369995,
      "rewards/rejected": -9.10953426361084,
      "step": 3340
    },
    {
      "epoch": 0.9890758783584293,
      "grad_norm": 17.362571716308594,
      "learning_rate": 1.3170268674343078e-05,
      "logits/chosen": 1.5115950107574463,
      "logits/rejected": 1.4712798595428467,
      "logps/chosen": -267.8152770996094,
      "logps/rejected": -288.9140625,
      "loss": 0.4811,
      "rewards/accuracies": 0.8166667819023132,
      "rewards/chosen": -7.57457971572876,
      "rewards/margins": 1.8868621587753296,
      "rewards/rejected": -9.461441993713379,
      "step": 3350
    },
    {
      "epoch": 0.9920283436669619,
      "grad_norm": 15.209115028381348,
      "learning_rate": 1.3167493356953055e-05,
      "logits/chosen": 1.717556357383728,
      "logits/rejected": 1.6668548583984375,
      "logps/chosen": -266.2491760253906,
      "logps/rejected": -293.47027587890625,
      "loss": 0.3371,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -7.7080535888671875,
      "rewards/margins": 2.565962314605713,
      "rewards/rejected": -10.274015426635742,
      "step": 3360
    },
    {
      "epoch": 0.9949808089754946,
      "grad_norm": 13.800497055053711,
      "learning_rate": 1.3164718039563036e-05,
      "logits/chosen": 1.4772173166275024,
      "logits/rejected": 1.4498226642608643,
      "logps/chosen": -257.1181640625,
      "logps/rejected": -286.2941589355469,
      "loss": 0.4422,
      "rewards/accuracies": 0.7333332896232605,
      "rewards/chosen": -7.158396244049072,
      "rewards/margins": 2.1696057319641113,
      "rewards/rejected": -9.3280029296875,
      "step": 3370
    },
    {
      "epoch": 0.9979332742840271,
      "grad_norm": 14.89316177368164,
      "learning_rate": 1.3161942722173015e-05,
      "logits/chosen": 1.2570035457611084,
      "logits/rejected": 1.2246694564819336,
      "logps/chosen": -259.2967529296875,
      "logps/rejected": -285.4353332519531,
      "loss": 0.5125,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -6.796895503997803,
      "rewards/margins": 2.184828281402588,
      "rewards/rejected": -8.981724739074707,
      "step": 3380
    },
    {
      "epoch": 1.0008857395925599,
      "grad_norm": 4.8660478591918945,
      "learning_rate": 1.3159167404782996e-05,
      "logits/chosen": 1.5989186763763428,
      "logits/rejected": 1.561263084411621,
      "logps/chosen": -255.3583221435547,
      "logps/rejected": -276.5693359375,
      "loss": 0.3484,
      "rewards/accuracies": 0.8166666030883789,
      "rewards/chosen": -6.834868431091309,
      "rewards/margins": 2.2735869884490967,
      "rewards/rejected": -9.1084566116333,
      "step": 3390
    },
    {
      "epoch": 1.0038382049010923,
      "grad_norm": 14.36005687713623,
      "learning_rate": 1.3156392087392973e-05,
      "logits/chosen": 1.5350335836410522,
      "logits/rejected": 1.5061041116714478,
      "logps/chosen": -269.0565490722656,
      "logps/rejected": -296.93475341796875,
      "loss": 0.4923,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -7.499262809753418,
      "rewards/margins": 2.1473886966705322,
      "rewards/rejected": -9.646650314331055,
      "step": 3400
    },
    {
      "epoch": 1.006790670209625,
      "grad_norm": 15.641313552856445,
      "learning_rate": 1.3153616770002952e-05,
      "logits/chosen": 1.34211003780365,
      "logits/rejected": 1.2818725109100342,
      "logps/chosen": -266.97955322265625,
      "logps/rejected": -289.0804138183594,
      "loss": 0.353,
      "rewards/accuracies": 0.8333333134651184,
      "rewards/chosen": -7.5385894775390625,
      "rewards/margins": 2.1445441246032715,
      "rewards/rejected": -9.683134078979492,
      "step": 3410
    },
    {
      "epoch": 1.0097431355181576,
      "grad_norm": 12.42680835723877,
      "learning_rate": 1.3150841452612933e-05,
      "logits/chosen": 1.4426066875457764,
      "logits/rejected": 1.373716115951538,
      "logps/chosen": -262.0675354003906,
      "logps/rejected": -280.0879211425781,
      "loss": 0.499,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -7.031494140625,
      "rewards/margins": 2.169060468673706,
      "rewards/rejected": -9.200554847717285,
      "step": 3420
    },
    {
      "epoch": 1.0126956008266903,
      "grad_norm": 13.02347469329834,
      "learning_rate": 1.3148066135222912e-05,
      "logits/chosen": 1.6985183954238892,
      "logits/rejected": 1.6697454452514648,
      "logps/chosen": -255.1676483154297,
      "logps/rejected": -272.046142578125,
      "loss": 0.3157,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -6.065064430236816,
      "rewards/margins": 2.1388320922851562,
      "rewards/rejected": -8.203897476196289,
      "step": 3430
    },
    {
      "epoch": 1.015648066135223,
      "grad_norm": 5.198780536651611,
      "learning_rate": 1.3145290817832891e-05,
      "logits/chosen": 1.2719242572784424,
      "logits/rejected": 1.2313992977142334,
      "logps/chosen": -250.9236297607422,
      "logps/rejected": -271.6742858886719,
      "loss": 0.2169,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -5.695176601409912,
      "rewards/margins": 2.6899707317352295,
      "rewards/rejected": -8.385146141052246,
      "step": 3440
    },
    {
      "epoch": 1.0186005314437556,
      "grad_norm": 5.845244884490967,
      "learning_rate": 1.314251550044287e-05,
      "logits/chosen": 1.7604135274887085,
      "logits/rejected": 1.7228683233261108,
      "logps/chosen": -253.22055053710938,
      "logps/rejected": -279.0220642089844,
      "loss": 0.279,
      "rewards/accuracies": 0.8833333849906921,
      "rewards/chosen": -5.933660507202148,
      "rewards/margins": 2.662256956100464,
      "rewards/rejected": -8.595916748046875,
      "step": 3450
    },
    {
      "epoch": 1.021552996752288,
      "grad_norm": 18.716503143310547,
      "learning_rate": 1.3139740183052851e-05,
      "logits/chosen": 1.5487339496612549,
      "logits/rejected": 1.5192700624465942,
      "logps/chosen": -254.7562713623047,
      "logps/rejected": -280.95416259765625,
      "loss": 0.4338,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -6.6221184730529785,
      "rewards/margins": 2.053391695022583,
      "rewards/rejected": -8.675511360168457,
      "step": 3460
    },
    {
      "epoch": 1.0245054620608207,
      "grad_norm": 8.43563461303711,
      "learning_rate": 1.3136964865662828e-05,
      "logits/chosen": 1.5847537517547607,
      "logits/rejected": 1.5417009592056274,
      "logps/chosen": -264.9450988769531,
      "logps/rejected": -285.5238952636719,
      "loss": 0.3813,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -7.016054630279541,
      "rewards/margins": 2.301947832107544,
      "rewards/rejected": -9.318002700805664,
      "step": 3470
    },
    {
      "epoch": 1.0274579273693534,
      "grad_norm": 20.8289794921875,
      "learning_rate": 1.3134189548272807e-05,
      "logits/chosen": 1.309187650680542,
      "logits/rejected": 1.22226083278656,
      "logps/chosen": -255.891357421875,
      "logps/rejected": -284.54071044921875,
      "loss": 0.3051,
      "rewards/accuracies": 0.9166666865348816,
      "rewards/chosen": -6.627040863037109,
      "rewards/margins": 2.5708324909210205,
      "rewards/rejected": -9.197874069213867,
      "step": 3480
    },
    {
      "epoch": 1.030410392677886,
      "grad_norm": 29.757781982421875,
      "learning_rate": 1.3131414230882788e-05,
      "logits/chosen": 1.1970049142837524,
      "logits/rejected": 1.180037021636963,
      "logps/chosen": -262.7554626464844,
      "logps/rejected": -284.325439453125,
      "loss": 0.4033,
      "rewards/accuracies": 0.8500000834465027,
      "rewards/chosen": -6.899953365325928,
      "rewards/margins": 2.563840389251709,
      "rewards/rejected": -9.463793754577637,
      "step": 3490
    },
    {
      "epoch": 1.0333628579864187,
      "grad_norm": 18.08755111694336,
      "learning_rate": 1.3128638913492767e-05,
      "logits/chosen": 1.1198313236236572,
      "logits/rejected": 1.0784003734588623,
      "logps/chosen": -263.82684326171875,
      "logps/rejected": -289.18536376953125,
      "loss": 0.3363,
      "rewards/accuracies": 0.8333333134651184,
      "rewards/chosen": -7.093008995056152,
      "rewards/margins": 2.3482508659362793,
      "rewards/rejected": -9.441259384155273,
      "step": 3500
    },
    {
      "epoch": 1.0363153232949514,
      "grad_norm": 14.094757080078125,
      "learning_rate": 1.3125863596102746e-05,
      "logits/chosen": 1.4178086519241333,
      "logits/rejected": 1.3372790813446045,
      "logps/chosen": -275.8313903808594,
      "logps/rejected": -302.73736572265625,
      "loss": 0.3617,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -8.357890129089355,
      "rewards/margins": 2.6191070079803467,
      "rewards/rejected": -10.976997375488281,
      "step": 3510
    },
    {
      "epoch": 1.039267788603484,
      "grad_norm": 6.360774517059326,
      "learning_rate": 1.3123088278712726e-05,
      "logits/chosen": 1.059387445449829,
      "logits/rejected": 1.041822075843811,
      "logps/chosen": -279.63299560546875,
      "logps/rejected": -303.48956298828125,
      "loss": 0.3879,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -8.608328819274902,
      "rewards/margins": 2.242551565170288,
      "rewards/rejected": -10.85088062286377,
      "step": 3520
    },
    {
      "epoch": 1.0422202539120164,
      "grad_norm": 17.892921447753906,
      "learning_rate": 1.3120312961322705e-05,
      "logits/chosen": 1.285994529724121,
      "logits/rejected": 1.2460358142852783,
      "logps/chosen": -281.79229736328125,
      "logps/rejected": -304.5270080566406,
      "loss": 0.3771,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -9.35191535949707,
      "rewards/margins": 2.0940518379211426,
      "rewards/rejected": -11.445966720581055,
      "step": 3530
    },
    {
      "epoch": 1.045172719220549,
      "grad_norm": 16.1668701171875,
      "learning_rate": 1.3117537643932684e-05,
      "logits/chosen": 1.590800166130066,
      "logits/rejected": 1.5284608602523804,
      "logps/chosen": -284.22259521484375,
      "logps/rejected": -311.89202880859375,
      "loss": 0.3929,
      "rewards/accuracies": 0.8500000834465027,
      "rewards/chosen": -9.454818725585938,
      "rewards/margins": 2.3246045112609863,
      "rewards/rejected": -11.779423713684082,
      "step": 3540
    },
    {
      "epoch": 1.0481251845290818,
      "grad_norm": 19.32920265197754,
      "learning_rate": 1.3114762326542663e-05,
      "logits/chosen": 1.3143106698989868,
      "logits/rejected": 1.2512487173080444,
      "logps/chosen": -290.1806335449219,
      "logps/rejected": -308.80194091796875,
      "loss": 0.5372,
      "rewards/accuracies": 0.7666666507720947,
      "rewards/chosen": -9.71679401397705,
      "rewards/margins": 2.181969165802002,
      "rewards/rejected": -11.898761749267578,
      "step": 3550
    },
    {
      "epoch": 1.0510776498376144,
      "grad_norm": 14.31533145904541,
      "learning_rate": 1.3111987009152644e-05,
      "logits/chosen": 1.4179617166519165,
      "logits/rejected": 1.3721221685409546,
      "logps/chosen": -286.714111328125,
      "logps/rejected": -309.36669921875,
      "loss": 0.396,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -9.715799331665039,
      "rewards/margins": 1.9174410104751587,
      "rewards/rejected": -11.633240699768066,
      "step": 3560
    },
    {
      "epoch": 1.054030115146147,
      "grad_norm": 6.4076690673828125,
      "learning_rate": 1.3109211691762623e-05,
      "logits/chosen": 1.8353309631347656,
      "logits/rejected": 1.7801090478897095,
      "logps/chosen": -282.08587646484375,
      "logps/rejected": -311.35333251953125,
      "loss": 0.3996,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -9.132697105407715,
      "rewards/margins": 2.476463794708252,
      "rewards/rejected": -11.609160423278809,
      "step": 3570
    },
    {
      "epoch": 1.0569825804546797,
      "grad_norm": 10.573390007019043,
      "learning_rate": 1.3106436374372602e-05,
      "logits/chosen": 1.620525598526001,
      "logits/rejected": 1.5591233968734741,
      "logps/chosen": -284.4248962402344,
      "logps/rejected": -316.397705078125,
      "loss": 0.2422,
      "rewards/accuracies": 0.8833333253860474,
      "rewards/chosen": -9.375039100646973,
      "rewards/margins": 2.9064979553222656,
      "rewards/rejected": -12.281537055969238,
      "step": 3580
    },
    {
      "epoch": 1.0599350457632122,
      "grad_norm": 4.0812153816223145,
      "learning_rate": 1.3103661056982581e-05,
      "logits/chosen": 1.1923863887786865,
      "logits/rejected": 1.1410999298095703,
      "logps/chosen": -284.131103515625,
      "logps/rejected": -311.2518310546875,
      "loss": 0.2808,
      "rewards/accuracies": 0.8833333849906921,
      "rewards/chosen": -9.659685134887695,
      "rewards/margins": 2.4120142459869385,
      "rewards/rejected": -12.071699142456055,
      "step": 3590
    },
    {
      "epoch": 1.0628875110717448,
      "grad_norm": 11.616724967956543,
      "learning_rate": 1.310088573959256e-05,
      "logits/chosen": 1.7596046924591064,
      "logits/rejected": 1.6589879989624023,
      "logps/chosen": -285.89349365234375,
      "logps/rejected": -326.8060607910156,
      "loss": 0.2325,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -9.799467086791992,
      "rewards/margins": 3.6108250617980957,
      "rewards/rejected": -13.410290718078613,
      "step": 3600
    },
    {
      "epoch": 1.0658399763802775,
      "grad_norm": 19.381608963012695,
      "learning_rate": 1.3098110422202539e-05,
      "logits/chosen": 2.3846516609191895,
      "logits/rejected": 2.2881627082824707,
      "logps/chosen": -288.4023742675781,
      "logps/rejected": -322.93756103515625,
      "loss": 0.2776,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -9.615399360656738,
      "rewards/margins": 3.1548328399658203,
      "rewards/rejected": -12.770232200622559,
      "step": 3610
    },
    {
      "epoch": 1.0687924416888102,
      "grad_norm": 23.564455032348633,
      "learning_rate": 1.3095335104812518e-05,
      "logits/chosen": 1.2511415481567383,
      "logits/rejected": 1.1372668743133545,
      "logps/chosen": -296.3532409667969,
      "logps/rejected": -331.31085205078125,
      "loss": 0.5083,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -10.462837219238281,
      "rewards/margins": 3.0698463916778564,
      "rewards/rejected": -13.532684326171875,
      "step": 3620
    },
    {
      "epoch": 1.0717449069973428,
      "grad_norm": 5.106109619140625,
      "learning_rate": 1.3092559787422499e-05,
      "logits/chosen": 1.3568699359893799,
      "logits/rejected": 1.2922638654708862,
      "logps/chosen": -299.0877685546875,
      "logps/rejected": -326.5018615722656,
      "loss": 0.29,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -10.424622535705566,
      "rewards/margins": 2.803112030029297,
      "rewards/rejected": -13.22773265838623,
      "step": 3630
    },
    {
      "epoch": 1.0746973723058755,
      "grad_norm": 15.425999641418457,
      "learning_rate": 1.3089784470032478e-05,
      "logits/chosen": 1.7296326160430908,
      "logits/rejected": 1.6520427465438843,
      "logps/chosen": -292.935791015625,
      "logps/rejected": -320.3554992675781,
      "loss": 0.2863,
      "rewards/accuracies": 0.8833333849906921,
      "rewards/chosen": -9.782617568969727,
      "rewards/margins": 3.1122336387634277,
      "rewards/rejected": -12.894851684570312,
      "step": 3640
    },
    {
      "epoch": 1.0776498376144081,
      "grad_norm": 13.068792343139648,
      "learning_rate": 1.3087009152642457e-05,
      "logits/chosen": 1.9024578332901,
      "logits/rejected": 1.8313686847686768,
      "logps/chosen": -296.46112060546875,
      "logps/rejected": -326.2397155761719,
      "loss": 0.2913,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -10.159660339355469,
      "rewards/margins": 3.1863906383514404,
      "rewards/rejected": -13.346051216125488,
      "step": 3650
    },
    {
      "epoch": 1.0806023029229406,
      "grad_norm": 5.79445219039917,
      "learning_rate": 1.3084233835252436e-05,
      "logits/chosen": 1.3920519351959229,
      "logits/rejected": 1.3203904628753662,
      "logps/chosen": -316.93280029296875,
      "logps/rejected": -344.98773193359375,
      "loss": 0.3773,
      "rewards/accuracies": 0.8000000715255737,
      "rewards/chosen": -12.128173828125,
      "rewards/margins": 2.7734389305114746,
      "rewards/rejected": -14.901613235473633,
      "step": 3660
    },
    {
      "epoch": 1.0835547682314732,
      "grad_norm": 6.003654956817627,
      "learning_rate": 1.3081458517862415e-05,
      "logits/chosen": 1.3288967609405518,
      "logits/rejected": 1.227825403213501,
      "logps/chosen": -321.6728820800781,
      "logps/rejected": -355.73187255859375,
      "loss": 0.3404,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -13.243426322937012,
      "rewards/margins": 3.0248942375183105,
      "rewards/rejected": -16.268321990966797,
      "step": 3670
    },
    {
      "epoch": 1.086507233540006,
      "grad_norm": 5.580012321472168,
      "learning_rate": 1.3078683200472396e-05,
      "logits/chosen": 1.3550019264221191,
      "logits/rejected": 1.2578575611114502,
      "logps/chosen": -326.6701965332031,
      "logps/rejected": -354.63970947265625,
      "loss": 0.4486,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -13.463099479675293,
      "rewards/margins": 2.337381601333618,
      "rewards/rejected": -15.8004789352417,
      "step": 3680
    },
    {
      "epoch": 1.0894596988485385,
      "grad_norm": 16.553070068359375,
      "learning_rate": 1.3075907883082373e-05,
      "logits/chosen": 1.847890853881836,
      "logits/rejected": 1.685072660446167,
      "logps/chosen": -307.5971374511719,
      "logps/rejected": -336.4680480957031,
      "loss": 0.3036,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -11.541740417480469,
      "rewards/margins": 2.8959743976593018,
      "rewards/rejected": -14.437713623046875,
      "step": 3690
    },
    {
      "epoch": 1.0924121641570712,
      "grad_norm": 7.214972496032715,
      "learning_rate": 1.3073132565692354e-05,
      "logits/chosen": 1.5498435497283936,
      "logits/rejected": 1.422104001045227,
      "logps/chosen": -300.82037353515625,
      "logps/rejected": -336.8814392089844,
      "loss": 0.2645,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -10.889363288879395,
      "rewards/margins": 3.1880948543548584,
      "rewards/rejected": -14.077459335327148,
      "step": 3700
    },
    {
      "epoch": 1.0953646294656039,
      "grad_norm": 11.332780838012695,
      "learning_rate": 1.3070357248302333e-05,
      "logits/chosen": 1.587679147720337,
      "logits/rejected": 1.5090705156326294,
      "logps/chosen": -291.8326721191406,
      "logps/rejected": -323.1639099121094,
      "loss": 0.2836,
      "rewards/accuracies": 0.9333333969116211,
      "rewards/chosen": -10.052423477172852,
      "rewards/margins": 3.0774598121643066,
      "rewards/rejected": -13.1298828125,
      "step": 3710
    },
    {
      "epoch": 1.0983170947741363,
      "grad_norm": 13.029647827148438,
      "learning_rate": 1.306758193091231e-05,
      "logits/chosen": 1.3419640064239502,
      "logits/rejected": 1.3076744079589844,
      "logps/chosen": -292.5884094238281,
      "logps/rejected": -320.22076416015625,
      "loss": 0.3012,
      "rewards/accuracies": 0.8333333134651184,
      "rewards/chosen": -10.256292343139648,
      "rewards/margins": 2.7207422256469727,
      "rewards/rejected": -12.977033615112305,
      "step": 3720
    },
    {
      "epoch": 1.101269560082669,
      "grad_norm": 22.0727596282959,
      "learning_rate": 1.3064806613522292e-05,
      "logits/chosen": 1.4968525171279907,
      "logits/rejected": 1.4041082859039307,
      "logps/chosen": -307.1689453125,
      "logps/rejected": -333.0337829589844,
      "loss": 0.3597,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -11.223407745361328,
      "rewards/margins": 2.8814568519592285,
      "rewards/rejected": -14.104864120483398,
      "step": 3730
    },
    {
      "epoch": 1.1042220253912016,
      "grad_norm": 21.723726272583008,
      "learning_rate": 1.306203129613227e-05,
      "logits/chosen": 1.3978383541107178,
      "logits/rejected": 1.3099730014801025,
      "logps/chosen": -313.9325256347656,
      "logps/rejected": -338.7426452636719,
      "loss": 0.3949,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -12.221261024475098,
      "rewards/margins": 2.8407349586486816,
      "rewards/rejected": -15.061994552612305,
      "step": 3740
    },
    {
      "epoch": 1.1071744906997343,
      "grad_norm": 9.808956146240234,
      "learning_rate": 1.3059255978742251e-05,
      "logits/chosen": 1.6790415048599243,
      "logits/rejected": 1.5928844213485718,
      "logps/chosen": -334.9511413574219,
      "logps/rejected": -355.1834716796875,
      "loss": 0.5159,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -14.295740127563477,
      "rewards/margins": 1.9419105052947998,
      "rewards/rejected": -16.237651824951172,
      "step": 3750
    },
    {
      "epoch": 1.110126956008267,
      "grad_norm": 16.882793426513672,
      "learning_rate": 1.3056480661352229e-05,
      "logits/chosen": 1.2578916549682617,
      "logits/rejected": 1.1758784055709839,
      "logps/chosen": -324.71160888671875,
      "logps/rejected": -348.6304931640625,
      "loss": 0.3801,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -13.535326957702637,
      "rewards/margins": 1.9289392232894897,
      "rewards/rejected": -15.464266777038574,
      "step": 3760
    },
    {
      "epoch": 1.1130794213167996,
      "grad_norm": 13.699742317199707,
      "learning_rate": 1.305370534396221e-05,
      "logits/chosen": 1.2058359384536743,
      "logits/rejected": 1.1262195110321045,
      "logps/chosen": -316.2795104980469,
      "logps/rejected": -343.30230712890625,
      "loss": 0.3438,
      "rewards/accuracies": 0.8500000834465027,
      "rewards/chosen": -12.753338813781738,
      "rewards/margins": 2.069978713989258,
      "rewards/rejected": -14.82331657409668,
      "step": 3770
    },
    {
      "epoch": 1.1160318866253323,
      "grad_norm": 16.399755477905273,
      "learning_rate": 1.3050930026572189e-05,
      "logits/chosen": 1.2111709117889404,
      "logits/rejected": 1.1621640920639038,
      "logps/chosen": -320.328857421875,
      "logps/rejected": -347.0388488769531,
      "loss": 0.4061,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -13.517303466796875,
      "rewards/margins": 2.1462979316711426,
      "rewards/rejected": -15.663601875305176,
      "step": 3780
    },
    {
      "epoch": 1.1189843519338647,
      "grad_norm": 16.02547264099121,
      "learning_rate": 1.3048154709182168e-05,
      "logits/chosen": 1.2716920375823975,
      "logits/rejected": 1.1698682308197021,
      "logps/chosen": -312.40576171875,
      "logps/rejected": -331.4580993652344,
      "loss": 0.2473,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -12.00969409942627,
      "rewards/margins": 2.5955686569213867,
      "rewards/rejected": -14.605262756347656,
      "step": 3790
    },
    {
      "epoch": 1.1219368172423974,
      "grad_norm": 14.296483993530273,
      "learning_rate": 1.3045379391792147e-05,
      "logits/chosen": 1.1365749835968018,
      "logits/rejected": 1.0810619592666626,
      "logps/chosen": -310.8717346191406,
      "logps/rejected": -338.4515075683594,
      "loss": 0.3857,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -11.877084732055664,
      "rewards/margins": 2.737318277359009,
      "rewards/rejected": -14.614402770996094,
      "step": 3800
    },
    {
      "epoch": 1.12488928255093,
      "grad_norm": 15.513395309448242,
      "learning_rate": 1.3042604074402126e-05,
      "logits/chosen": 1.7256889343261719,
      "logits/rejected": 1.6522912979125977,
      "logps/chosen": -302.6755676269531,
      "logps/rejected": -328.57220458984375,
      "loss": 0.2859,
      "rewards/accuracies": 0.8333333134651184,
      "rewards/chosen": -10.874592781066895,
      "rewards/margins": 2.6025185585021973,
      "rewards/rejected": -13.4771089553833,
      "step": 3810
    },
    {
      "epoch": 1.1278417478594627,
      "grad_norm": 21.419055938720703,
      "learning_rate": 1.3039828757012107e-05,
      "logits/chosen": 1.5999565124511719,
      "logits/rejected": 1.5241382122039795,
      "logps/chosen": -285.80767822265625,
      "logps/rejected": -317.55584716796875,
      "loss": 0.276,
      "rewards/accuracies": 0.8833333849906921,
      "rewards/chosen": -9.327058792114258,
      "rewards/margins": 3.075778007507324,
      "rewards/rejected": -12.402836799621582,
      "step": 3820
    },
    {
      "epoch": 1.1307942131679953,
      "grad_norm": 8.127215385437012,
      "learning_rate": 1.3037053439622084e-05,
      "logits/chosen": 1.3629505634307861,
      "logits/rejected": 1.2926809787750244,
      "logps/chosen": -275.5018310546875,
      "logps/rejected": -307.34307861328125,
      "loss": 0.3195,
      "rewards/accuracies": 0.8833333849906921,
      "rewards/chosen": -8.500781059265137,
      "rewards/margins": 2.8664069175720215,
      "rewards/rejected": -11.367189407348633,
      "step": 3830
    },
    {
      "epoch": 1.133746678476528,
      "grad_norm": 10.68191909790039,
      "learning_rate": 1.3034278122232065e-05,
      "logits/chosen": 1.6073471307754517,
      "logits/rejected": 1.5561466217041016,
      "logps/chosen": -262.3487243652344,
      "logps/rejected": -294.4128723144531,
      "loss": 0.2363,
      "rewards/accuracies": 0.8833333849906921,
      "rewards/chosen": -7.167367458343506,
      "rewards/margins": 3.049516201019287,
      "rewards/rejected": -10.21688461303711,
      "step": 3840
    },
    {
      "epoch": 1.1366991437850604,
      "grad_norm": 12.802721977233887,
      "learning_rate": 1.3031502804842044e-05,
      "logits/chosen": 1.0494645833969116,
      "logits/rejected": 1.0421242713928223,
      "logps/chosen": -274.0091552734375,
      "logps/rejected": -304.38494873046875,
      "loss": 0.3469,
      "rewards/accuracies": 0.8333333730697632,
      "rewards/chosen": -8.018099784851074,
      "rewards/margins": 2.550150156021118,
      "rewards/rejected": -10.568249702453613,
      "step": 3850
    },
    {
      "epoch": 1.139651609093593,
      "grad_norm": 15.465486526489258,
      "learning_rate": 1.3028727487452023e-05,
      "logits/chosen": 1.3358551263809204,
      "logits/rejected": 1.3233448266983032,
      "logps/chosen": -275.6295166015625,
      "logps/rejected": -297.1833801269531,
      "loss": 0.2874,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -8.095436096191406,
      "rewards/margins": 2.847388982772827,
      "rewards/rejected": -10.94282341003418,
      "step": 3860
    },
    {
      "epoch": 1.1426040744021257,
      "grad_norm": 5.591419219970703,
      "learning_rate": 1.3025952170062002e-05,
      "logits/chosen": 1.0365755558013916,
      "logits/rejected": 0.9283109903335571,
      "logps/chosen": -271.57232666015625,
      "logps/rejected": -305.00726318359375,
      "loss": 0.2581,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -8.091922760009766,
      "rewards/margins": 3.045611619949341,
      "rewards/rejected": -11.137535095214844,
      "step": 3870
    },
    {
      "epoch": 1.1455565397106584,
      "grad_norm": 10.439189910888672,
      "learning_rate": 1.3023176852671981e-05,
      "logits/chosen": 1.2509267330169678,
      "logits/rejected": 1.193901777267456,
      "logps/chosen": -272.0635986328125,
      "logps/rejected": -294.68011474609375,
      "loss": 0.4937,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -7.999770164489746,
      "rewards/margins": 2.4046833515167236,
      "rewards/rejected": -10.40445327758789,
      "step": 3880
    },
    {
      "epoch": 1.148509005019191,
      "grad_norm": 4.9589715003967285,
      "learning_rate": 1.3020401535281962e-05,
      "logits/chosen": 1.0683873891830444,
      "logits/rejected": 1.0156785249710083,
      "logps/chosen": -261.0447998046875,
      "logps/rejected": -291.395751953125,
      "loss": 0.1977,
      "rewards/accuracies": 0.9166666865348816,
      "rewards/chosen": -6.906085014343262,
      "rewards/margins": 3.0630388259887695,
      "rewards/rejected": -9.969124794006348,
      "step": 3890
    },
    {
      "epoch": 1.1514614703277237,
      "grad_norm": 20.399404525756836,
      "learning_rate": 1.301762621789194e-05,
      "logits/chosen": 1.2844022512435913,
      "logits/rejected": 1.2410422563552856,
      "logps/chosen": -274.40850830078125,
      "logps/rejected": -304.00128173828125,
      "loss": 0.4583,
      "rewards/accuracies": 0.8166667222976685,
      "rewards/chosen": -8.491483688354492,
      "rewards/margins": 2.545792818069458,
      "rewards/rejected": -11.037277221679688,
      "step": 3900
    },
    {
      "epoch": 1.1544139356362564,
      "grad_norm": 15.334240913391113,
      "learning_rate": 1.3014850900501919e-05,
      "logits/chosen": 0.9831063151359558,
      "logits/rejected": 0.9330054521560669,
      "logps/chosen": -277.3258972167969,
      "logps/rejected": -298.26416015625,
      "loss": 0.4255,
      "rewards/accuracies": 0.7333333492279053,
      "rewards/chosen": -8.635716438293457,
      "rewards/margins": 2.2938411235809326,
      "rewards/rejected": -10.929559707641602,
      "step": 3910
    },
    {
      "epoch": 1.1573664009447888,
      "grad_norm": 18.59358787536621,
      "learning_rate": 1.30120755831119e-05,
      "logits/chosen": 1.3472999334335327,
      "logits/rejected": 1.2777721881866455,
      "logps/chosen": -285.2633056640625,
      "logps/rejected": -310.1905212402344,
      "loss": 0.3131,
      "rewards/accuracies": 0.8833333849906921,
      "rewards/chosen": -9.093297958374023,
      "rewards/margins": 2.760349750518799,
      "rewards/rejected": -11.853647232055664,
      "step": 3920
    },
    {
      "epoch": 1.1603188662533215,
      "grad_norm": 18.978317260742188,
      "learning_rate": 1.3009300265721878e-05,
      "logits/chosen": 1.6674721240997314,
      "logits/rejected": 1.5735267400741577,
      "logps/chosen": -277.53863525390625,
      "logps/rejected": -304.01141357421875,
      "loss": 0.2577,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -8.558698654174805,
      "rewards/margins": 3.0287909507751465,
      "rewards/rejected": -11.587491035461426,
      "step": 3930
    },
    {
      "epoch": 1.1632713315618541,
      "grad_norm": 5.15968656539917,
      "learning_rate": 1.3006524948331858e-05,
      "logits/chosen": 1.7267391681671143,
      "logits/rejected": 1.6674858331680298,
      "logps/chosen": -272.2288513183594,
      "logps/rejected": -309.8069763183594,
      "loss": 0.2891,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -8.40453815460205,
      "rewards/margins": 3.377185106277466,
      "rewards/rejected": -11.781723976135254,
      "step": 3940
    },
    {
      "epoch": 1.1662237968703868,
      "grad_norm": 14.24914836883545,
      "learning_rate": 1.3003749630941837e-05,
      "logits/chosen": 1.7383594512939453,
      "logits/rejected": 1.6511882543563843,
      "logps/chosen": -273.0992736816406,
      "logps/rejected": -303.14837646484375,
      "loss": 0.2835,
      "rewards/accuracies": 0.8666666746139526,
      "rewards/chosen": -8.55908489227295,
      "rewards/margins": 2.7792930603027344,
      "rewards/rejected": -11.338377952575684,
      "step": 3950
    },
    {
      "epoch": 1.1691762621789195,
      "grad_norm": 14.890795707702637,
      "learning_rate": 1.3000974313551817e-05,
      "logits/chosen": 0.7544081807136536,
      "logits/rejected": 0.7111387252807617,
      "logps/chosen": -294.17437744140625,
      "logps/rejected": -321.0454406738281,
      "loss": 0.4162,
      "rewards/accuracies": 0.8166667819023132,
      "rewards/chosen": -10.236337661743164,
      "rewards/margins": 2.4503421783447266,
      "rewards/rejected": -12.686680793762207,
      "step": 3960
    },
    {
      "epoch": 1.1721287274874521,
      "grad_norm": 21.206138610839844,
      "learning_rate": 1.2998198996161795e-05,
      "logits/chosen": 1.4709171056747437,
      "logits/rejected": 1.4191340208053589,
      "logps/chosen": -285.8981628417969,
      "logps/rejected": -316.00006103515625,
      "loss": 0.4841,
      "rewards/accuracies": 0.7500000596046448,
      "rewards/chosen": -9.593048095703125,
      "rewards/margins": 2.5298328399658203,
      "rewards/rejected": -12.122880935668945,
      "step": 3970
    },
    {
      "epoch": 1.1750811927959846,
      "grad_norm": 17.661842346191406,
      "learning_rate": 1.2995423678771774e-05,
      "logits/chosen": 1.137695550918579,
      "logits/rejected": 1.0503785610198975,
      "logps/chosen": -289.841552734375,
      "logps/rejected": -312.2737121582031,
      "loss": 0.4315,
      "rewards/accuracies": 0.783333420753479,
      "rewards/chosen": -10.18006420135498,
      "rewards/margins": 2.3291351795196533,
      "rewards/rejected": -12.509199142456055,
      "step": 3980
    },
    {
      "epoch": 1.1780336581045172,
      "grad_norm": 7.994351387023926,
      "learning_rate": 1.2992648361381755e-05,
      "logits/chosen": 0.8476983308792114,
      "logits/rejected": 0.7773923873901367,
      "logps/chosen": -285.77667236328125,
      "logps/rejected": -315.62078857421875,
      "loss": 0.3131,
      "rewards/accuracies": 0.8833333849906921,
      "rewards/chosen": -9.707022666931152,
      "rewards/margins": 2.5148863792419434,
      "rewards/rejected": -12.221908569335938,
      "step": 3990
    },
    {
      "epoch": 1.1809861234130499,
      "grad_norm": 12.473135948181152,
      "learning_rate": 1.2989873043991734e-05,
      "logits/chosen": 1.2142366170883179,
      "logits/rejected": 1.09906005859375,
      "logps/chosen": -295.94354248046875,
      "logps/rejected": -326.14324951171875,
      "loss": 0.3353,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -10.001886367797852,
      "rewards/margins": 3.1758193969726562,
      "rewards/rejected": -13.177706718444824,
      "step": 4000
    }
  ],
  "logging_steps": 10,
  "max_steps": 50805,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 6,
  "trial_name": null,
  "trial_params": null
}
